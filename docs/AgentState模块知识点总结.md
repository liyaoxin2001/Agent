# AgentState æ¨¡å—çŸ¥è¯†ç‚¹æ€»ç»“

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æ€»ç»“ LangGraph Agent ä¸­ Stateï¼ˆçŠ¶æ€ï¼‰æ¨¡å—çš„æ ¸å¿ƒçŸ¥è¯†ç‚¹ï¼ŒåŒ…æ‹¬æ¦‚å¿µã€è®¾è®¡åŸåˆ™ã€å®ç°æ–¹æ³•å’Œæœ€ä½³å®è·µã€‚

**é€‚ç”¨å¯¹è±¡**ï¼šå­¦ä¹  LangGraph Agent å¼€å‘çš„åˆå­¦è€…å’Œå®è·µè€…

**çŸ¥è¯†ç‚¹å±‚çº§**ï¼šä»åŸºç¡€æ¦‚å¿µåˆ°é«˜çº§åº”ç”¨ï¼Œé€å±‚é€’è¿›

---

## ä¸€ã€æ ¸å¿ƒæ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯ Stateï¼Ÿ

**å®šä¹‰**ï¼šState æ˜¯ LangGraph Agent æ‰§è¡Œè¿‡ç¨‹ä¸­çš„**å…±äº«å·¥ä½œç©ºé—´**ï¼Œç”¨äºåœ¨å¤šä¸ªèŠ‚ç‚¹ä¹‹é—´ä¼ é€’æ•°æ®å’Œè®°å½•æ‰§è¡ŒçŠ¶æ€ã€‚

**æœ¬è´¨**ï¼š
- State æ˜¯ä¸€ä¸ª**ç»“æ„åŒ–çš„æ•°æ®å®¹å™¨**
- ç±»ä¼¼äº**å…¨å±€å˜é‡**ï¼Œä½†æ›´åŠ ç»“æ„åŒ–å’Œç±»å‹å®‰å…¨
- æ˜¯èŠ‚ç‚¹ä¹‹é—´çš„**æ•°æ®æ€»çº¿**

**æ‰§è¡Œæµç¨‹**ï¼š
```
åˆå§‹ State
    â†“
[èŠ‚ç‚¹1: æ£€ç´¢] â†’ æ›´æ–° State (æ·»åŠ  retrieved_docs)
    â†“
[èŠ‚ç‚¹2: ç”Ÿæˆ] â†’ æ›´æ–° State (æ·»åŠ  answer)
    â†“
[èŠ‚ç‚¹3: è¯„ä¼°] â†’ æ›´æ–° State (æ·»åŠ  score)
    â†“
æœ€ç»ˆ State (åŒ…å«å®Œæ•´çš„æ‰§è¡Œç»“æœ)
```

**ä¸ä¼ ç»Ÿç¼–ç¨‹çš„å¯¹æ¯”**ï¼š

| ä¼ ç»Ÿæ–¹å¼ | LangGraph State |
|---------|----------------|
| å‡½æ•°å‚æ•°ä¼ é€’ | å…±äº« State å¯¹è±¡ |
| è¿”å›å€¼åµŒå¥— | State è‡ªåŠ¨æµè½¬ |
| æ‰‹åŠ¨ç®¡ç†æ•°æ®æµ | æ¡†æ¶è‡ªåŠ¨ç®¡ç† |
| éš¾ä»¥è¿½è¸ªçŠ¶æ€ | State è®°å½•æ‰€æœ‰å˜åŒ– |

**ä»£ç ç¤ºä¾‹**ï¼š
```python
# ä¼ ç»Ÿæ–¹å¼ - å‚æ•°ä¼ é€’æ··ä¹±
docs = retrieve(question)
context = format_docs(docs)
answer = generate(context, question)
score = evaluate(answer, question, docs)
# å‚æ•°è¶Šæ¥è¶Šå¤šï¼Œéš¾ä»¥ç»´æŠ¤

# LangGraph æ–¹å¼ - State è‡ªåŠ¨æµè½¬
state = {"question": question}
state = retrieve_node(state)    # State è‡ªåŠ¨åŒ…å« retrieved_docs
state = generate_node(state)    # State è‡ªåŠ¨åŒ…å« answer
state = evaluate_node(state)    # State è‡ªåŠ¨åŒ…å« score
# æ•°æ®æµæ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤
```

---

### 1.2 ä¸ºä»€ä¹ˆéœ€è¦ Stateï¼Ÿ

#### é—®é¢˜1ï¼šå¤šèŠ‚ç‚¹æ•°æ®ä¼ é€’å¤æ‚

**åœºæ™¯**ï¼šä¸€ä¸ª Agent åŒ…å« 5 ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹éœ€è¦ä¸åŒçš„æ•°æ®

```python
# âŒ æ²¡æœ‰ State - å‚æ•°ä¼ é€’åœ°ç‹±
def agent_pipeline(question):
    # èŠ‚ç‚¹1
    docs = retrieve(question)
    
    # èŠ‚ç‚¹2 - éœ€è¦ question å’Œ docs
    context = format_context(question, docs)
    
    # èŠ‚ç‚¹3 - éœ€è¦ question, docs, context
    answer = generate(question, docs, context)
    
    # èŠ‚ç‚¹4 - éœ€è¦æ‰€æœ‰ä¹‹å‰çš„æ•°æ®
    score = evaluate(question, docs, context, answer)
    
    # èŠ‚ç‚¹5 - å‚æ•°çˆ†ç‚¸
    final = postprocess(question, docs, context, answer, score)
    
    return final  # è¿”å›å€¼ä¹Ÿå¾ˆå¤æ‚
```

```python
# âœ… æœ‰ State - æ¸…æ™°ç®€æ´
def agent_pipeline(question):
    state = {"question": question}
    
    state = retrieve_node(state)      # æ‰€æœ‰æ•°æ®åœ¨ State ä¸­
    state = format_node(state)
    state = generate_node(state)
    state = evaluate_node(state)
    state = postprocess_node(state)
    
    return state  # è¿”å›å®Œæ•´ State
```

#### é—®é¢˜2ï¼šéš¾ä»¥è¿½è¸ªæ‰§è¡ŒçŠ¶æ€

**åœºæ™¯**ï¼šè°ƒè¯•æ—¶éœ€è¦çŸ¥é“æ¯ä¸€æ­¥çš„çŠ¶æ€

```python
# âŒ æ²¡æœ‰ State - éœ€è¦æ‰‹åŠ¨è®°å½•
def agent_with_logging(question):
    logs = []
    
    docs = retrieve(question)
    logs.append(f"Retrieved {len(docs)} docs")
    
    answer = generate(question, docs)
    logs.append(f"Generated answer: {answer[:50]}")
    
    # æ—¥å¿—å’Œä¸šåŠ¡é€»è¾‘æ··åœ¨ä¸€èµ·
    return answer, logs
```

```python
# âœ… æœ‰ State - è‡ªåŠ¨è®°å½•
class AgentState(TypedDict):
    question: str
    answer: Optional[str]
    processing_log: List[str]  # å†…ç½®æ—¥å¿—

def retrieve_node(state):
    docs = retrieve(state['question'])
    state['processing_log'].append(f"Retrieved {len(docs)} docs")
    return state

# æ—¥å¿—æ˜¯ State çš„ä¸€éƒ¨åˆ†ï¼Œè‡ªåŠ¨ç®¡ç†
```

#### é—®é¢˜3ï¼šæ¡ä»¶åˆ†æ”¯å†³ç­–å›°éš¾

**åœºæ™¯**ï¼šæ ¹æ®ä¸­é—´ç»“æœå†³å®šä¸‹ä¸€æ­¥æ“ä½œ

```python
# âŒ æ²¡æœ‰ State - é€»è¾‘å¤æ‚
def agent_with_decision(question):
    docs = retrieve(question)
    
    # éœ€è¦è¿”å›å¤šä¸ªå€¼æ¥æ”¯æŒå†³ç­–
    if len(docs) < 3:
        more_docs = retrieve_more(question)
        docs.extend(more_docs)
    
    answer = generate(question, docs)
    
    # åˆéœ€è¦è¿”å›å¤šä¸ªå€¼
    if len(answer) < 50:
        answer = generate_longer(question, docs)
    
    return answer
```

```python
# âœ… æœ‰ State - å†³ç­–æ¸…æ™°
def should_retrieve_more(state):
    """å†³ç­–å‡½æ•°"""
    if len(state['retrieved_docs']) < 3:
        return "retrieve_more"
    else:
        return "generate"

# åœ¨ Graph ä¸­ä½¿ç”¨æ¡ä»¶è¾¹
graph.add_conditional_edges(
    "retrieve",
    should_retrieve_more,
    {
        "retrieve_more": "retrieve",
        "generate": "generate"
    }
)
```

---

### 1.3 State çš„æ ¸å¿ƒç‰¹æ€§

#### ç‰¹æ€§1ï¼šç±»å‹å®‰å…¨ï¼ˆTypedDictï¼‰

**ä¸ºä»€ä¹ˆä½¿ç”¨ TypedDictï¼Ÿ**

```python
# âŒ æ™®é€š dict - æ²¡æœ‰ç±»å‹æ£€æŸ¥
state = {"question": "Pythonæ˜¯ä»€ä¹ˆï¼Ÿ"}
state["anser"] = "..."  # æ‹¼å†™é”™è¯¯ï¼Œè¿è¡Œæ—¶æ‰å‘ç°ï¼
state["retrieved_docs"] = "wrong type"  # ç±»å‹é”™è¯¯ï¼Œè¿è¡Œæ—¶æ‰å‘ç°ï¼

# âœ… TypedDict - ç¼–è¯‘æ—¶æ£€æŸ¥
from typing import TypedDict, Optional, List
from langchain.schema import Document

class AgentState(TypedDict):
    question: str
    answer: Optional[str]
    retrieved_docs: Optional[List[Document]]

state: AgentState = {"question": "Pythonæ˜¯ä»€ä¹ˆï¼Ÿ"}
state["anser"] = "..."  # IDE ç«‹å³æç¤ºé”™è¯¯ï¼
state["retrieved_docs"] = "wrong"  # IDE ç«‹å³æç¤ºç±»å‹é”™è¯¯ï¼
```

**TypedDict çš„ä¼˜åŠ¿**ï¼š
1. **IDE è‡ªåŠ¨è¡¥å…¨**ï¼šè¾“å…¥ `state[` æ—¶è‡ªåŠ¨æç¤ºæ‰€æœ‰å¯ç”¨å­—æ®µ
2. **ç±»å‹æ£€æŸ¥**ï¼šèµ‹å€¼é”™è¯¯ç±»å‹æ—¶ç«‹å³æŠ¥é”™
3. **æ–‡æ¡£åŒ–**ï¼šç±»å‹æ³¨è§£æœ¬èº«å°±æ˜¯æ–‡æ¡£
4. **é‡æ„å®‰å…¨**ï¼šé‡å‘½åå­—æ®µæ—¶è‡ªåŠ¨æ‰¾åˆ°æ‰€æœ‰å¼•ç”¨

#### ç‰¹æ€§2ï¼šå¯é€‰å­—æ®µï¼ˆOptionalï¼‰

**ä¸ºä»€ä¹ˆå¾ˆå¤šå­—æ®µæ˜¯ Optionalï¼Ÿ**

```python
class AgentState(TypedDict):
    question: str                           # å¿…å¡«ï¼ˆåˆå§‹åŒ–æ—¶å°±æœ‰ï¼‰
    retrieved_docs: Optional[List[Document]]  # å¯é€‰ï¼ˆæ£€ç´¢èŠ‚ç‚¹å¡«å……ï¼‰
    answer: Optional[str]                    # å¯é€‰ï¼ˆç”ŸæˆèŠ‚ç‚¹å¡«å……ï¼‰
```

**åŸå› **ï¼š
- åˆå§‹åŒ–æ—¶å¹¶éæ‰€æœ‰å­—æ®µéƒ½æœ‰å€¼
- ä¸åŒèŠ‚ç‚¹è´Ÿè´£å¡«å……ä¸åŒå­—æ®µ
- Optional æ˜ç¡®è¡¨ç¤º"è¿™ä¸ªå­—æ®µå¯èƒ½ä¸ºç©º"

**æ‰§è¡Œæµç¨‹**ï¼š
```python
# æ­¥éª¤1: åˆå§‹åŒ–ï¼ˆåªæœ‰ questionï¼‰
state = {"question": "Pythonæ˜¯ä»€ä¹ˆï¼Ÿ", "retrieved_docs": None, "answer": None}

# æ­¥éª¤2: æ£€ç´¢èŠ‚ç‚¹å¡«å…… retrieved_docs
state["retrieved_docs"] = [doc1, doc2, doc3]

# æ­¥éª¤3: ç”ŸæˆèŠ‚ç‚¹å¡«å…… answer
state["answer"] = "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€..."
```

#### ç‰¹æ€§3ï¼šè‡ªåŠ¨åˆå¹¶æ›´æ–°

**èŠ‚ç‚¹å¯ä»¥è¿”å›éƒ¨åˆ†æ›´æ–°**ï¼š

```python
# æ–¹å¼1: è¿”å›å®Œæ•´ State
def node1(state: AgentState) -> AgentState:
    state["answer"] = "..."
    return state  # è¿”å›æ•´ä¸ª state

# æ–¹å¼2: åªè¿”å›æ›´æ–°çš„å­—æ®µï¼ˆæ¨èï¼‰
def node2(state: AgentState) -> dict:
    return {"answer": "..."}  # LangGraph ä¼šè‡ªåŠ¨åˆå¹¶åˆ° state ä¸­
```

**è‡ªåŠ¨åˆå¹¶ç¤ºä¾‹**ï¼š
```python
# å½“å‰ State
state = {
    "question": "Pythonæ˜¯ä»€ä¹ˆï¼Ÿ",
    "retrieved_docs": [doc1, doc2],
    "answer": None
}

# èŠ‚ç‚¹è¿”å›éƒ¨åˆ†æ›´æ–°
def generate_node(state):
    return {"answer": "Pythonæ˜¯..."}  # åªè¿”å› answer å­—æ®µ

# LangGraph è‡ªåŠ¨åˆå¹¶åçš„ State
state = {
    "question": "Pythonæ˜¯ä»€ä¹ˆï¼Ÿ",      # ä¿æŒä¸å˜
    "retrieved_docs": [doc1, doc2],   # ä¿æŒä¸å˜
    "answer": "Pythonæ˜¯..."           # æ›´æ–°äº†
}
```

---

## äºŒã€å­—æ®µè®¾è®¡åŸåˆ™

### 2.1 åˆ†ç±»åŸåˆ™

å°† State å­—æ®µæŒ‰åŠŸèƒ½åˆ†ç±»ï¼Œä¾¿äºç†è§£å’Œç»´æŠ¤ï¼š

```python
class AgentState(TypedDict):
    # ========== æ ¸å¿ƒå­—æ®µ ==========
    question: str                    # ç”¨æˆ·é—®é¢˜
    answer: Optional[str]             # æœ€ç»ˆç­”æ¡ˆ
    
    # ========== æ£€ç´¢ç›¸å…³ ==========
    retrieved_docs: Optional[List[Document]]  # æ£€ç´¢ç»“æœ
    retrieval_query: Optional[str]            # æ”¹å†™åçš„æŸ¥è¯¢
    retrieval_score: Optional[float]          # æ£€ç´¢è´¨é‡
    
    # ========== ç”Ÿæˆç›¸å…³ ==========
    intermediate_answer: Optional[str]        # ä¸­é—´ç­”æ¡ˆ
    confidence_score: Optional[float]         # ç­”æ¡ˆç½®ä¿¡åº¦
    
    # ========== å¯¹è¯ç®¡ç† ==========
    messages: List[BaseMessage]              # å¯¹è¯å†å²
    conversation_id: Optional[str]           # ä¼šè¯ID
    
    # ========== æ‰§è¡Œæ§åˆ¶ ==========
    step_count: int                          # å½“å‰æ­¥éª¤
    max_steps: int                           # æœ€å¤§æ­¥æ•°
    next_action: Optional[str]               # ä¸‹ä¸€æ­¥åŠ¨ä½œ
    
    # ========== å…ƒæ•°æ® ==========
    metadata: Dict[str, Any]                 # é¢å¤–ä¿¡æ¯
    error: Optional[str]                     # é”™è¯¯ä¿¡æ¯
```

**è®¾è®¡ç†å¿µ**ï¼š
- **æ ¸å¿ƒå­—æ®µ**ï¼šå¿…ä¸å¯å°‘çš„åŸºç¡€æ•°æ®
- **åŠŸèƒ½å­—æ®µ**ï¼šæŒ‰åŠŸèƒ½æ¨¡å—åˆ†ç»„ï¼ˆæ£€ç´¢ã€ç”Ÿæˆã€å¯¹è¯ç­‰ï¼‰
- **æ§åˆ¶å­—æ®µ**ï¼šç”¨äºæµç¨‹æ§åˆ¶å’Œå†³ç­–
- **å…ƒæ•°æ®å­—æ®µ**ï¼šè°ƒè¯•ã€ç›‘æ§ã€æ‰©å±•ç”¨

---

### 2.2 å‘½åè§„èŒƒ

#### è§„èŒƒ1ï¼šæè¿°æ€§å‘½å

```python
# âŒ ä¸å¥½çš„å‘½å
class AgentState(TypedDict):
    q: str          # å¤ªç®€çŸ­
    docs: List      # ä¸æ¸…æ¥šæ˜¯ä»€ä¹ˆæ–‡æ¡£
    ans: str        # ç¼©å†™ä¸æ¸…æ™°
    flag: bool      # ä»€ä¹ˆæ ‡å¿—ï¼Ÿ
    data: Any       # å¤ªæ¨¡ç³Š

# âœ… å¥½çš„å‘½å
class AgentState(TypedDict):
    question: str                      # æ¸…æ™°æ˜ç¡®
    retrieved_docs: List[Document]     # æè¿°æ€§å¼º
    answer: str                        # å®Œæ•´å•è¯
    need_more_context: bool            # å¸ƒå°”å€¼æè¿°æ¸…æ™°
    session_metadata: Dict[str, Any]   # æ˜ç¡®ç”¨é€”
```

#### è§„èŒƒ2ï¼šä¸€è‡´æ€§

```python
# âŒ ä¸ä¸€è‡´
class AgentState(TypedDict):
    question: str           # é—®é¢˜
    generatedAnswer: str    # é©¼å³°å‘½å
    Docs: List              # å¤§å†™å¼€å¤´
    retrieval_score: float  # ä¸‹åˆ’çº¿

# âœ… ä¸€è‡´
class AgentState(TypedDict):
    question: str           # ç»Ÿä¸€ä½¿ç”¨ä¸‹åˆ’çº¿å‘½å
    generated_answer: str
    retrieved_docs: List
    retrieval_score: float
```

#### è§„èŒƒ3ï¼šå¸ƒå°”å€¼å‘½å

```python
# âŒ ä¸æ¸…æ™°
class AgentState(TypedDict):
    debug: bool         # debug æ˜¯åè¯ï¼Œä¸æ¸…æ™°
    retrieve: bool      # retrieve æ˜¯åŠ¨è¯ï¼Œä¸æ¸…æ™°

# âœ… æ¸…æ™°
class AgentState(TypedDict):
    is_debug_mode: bool       # is_ å¼€å¤´ï¼Œæ¸…æ™°è¡¨ç¤ºå¸ƒå°”å€¼
    need_more_context: bool   # need_ å¼€å¤´
    has_error: bool           # has_ å¼€å¤´
```

---

### 2.3 ç±»å‹é€‰æ‹©

#### åŸºæœ¬ç±»å‹

```python
class AgentState(TypedDict):
    # å­—ç¬¦ä¸²
    question: str
    answer: Optional[str]
    
    # æ•°å­—
    step_count: int
    temperature: float
    retrieval_score: float
    
    # å¸ƒå°”å€¼
    debug_mode: bool
    need_more_context: bool
```

#### å¤æ‚ç±»å‹

```python
from typing import List, Dict, Any, Optional
from langchain.schema import Document, BaseMessage

class AgentState(TypedDict):
    # åˆ—è¡¨
    retrieved_docs: Optional[List[Document]]
    messages: List[BaseMessage]
    processing_log: List[str]
    
    # å­—å…¸
    metadata: Dict[str, Any]
    user_preferences: Dict[str, Any]
    statistics: Dict[str, int]
    
    # åµŒå¥—ç»“æ„
    tool_calls: Optional[List[Dict[str, Any]]]
```

#### è‡ªå®šä¹‰ç±»å‹

```python
from typing import Literal

class AgentState(TypedDict):
    # ä½¿ç”¨ Literal é™åˆ¶å–å€¼èŒƒå›´
    next_action: Literal["retrieve", "generate", "end"]
    language: Literal["zh-CN", "en-US", "ja-JP"]
    detail_level: Literal["brief", "detailed", "comprehensive"]
```

---

## ä¸‰ã€ä¸‰ä¸ªç‰ˆæœ¬çš„è®¾è®¡

### 3.1 åŸºç¡€ç‰ˆæœ¬ - AgentStateBasic

**è®¾è®¡ç›®æ ‡**ï¼šæœ€å°åŒ–ï¼ŒåªåŒ…å«æ ¸å¿ƒå­—æ®µ

```python
class AgentStateBasic(TypedDict):
    """åŸºç¡€ç‰ˆæœ¬ - é€‚åˆå­¦ä¹ """
    question: str                           # ç”¨æˆ·é—®é¢˜
    retrieved_docs: Optional[List[Document]]  # æ£€ç´¢ç»“æœ
    answer: Optional[str]                    # ç”Ÿæˆç­”æ¡ˆ
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… å­¦ä¹  LangGraph çš„ç¬¬ä¸€ä¸ª Agent
- âœ… ç®€å•çš„ RAG æµç¨‹ï¼ˆé—®é¢˜ â†’ æ£€ç´¢ â†’ ç”Ÿæˆï¼‰
- âœ… å¿«é€ŸåŸå‹å¼€å‘

**ä¼˜ç‚¹**ï¼š
- ç®€å•æ˜“æ‡‚ï¼Œé™ä½å­¦ä¹ æ›²çº¿
- å­—æ®µå°‘ï¼Œå®¹æ˜“ç†è§£æ•°æ®æµ
- é€‚åˆæ•™å­¦æ¼”ç¤º

**ç¼ºç‚¹**ï¼š
- åŠŸèƒ½æœ‰é™ï¼Œä¸æ”¯æŒå¤æ‚åœºæ™¯
- æ²¡æœ‰æ‰§è¡Œæ§åˆ¶ï¼Œæ— æ³•é˜²æ­¢æ— é™å¾ªç¯
- æ²¡æœ‰æ—¥å¿—ï¼Œéš¾ä»¥è°ƒè¯•

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
from src.agent.state import create_basic_state

# åˆ›å»ºåˆå§‹çŠ¶æ€
state = create_basic_state("Pythonæ˜¯ä»€ä¹ˆï¼Ÿ")

# æ£€ç´¢èŠ‚ç‚¹
state["retrieved_docs"] = [doc1, doc2]

# ç”ŸæˆèŠ‚ç‚¹
state["answer"] = "Pythonæ˜¯..."

# å®Œæˆ
print(state["answer"])
```

---

### 3.2 å¯¹è¯ç‰ˆæœ¬ - AgentStateConversational

**è®¾è®¡ç›®æ ‡**ï¼šæ”¯æŒå¤šè½®å¯¹è¯å’ŒæŸ¥è¯¢æ”¹å†™

```python
class AgentStateConversational(TypedDict):
    """å¯¹è¯ç‰ˆæœ¬ - é€‚åˆå®é™…åº”ç”¨"""
    # æ ¸å¿ƒå­—æ®µ
    question: str
    retrieved_docs: Optional[List[Document]]
    answer: Optional[str]
    
    # å¯¹è¯ç®¡ç†ï¼ˆæ–°å¢ï¼‰
    messages: List[BaseMessage]         # å¯¹è¯å†å²
    retrieval_query: Optional[str]      # æ”¹å†™åçš„æŸ¥è¯¢
    
    # æ‰§è¡Œæ§åˆ¶ï¼ˆæ–°å¢ï¼‰
    step_count: int                     # å½“å‰æ­¥éª¤
    max_steps: int                      # æœ€å¤§æ­¥æ•°
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… éœ€è¦å¤šè½®å¯¹è¯
- âœ… éœ€è¦ä»£è¯æ¶ˆè§£ï¼ˆ"å®ƒ"æŒ‡ä»£ä»€ä¹ˆï¼‰
- âœ… éœ€è¦æŸ¥è¯¢æ”¹å†™å’Œä¼˜åŒ–
- âœ… éœ€è¦æ‰§è¡Œæ­¥éª¤æ§åˆ¶

**æ–°å¢åŠŸèƒ½**ï¼š

1. **å¯¹è¯å†å²ç®¡ç†**ï¼š
```python
state["messages"] = [
    HumanMessage(content="Pythonæ˜¯ä»€ä¹ˆï¼Ÿ"),
    AIMessage(content="Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€..."),
    HumanMessage(content="å®ƒçš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ"),  # "å®ƒ"æŒ‡ Python
]
```

2. **æŸ¥è¯¢æ”¹å†™**ï¼š
```python
# ç”¨æˆ·é—®é¢˜åŒ…å«ä»£è¯
state["question"] = "å®ƒçš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ"

# æ”¹å†™èŠ‚ç‚¹è¿›è¡Œä»£è¯æ¶ˆè§£
state["retrieval_query"] = "Python çš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ"

# ä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢è¿›è¡Œæ£€ç´¢
docs = vectorstore.search(state["retrieval_query"])
```

3. **æ‰§è¡Œæ§åˆ¶**ï¼š
```python
def should_continue(state):
    """é˜²æ­¢æ— é™å¾ªç¯"""
    if state["step_count"] >= state["max_steps"]:
        return "end"
    return "continue"
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
from src.agent.state import create_conversational_state
from langchain.schema import HumanMessage, AIMessage

# ç¬¬ä¸€è½®å¯¹è¯
state = create_conversational_state("Pythonæ˜¯ä»€ä¹ˆï¼Ÿ", max_steps=5)
state = retrieve_node(state)
state = generate_node(state)

# ä¿å­˜å¯¹è¯å†å²
state["messages"].append(HumanMessage(content=state["question"]))
state["messages"].append(AIMessage(content=state["answer"]))

# ç¬¬äºŒè½®å¯¹è¯ï¼ˆåŒ…å«ä»£è¯ï¼‰
state["question"] = "å®ƒçš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ"
state["retrieval_query"] = "Pythonçš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ"  # ä»£è¯æ¶ˆè§£
state = retrieve_node(state)
state = generate_node(state)
```

---

### 3.3 å®Œæ•´ç‰ˆæœ¬ - AgentState

**è®¾è®¡ç›®æ ‡**ï¼šç”Ÿäº§çº§ï¼ŒåŒ…å«æ‰€æœ‰åŠŸèƒ½

```python
class AgentState(TypedDict):
    """å®Œæ•´ç‰ˆæœ¬ - ç”Ÿäº§ç¯å¢ƒ"""
    # æ ¸å¿ƒå­—æ®µï¼ˆ3ä¸ªï¼‰
    question: str
    answer: Optional[str]
    
    # æ£€ç´¢ç›¸å…³ï¼ˆ4ä¸ªï¼‰
    retrieved_docs: Optional[List[Document]]
    retrieval_query: Optional[str]
    retrieval_score: Optional[float]       # æ–°å¢ï¼šæ£€ç´¢è´¨é‡
    need_more_context: bool                # æ–°å¢ï¼šæ˜¯å¦éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡
    
    # ç”Ÿæˆç›¸å…³ï¼ˆ2ä¸ªï¼‰
    intermediate_answer: Optional[str]     # æ–°å¢ï¼šä¸­é—´ç­”æ¡ˆ
    confidence_score: Optional[float]      # æ–°å¢ï¼šç­”æ¡ˆç½®ä¿¡åº¦
    
    # å¯¹è¯ç®¡ç†ï¼ˆ2ä¸ªï¼‰
    messages: List[BaseMessage]
    conversation_id: Optional[str]         # æ–°å¢ï¼šä¼šè¯ID
    
    # æ‰§è¡Œæ§åˆ¶ï¼ˆ4ä¸ªï¼‰
    step_count: int
    max_steps: int
    current_node: Optional[str]            # æ–°å¢ï¼šå½“å‰èŠ‚ç‚¹
    next_action: Optional[str]             # æ–°å¢ï¼šä¸‹ä¸€æ­¥åŠ¨ä½œ
    
    # å·¥å…·è°ƒç”¨ï¼ˆ2ä¸ªï¼‰
    tool_calls: Optional[List[Dict[str, Any]]]   # æ–°å¢
    tool_results: Optional[List[Any]]            # æ–°å¢
    
    # å…ƒæ•°æ®ï¼ˆ2ä¸ªï¼‰
    metadata: Dict[str, Any]               # æ–°å¢
    error: Optional[str]                   # æ–°å¢
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- âœ… éœ€è¦è¯¦ç»†ç›‘æ§å’Œæ—¥å¿—
- âœ… å¤æ‚çš„å¤šæ­¥éª¤ Agent
- âœ… éœ€è¦å·¥å…·è°ƒç”¨å’Œå¤–éƒ¨é›†æˆ

**æ ¸å¿ƒåŠŸèƒ½è¯¦è§£**ï¼š

#### åŠŸèƒ½1ï¼šæ£€ç´¢è´¨é‡è¯„ä¼°

```python
def retrieve_node(state):
    docs = vectorstore.similarity_search(state["question"], k=4)
    
    # è®¡ç®—æ£€ç´¢è´¨é‡åˆ†æ•°
    scores = [doc.metadata.get("score", 0) for doc in docs]
    state["retrieval_score"] = sum(scores) / len(scores) if scores else 0
    
    # åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡
    state["need_more_context"] = state["retrieval_score"] < 0.6
    
    return state

def decide_node(state):
    """æ ¹æ®æ£€ç´¢è´¨é‡å†³å®šä¸‹ä¸€æ­¥"""
    if state["need_more_context"]:
        return "retrieve_more"  # é‡æ–°æ£€ç´¢æˆ–æ‰©å±•æŸ¥è¯¢
    else:
        return "generate"  # ç›´æ¥ç”Ÿæˆ
```

#### åŠŸèƒ½2ï¼šå¤šæ­¥æ¨ç†

```python
def generate_step1(state):
    """ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆåˆæ­¥ç­”æ¡ˆ"""
    state["intermediate_answer"] = llm.generate("ç®€è¦å›ç­”ï¼š" + state["question"])
    return state

def generate_step2(state):
    """ç¬¬äºŒæ­¥ï¼šåŸºäºåˆæ­¥ç­”æ¡ˆæ‰©å±•"""
    prompt = f"""
    åˆæ­¥ç­”æ¡ˆï¼š{state['intermediate_answer']}
    
    è¯·åŸºäºä»¥ä¸Šç­”æ¡ˆï¼Œç»“åˆä»¥ä¸‹æ–‡æ¡£è¿›è¡Œè¯¦ç»†æ‰©å±•ï¼š
    {state['retrieved_docs']}
    """
    state["answer"] = llm.generate(prompt)
    return state
```

#### åŠŸèƒ½3ï¼šå·¥å…·è°ƒç”¨

```python
def tool_node(state):
    """è°ƒç”¨å¤–éƒ¨å·¥å…·"""
    state["tool_calls"] = []
    state["tool_results"] = []
    
    # è°ƒç”¨ç½‘ç»œæœç´¢
    if "æœ€æ–°" in state["question"]:
        state["tool_calls"].append({
            "tool": "web_search",
            "query": state["question"],
            "timestamp": datetime.now()
        })
        result = web_search(state["question"])
        state["tool_results"].append(result)
    
    return state
```

#### åŠŸèƒ½4ï¼šé”™è¯¯å¤„ç†

```python
def safe_node(state):
    """å¸¦é”™è¯¯å¤„ç†çš„èŠ‚ç‚¹"""
    try:
        # æ‰§è¡Œä¸šåŠ¡é€»è¾‘
        state["answer"] = llm.generate(state["question"])
    except Exception as e:
        # è®°å½•é”™è¯¯
        state["error"] = f"ç”Ÿæˆå¤±è´¥: {str(e)}"
        state["next_action"] = "error_fallback"
    
    return state
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
from src.agent.state import create_initial_state

# åˆ›å»ºå®Œæ•´çŠ¶æ€
state = create_initial_state(
    question="RAGç³»ç»Ÿçš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
    max_steps=10,
    conversation_id="conv-20260113-001",
    metadata={
        "user_id": "user-123",
        "knowledge_base": "tech_kb",
        "language": "zh-CN"
    }
)

# æ‰§è¡Œ Agent
state = retrieve_node(state)
# retrieval_score: 0.85, need_more_context: False

state = generate_node(state)
# answer: "...", confidence_score: 0.92

# æŸ¥çœ‹æ‰§è¡Œç»“æœ
print(f"ç­”æ¡ˆ: {state['answer']}")
print(f"ç½®ä¿¡åº¦: {state['confidence_score']}")
print(f"æ‰§è¡Œæ­¥éª¤: {state['step_count']}")
```

---

## å››ã€å…³é”®å­—æ®µè¯¦è§£

### 4.1 æ ¸å¿ƒå­—æ®µ

#### question: str

**ä½œç”¨**ï¼šå­˜å‚¨ç”¨æˆ·çš„åŸå§‹é—®é¢˜

**ç‰¹ç‚¹**ï¼š
- å¿…å¡«å­—æ®µï¼ˆä¸æ˜¯ Optionalï¼‰
- åˆå§‹åŒ–æ—¶è®¾ç½®ï¼Œé€šå¸¸ä¸ä¿®æ”¹
- æ‰€æœ‰èŠ‚ç‚¹çš„èµ·ç‚¹

**ä½¿ç”¨åœºæ™¯**ï¼š
```python
# åˆå§‹åŒ–
state = {"question": "Pythonæ˜¯ä»€ä¹ˆï¼Ÿ", ...}

# åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨
def retrieve_node(state):
    query = state["question"]  # è¯»å–é—®é¢˜
    docs = vectorstore.search(query)
    return state

# ä¿æŒä¸å˜
# state["question"] åœ¨æ•´ä¸ªæ‰§è¡Œè¿‡ç¨‹ä¸­é€šå¸¸ä¸å˜
```

#### answer: Optional[str]

**ä½œç”¨**ï¼šå­˜å‚¨æœ€ç»ˆç”Ÿæˆçš„ç­”æ¡ˆ

**ç‰¹ç‚¹**ï¼š
- å¯é€‰å­—æ®µï¼ˆåˆå§‹åŒ–æ—¶ä¸º Noneï¼‰
- ç”±ç”ŸæˆèŠ‚ç‚¹å¡«å……
- æ˜¯ Agent çš„æœ€ç»ˆè¾“å‡º

**ä½¿ç”¨åœºæ™¯**ï¼š
```python
# åˆå§‹åŒ–
state = {"answer": None, ...}

# ç”ŸæˆèŠ‚ç‚¹å¡«å……
def generate_node(state):
    state["answer"] = llm.generate(prompt)
    return state

# è·å–ç»“æœ
final_answer = state["answer"]
```

**æ³¨æ„äº‹é¡¹**ï¼š
- å¦‚æœéœ€è¦å¤šæ­¥ç”Ÿæˆï¼Œä½¿ç”¨ `intermediate_answer` å­˜å‚¨ä¸­é—´ç»“æœ
- ç¡®ä¿ç”ŸæˆèŠ‚ç‚¹ä¸€å®šä¼šè®¾ç½® `answer`ï¼Œå¦åˆ™ä¸‹æ¸¸èŠ‚ç‚¹å¯èƒ½æŠ¥é”™

---

### 4.2 æ£€ç´¢ç›¸å…³å­—æ®µ

#### retrieved_docs: Optional[List[Document]]

**ä½œç”¨**ï¼šå­˜å‚¨ä»å‘é‡åº“æ£€ç´¢åˆ°çš„æ–‡æ¡£

**Document ç»“æ„**ï¼š
```python
from langchain.schema import Document

doc = Document(
    page_content="è¿™æ˜¯æ–‡æ¡£å†…å®¹...",
    metadata={
        "source": "python_intro.txt",
        "page": 1,
        "score": 0.95  # ç›¸ä¼¼åº¦åˆ†æ•°
    }
)
```

**ä½¿ç”¨åœºæ™¯**ï¼š
```python
# æ£€ç´¢èŠ‚ç‚¹å¡«å……
def retrieve_node(state):
    docs = vectorstore.similarity_search(
        state["question"],
        k=4
    )
    state["retrieved_docs"] = docs
    return state

# ç”ŸæˆèŠ‚ç‚¹ä½¿ç”¨
def generate_node(state):
    context = "\n\n".join([
        doc.page_content 
        for doc in state["retrieved_docs"]
    ])
    prompt = f"åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”ï¼š\n{context}\n\né—®é¢˜ï¼š{state['question']}"
    state["answer"] = llm.generate(prompt)
    return state
```

#### retrieval_query: Optional[str]

**ä½œç”¨**ï¼šå­˜å‚¨ç»è¿‡æ”¹å†™/ä¼˜åŒ–çš„æ£€ç´¢æŸ¥è¯¢

**åº”ç”¨åœºæ™¯**ï¼š

1. **ä»£è¯æ¶ˆè§£**ï¼š
```python
# åŸå§‹é—®é¢˜
state["question"] = "å®ƒçš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ"

# æ”¹å†™æŸ¥è¯¢ï¼ˆå°†"å®ƒ"æ›¿æ¢ä¸ºå…·ä½“å®ä½“ï¼‰
state["retrieval_query"] = "Pythonçš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ"

# ä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢æ£€ç´¢
docs = vectorstore.search(state["retrieval_query"])
```

2. **æŸ¥è¯¢æ‰©å±•**ï¼š
```python
# åŸå§‹é—®é¢˜
state["question"] = "RAG"

# æ‰©å±•æŸ¥è¯¢
state["retrieval_query"] = "RAG æ£€ç´¢å¢å¼ºç”Ÿæˆ åŸç† åº”ç”¨"
```

3. **æŸ¥è¯¢ç®€åŒ–**ï¼š
```python
# åŸå§‹é—®é¢˜
state["question"] = "è¯·ä½ è¯¦ç»†è§£é‡Šä¸€ä¸‹ Python è¿™é—¨éå¸¸æµè¡Œçš„ç¼–ç¨‹è¯­è¨€"

# ç®€åŒ–æŸ¥è¯¢
state["retrieval_query"] = "Python ç¼–ç¨‹è¯­è¨€"
```

#### retrieval_score: Optional[float]

**ä½œç”¨**ï¼šè¯„ä¼°æ£€ç´¢è´¨é‡ï¼ˆ0.0 - 1.0ï¼‰

**è®¡ç®—æ–¹æ³•**ï¼š
```python
def retrieve_node(state):
    docs = vectorstore.similarity_search_with_score(
        state["question"],
        k=4
    )
    
    # æ–¹æ³•1: å¹³å‡ç›¸ä¼¼åº¦åˆ†æ•°
    scores = [score for doc, score in docs]
    state["retrieval_score"] = sum(scores) / len(scores)
    
    # æ–¹æ³•2: æœ€é«˜åˆ†
    state["retrieval_score"] = max(scores)
    
    # æ–¹æ³•3: åŠ æƒå¹³å‡ï¼ˆç»™å‰é¢çš„æ–‡æ¡£æ›´é«˜æƒé‡ï¼‰
    weights = [1.0, 0.8, 0.6, 0.4]
    state["retrieval_score"] = sum(s * w for s, w in zip(scores, weights)) / sum(weights)
    
    return state
```

**ä½¿ç”¨åœºæ™¯**ï¼š
```python
def decide_node(state):
    """æ ¹æ®æ£€ç´¢è´¨é‡å†³ç­–"""
    if state["retrieval_score"] < 0.5:
        # æ£€ç´¢è´¨é‡å·®ï¼Œé‡æ–°æ£€ç´¢
        return "rewrite_and_retrieve"
    elif state["retrieval_score"] < 0.8:
        # æ£€ç´¢è´¨é‡ä¸€èˆ¬ï¼Œå¢åŠ æ£€ç´¢æ•°é‡
        return "retrieve_more"
    else:
        # æ£€ç´¢è´¨é‡å¥½ï¼Œç›´æ¥ç”Ÿæˆ
        return "generate"
```

#### need_more_context: bool

**ä½œç”¨**ï¼šæ ‡è®°æ˜¯å¦éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯

**è®¾ç½®é€»è¾‘**ï¼š
```python
def evaluate_retrieval(state):
    """è¯„ä¼°æ˜¯å¦éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡"""
    
    # æ¡ä»¶1: æ£€ç´¢è´¨é‡ä½
    if state["retrieval_score"] < 0.6:
        state["need_more_context"] = True
        return state
    
    # æ¡ä»¶2: æ–‡æ¡£æ•°é‡å°‘
    if len(state["retrieved_docs"]) < 3:
        state["need_more_context"] = True
        return state
    
    # æ¡ä»¶3: æ–‡æ¡£ç›¸å…³æ€§åˆ†æ•£
    scores = [doc.metadata.get("score", 0) for doc in state["retrieved_docs"]]
    if max(scores) - min(scores) > 0.3:  # åˆ†æ•°å·®è·å¤§
        state["need_more_context"] = True
        return state
    
    state["need_more_context"] = False
    return state
```

---

### 4.3 å¯¹è¯ç®¡ç†å­—æ®µ

#### messages: List[BaseMessage]

**ä½œç”¨**ï¼šå­˜å‚¨å®Œæ•´çš„å¯¹è¯å†å²

**Message ç±»å‹**ï¼š
```python
from langchain.schema import HumanMessage, AIMessage, SystemMessage

messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªhelpfulçš„åŠ©æ‰‹"),
    HumanMessage(content="Pythonæ˜¯ä»€ä¹ˆï¼Ÿ"),
    AIMessage(content="Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€..."),
    HumanMessage(content="å®ƒçš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ"),
    AIMessage(content="Pythonå¹¿æ³›åº”ç”¨äº...")
]
```

**ä½¿ç”¨åœºæ™¯**ï¼š

1. **ä¿å­˜å¯¹è¯å†å²**ï¼š
```python
def save_turn(state):
    """ä¿å­˜ä¸€è½®å¯¹è¯"""
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    state["messages"].append(
        HumanMessage(content=state["question"])
    )
    # æ·»åŠ AIå›å¤
    state["messages"].append(
        AIMessage(content=state["answer"])
    )
    return state
```

2. **ä¸Šä¸‹æ–‡ç†è§£**ï¼š
```python
def understand_context(state):
    """åˆ©ç”¨å†å²ç†è§£å½“å‰é—®é¢˜"""
    history = "\n".join([
        f"{'ç”¨æˆ·' if isinstance(msg, HumanMessage) else 'AI'}: {msg.content}"
        for msg in state["messages"][-4:]  # æœ€è¿‘2è½®å¯¹è¯
    ])
    
    prompt = f"""
    å¯¹è¯å†å²ï¼š
    {history}
    
    å½“å‰é—®é¢˜ï¼š{state['question']}
    
    è¯·ç†è§£å½“å‰é—®é¢˜çš„çœŸå®æ„å›¾ã€‚
    """
    return state
```

3. **ä»£è¯æ¶ˆè§£**ï¼š
```python
def resolve_pronouns(state):
    """ä»£è¯æ¶ˆè§£"""
    if "å®ƒ" in state["question"] or "ä»–" in state["question"]:
        # ä»å†å²ä¸­æ‰¾åˆ°æŒ‡ä»£å¯¹è±¡
        last_ai_msg = [msg for msg in state["messages"] if isinstance(msg, AIMessage)][-1]
        
        # æå–å®ä½“ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
        if "Python" in last_ai_msg.content:
            state["retrieval_query"] = state["question"].replace("å®ƒ", "Python")
    
    return state
```

---

### 4.4 æ‰§è¡Œæ§åˆ¶å­—æ®µ

#### step_count: int å’Œ max_steps: int

**ä½œç”¨**ï¼šæ§åˆ¶æ‰§è¡Œæ­¥éª¤ï¼Œé˜²æ­¢æ— é™å¾ªç¯

**ä½¿ç”¨æ¨¡å¼**ï¼š
```python
# åˆå§‹åŒ–
state = {
    "step_count": 0,
    "max_steps": 5
}

# æ¯ä¸ªèŠ‚ç‚¹å¢åŠ è®¡æ•°
def any_node(state):
    state["step_count"] += 1
    # ... ä¸šåŠ¡é€»è¾‘
    return state

# æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»ˆæ­¢
def should_continue(state):
    if state["step_count"] >= state["max_steps"]:
        print(f"âš ï¸ è¾¾åˆ°æœ€å¤§æ­¥æ•° {state['max_steps']}ï¼Œå¼ºåˆ¶ç»ˆæ­¢")
        return "end"
    
    if state["answer"] is not None:
        return "end"
    
    return "continue"
```

**ä¸ºä»€ä¹ˆéœ€è¦ï¼Ÿ**
- é˜²æ­¢å¾ªç¯æ¡ä»¶é”™è¯¯å¯¼è‡´çš„æ— é™å¾ªç¯
- ä¿æŠ¤ç³»ç»Ÿèµ„æº
- ç»™ç”¨æˆ·åˆç†çš„å“åº”æ—¶é—´

#### current_node: Optional[str]

**ä½œç”¨**ï¼šè®°å½•å½“å‰æ‰§è¡Œçš„èŠ‚ç‚¹ï¼ˆç”¨äºæ—¥å¿—å’Œè°ƒè¯•ï¼‰

**ä½¿ç”¨åœºæ™¯**ï¼š
```python
def retrieve_node(state):
    state["current_node"] = "retrieve"
    print(f"[{state['current_node']}] å¼€å§‹æ‰§è¡Œ...")
    
    # ... ä¸šåŠ¡é€»è¾‘
    
    print(f"[{state['current_node']}] æ‰§è¡Œå®Œæˆ")
    return state

# æ—¥å¿—è¾“å‡ºï¼š
# [retrieve] å¼€å§‹æ‰§è¡Œ...
# [retrieve] æ‰§è¡Œå®Œæˆ
# [generate] å¼€å§‹æ‰§è¡Œ...
# [generate] æ‰§è¡Œå®Œæˆ
```

**è°ƒè¯•ä»·å€¼**ï¼š
- å¿«é€Ÿå®šä½é”™è¯¯å‘ç”Ÿçš„èŠ‚ç‚¹
- ç†è§£æ‰§è¡Œæµç¨‹
- æ€§èƒ½åˆ†æï¼ˆè®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„è€—æ—¶ï¼‰

#### next_action: Optional[str]

**ä½œç”¨**ï¼šæŒ‡ç¤ºä¸‹ä¸€æ­¥åº”è¯¥æ‰§è¡Œçš„åŠ¨ä½œ

**ä½¿ç”¨åœºæ™¯**ï¼š
```python
def decide_node(state):
    """å†³ç­–èŠ‚ç‚¹"""
    
    # æ ¹æ®æ£€ç´¢è´¨é‡å†³å®š
    if state["retrieval_score"] < 0.5:
        state["next_action"] = "rewrite_query"
    elif state["need_more_context"]:
        state["next_action"] = "retrieve_more"
    elif state["retrieved_docs"] is None:
        state["next_action"] = "retrieve"
    else:
        state["next_action"] = "generate"
    
    return state

# åœ¨ Graph ä¸­ä½¿ç”¨
def route_next(state):
    """è·¯ç”±å‡½æ•°"""
    return state["next_action"]

graph.add_conditional_edges(
    "decide",
    route_next,
    {
        "rewrite_query": "rewrite",
        "retrieve_more": "retrieve",
        "retrieve": "retrieve",
        "generate": "generate"
    }
)
```

---

## äº”ã€æœ€ä½³å®è·µ

### 5.1 æ¸è¿›å¼è®¾è®¡

**åŸåˆ™**ï¼šä»ç®€å•å¼€å§‹ï¼Œé€æ­¥å¢åŠ å¤æ‚åº¦

```python
# ç¬¬1å¤©ï¼šä½¿ç”¨åŸºç¡€ç‰ˆæœ¬
from src.agent.state import AgentStateBasic

state = AgentStateBasic(
    question="...",
    retrieved_docs=None,
    answer=None
)

# ç¬¬2å¤©ï¼šå‡çº§åˆ°å¯¹è¯ç‰ˆæœ¬
from src.agent.state import AgentStateConversational

state = AgentStateConversational(
    question="...",
    retrieved_docs=None,
    answer=None,
    messages=[],  # æ–°å¢
    retrieval_query=None,
    step_count=0,
    max_steps=5
)

# ç¬¬3å¤©ï¼šä½¿ç”¨å®Œæ•´ç‰ˆæœ¬
from src.agent.state import AgentState

state = create_initial_state(
    question="...",
    max_steps=10,
    metadata={"user_id": "..."}
)
```

---

### 5.2 ä½¿ç”¨è¾…åŠ©å‡½æ•°

**ä¸è¦æ‰‹åŠ¨åˆ›å»º Stateï¼Œä½¿ç”¨è¾…åŠ©å‡½æ•°**ï¼š

```python
# âŒ æ‰‹åŠ¨åˆ›å»º - å®¹æ˜“é—æ¼å­—æ®µ
state = AgentState(
    question="...",
    answer=None,
    # ... è¿˜æœ‰16ä¸ªå­—æ®µï¼Œå®¹æ˜“é—æ¼
)

# âœ… ä½¿ç”¨è¾…åŠ©å‡½æ•° - ä¿è¯å®Œæ•´æ€§
state = create_initial_state(
    question="...",
    max_steps=5
)
# æ‰€æœ‰å­—æ®µéƒ½æœ‰æ­£ç¡®çš„é»˜è®¤å€¼
```

---

### 5.3 ç±»å‹æ³¨è§£

**åœ¨èŠ‚ç‚¹å‡½æ•°ä¸­ä½¿ç”¨ç±»å‹æ³¨è§£**ï¼š

```python
# âŒ æ²¡æœ‰ç±»å‹æ³¨è§£
def retrieve_node(state):
    # IDE ä¸çŸ¥é“ state çš„ç»“æ„
    docs = vectorstore.search(state["question"])  # æ²¡æœ‰è‡ªåŠ¨è¡¥å…¨
    state["retrieved_docs"] = docs
    return state

# âœ… æœ‰ç±»å‹æ³¨è§£
def retrieve_node(state: AgentState) -> AgentState:
    # IDE çŸ¥é“ state çš„ç»“æ„ï¼Œæä¾›è‡ªåŠ¨è¡¥å…¨
    docs = vectorstore.search(state["question"])  # æœ‰è‡ªåŠ¨è¡¥å…¨
    state["retrieved_docs"] = docs
    return state
```

---

### 5.4 æ—¥å¿—å’Œè°ƒè¯•

**æ·»åŠ æ—¥å¿—å­—æ®µä¾¿äºè°ƒè¯•**ï¼š

```python
class DebuggableState(AgentState):
    """å¸¦è°ƒè¯•åŠŸèƒ½çš„ State"""
    processing_log: List[str]  # å¤„ç†æ—¥å¿—
    node_timings: Dict[str, float]  # èŠ‚ç‚¹è€—æ—¶

def retrieve_node(state: DebuggableState) -> DebuggableState:
    import time
    start = time.time()
    
    # è®°å½•å¼€å§‹
    state["processing_log"].append("[retrieve] å¼€å§‹æ£€ç´¢")
    
    # ä¸šåŠ¡é€»è¾‘
    docs = vectorstore.search(state["question"])
    state["retrieved_docs"] = docs
    
    # è®°å½•ç»“æœ
    state["processing_log"].append(f"[retrieve] æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
    
    # è®°å½•è€—æ—¶
    elapsed = time.time() - start
    state["node_timings"]["retrieve"] = elapsed
    state["processing_log"].append(f"[retrieve] è€—æ—¶ {elapsed:.3f}s")
    
    return state
```

---

## å…­ã€å¸¸è§é—®é¢˜

### Q1: State ä¼šä¸ä¼šè¶Šæ¥è¶Šå¤§ï¼Œå ç”¨å¤ªå¤šå†…å­˜ï¼Ÿ

**A**: ä¸ä¼šã€‚æ¯æ¬¡å¯¹è¯éƒ½æ˜¯æ–°çš„ Stateï¼Œæ‰§è¡Œå®Œæ¯•åä¼šé‡Šæ”¾å†…å­˜ã€‚

```python
# æ¯æ¬¡å¯¹è¯ç‹¬ç«‹
state1 = create_initial_state("é—®é¢˜1")
result1 = graph.invoke(state1)
# state1 æ‰§è¡Œå®Œæ¯•ï¼Œå†…å­˜é‡Šæ”¾

state2 = create_initial_state("é—®é¢˜2")
result2 = graph.invoke(state2)
# æ–°çš„ state2ï¼Œä¸ä¼šç´¯ç§¯
```

---

### Q2: å¯ä»¥åœ¨ State ä¸­å­˜å‚¨ä»€ä¹ˆç±»å‹çš„æ•°æ®ï¼Ÿ

**A**: ç†è®ºä¸Šä»»ä½•ç±»å‹ï¼Œä½†å»ºè®®ï¼š

âœ… **æ¨è**ï¼š
- åŸºæœ¬ç±»å‹ï¼šstr, int, float, bool
- LangChain ç±»å‹ï¼šDocument, BaseMessage
- åˆ—è¡¨å’Œå­—å…¸
- åºåˆ—åŒ–å¯¹è±¡

âš ï¸ **é¿å…**ï¼š
- å¤§æ–‡ä»¶å†…å®¹ï¼ˆåº”å­˜å‚¨è·¯å¾„ï¼‰
- æ¨¡å‹å®ä¾‹ï¼ˆåº”åœ¨èŠ‚ç‚¹ä¸­åˆ›å»ºï¼‰
- ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡

---

### Q3: èŠ‚ç‚¹å¿…é¡»è¿”å›å®Œæ•´ State å—ï¼Ÿ

**A**: ä¸éœ€è¦ï¼Œå¯ä»¥åªè¿”å›æ›´æ–°çš„å­—æ®µã€‚

```python
# æ–¹å¼1: è¿”å›å®Œæ•´ State
def node1(state):
    state["answer"] = "..."
    return state

# æ–¹å¼2: åªè¿”å›æ›´æ–°éƒ¨åˆ†ï¼ˆLangGraph ä¼šè‡ªåŠ¨åˆå¹¶ï¼‰
def node2(state):
    return {"answer": "..."}
```

---

### Q4: å¦‚ä½•åœ¨ç°æœ‰ State ä¸­æ·»åŠ æ–°å­—æ®µï¼Ÿ

**A**: ä½¿ç”¨ Optional ä¿è¯å‘åå…¼å®¹ã€‚

```python
# åŸå§‹ State
class AgentState(TypedDict):
    question: str
    answer: Optional[str]

# æ·»åŠ æ–°å­—æ®µï¼ˆä½¿ç”¨ Optionalï¼‰
class AgentState(TypedDict):
    question: str
    answer: Optional[str]
    
    # æ–°å­—æ®µï¼ˆOptional ä¿è¯å…¼å®¹æ€§ï¼‰
    user_id: Optional[str]
    custom_field: Optional[Any]
```

---

## ä¸ƒã€æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **State æ˜¯ä»€ä¹ˆ**
   - LangGraph Agent çš„å…±äº«å·¥ä½œç©ºé—´
   - èŠ‚ç‚¹é—´çš„æ•°æ®æ€»çº¿
   - æ‰§è¡ŒçŠ¶æ€çš„è®°å½•å™¨

2. **ä¸ºä»€ä¹ˆéœ€è¦ State**
   - ç®€åŒ–èŠ‚ç‚¹é—´æ•°æ®ä¼ é€’
   - ä¾¿äºè¿½è¸ªæ‰§è¡ŒçŠ¶æ€
   - æ”¯æŒæ¡ä»¶åˆ†æ”¯å†³ç­–

3. **è®¾è®¡åŸåˆ™**
   - ä½¿ç”¨ TypedDict ä¿è¯ç±»å‹å®‰å…¨
   - ä½¿ç”¨ Optional è¡¨ç¤ºå¯é€‰å­—æ®µ
   - æŒ‰åŠŸèƒ½åˆ†ç±»ç»„ç»‡å­—æ®µ
   - éµå¾ªå‘½åè§„èŒƒ

4. **ä¸‰ä¸ªç‰ˆæœ¬**
   - åŸºç¡€ç‰ˆï¼šå­¦ä¹ å…¥é—¨
   - å¯¹è¯ç‰ˆï¼šå®é™…åº”ç”¨
   - å®Œæ•´ç‰ˆï¼šç”Ÿäº§ç¯å¢ƒ

5. **æœ€ä½³å®è·µ**
   - æ¸è¿›å¼è®¾è®¡
   - ä½¿ç”¨è¾…åŠ©å‡½æ•°
   - æ·»åŠ ç±»å‹æ³¨è§£
   - è®°å½•æ—¥å¿—è°ƒè¯•

### å­¦ä¹ æ£€æŸ¥æ¸…å•

å®Œæˆæœ¬æ–‡æ¡£å­¦ä¹ åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] ç†è§£ State åœ¨ LangGraph ä¸­çš„ä½œç”¨
- [ ] è§£é‡Šä¸ºä»€ä¹ˆä½¿ç”¨ TypedDict
- [ ] è®¾è®¡é€‚åˆè‡ªå·±é¡¹ç›®çš„ State ç»“æ„
- [ ] ç†è§£ä¸‰ä¸ªç‰ˆæœ¬çš„åŒºåˆ«å’Œé€‚ç”¨åœºæ™¯
- [ ] åœ¨èŠ‚ç‚¹ä¸­æ­£ç¡®è¯»å–å’Œä¿®æ”¹ State
- [ ] æ·»åŠ è‡ªå®šä¹‰å­—æ®µ
- [ ] ä½¿ç”¨æ—¥å¿—è¿½è¸ª State å˜åŒ–
- [ ] ç†è§£æ‰€æœ‰æ ¸å¿ƒå­—æ®µçš„ç”¨é€”

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**åˆ›å»ºæ—¥æœŸ**: 2026-01-13  
**é€‚ç”¨ç‰ˆæœ¬**: HuahuaChat é˜¶æ®µä¸‰
