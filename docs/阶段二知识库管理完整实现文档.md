# é˜¶æ®µäºŒï¼šçŸ¥è¯†åº“ç®¡ç†å®Œæ•´å®ç°æ–‡æ¡£

> **ä½œè€…**: AI Assistant  
> **æ—¥æœŸ**: 2026-01-09  
> **æ¨¡å—**: `src/knowledge_base/kb_manager.py`  
> **çŠ¶æ€**: âœ… å®Œæˆ

---

## ğŸ“‹ ç›®å½•

1. [å®ç°æ¦‚è¿°](#1-å®ç°æ¦‚è¿°)
2. [2.1 çŸ¥è¯†åº“åŸºç¡€åŠŸèƒ½](#2-21-çŸ¥è¯†åº“åŸºç¡€åŠŸèƒ½)
3. [2.2 çŸ¥è¯†åº“ç®¡ç†å™¨](#3-22-çŸ¥è¯†åº“ç®¡ç†å™¨)
4. [2.3 æ–‡æ¡£ç®¡ç†åŠŸèƒ½](#4-23-æ–‡æ¡£ç®¡ç†åŠŸèƒ½)
5. [2.4 æµ‹è¯•éªŒè¯](#5-24-æµ‹è¯•éªŒè¯)
6. [æ ¸å¿ƒæ¦‚å¿µè¯¦è§£](#6-æ ¸å¿ƒæ¦‚å¿µè¯¦è§£)
7. [å®æˆ˜ç¤ºä¾‹](#7-å®æˆ˜ç¤ºä¾‹)
8. [å¸¸è§é—®é¢˜](#8-å¸¸è§é—®é¢˜)
9. [æ€§èƒ½ä¼˜åŒ–å»ºè®®](#9-æ€§èƒ½ä¼˜åŒ–å»ºè®®)
10. [æ€»ç»“ä¸ä¸‹ä¸€æ­¥](#10-æ€»ç»“ä¸ä¸‹ä¸€æ­¥)

---

## 1. å®ç°æ¦‚è¿°

###  âœ… å·²å®Œæˆçš„åŠŸèƒ½

é˜¶æ®µäºŒå®Œæ•´å®ç°äº†çŸ¥è¯†åº“ç®¡ç†çš„æ‰€æœ‰åŠŸèƒ½ï¼š

| åˆ†ç±» | åŠŸèƒ½ | çŠ¶æ€ | æ–¹æ³• |
|------|------|------|------|
| **2.1 åŸºç¡€åŠŸèƒ½** | æ–‡æ¡£æ·»åŠ  | âœ… | `add_documents()` |
|  | æ–‡æ¡£æœç´¢ | âœ… | `search()` |
|  | çŸ¥è¯†åº“åˆ é™¤ | âœ… | `delete()` |
|  | æ–‡æ¡£è®¡æ•° | âœ… | `get_document_count()` |
| **2.2 ç®¡ç†å™¨** | åˆ›å»ºçŸ¥è¯†åº“ | âœ… | `create_kb()` |
|  | è·å–çŸ¥è¯†åº“ | âœ… | `get_kb()` |
|  | åˆ—å‡ºçŸ¥è¯†åº“ | âœ… | `list_kb()` |
|  | åˆ é™¤çŸ¥è¯†åº“ | âœ… | `delete_kb()` |
|  | çŸ¥è¯†åº“ä¿¡æ¯ | âœ… | `get_kb_info()` |
| **2.3 æ–‡æ¡£ç®¡ç†** | æ–‡æ¡£ç´¢å¼•ç»´æŠ¤ | âœ… | `_load_doc_index()`, `_save_doc_index()` |
|  | æ–‡ä»¶ä¸Šä¼  | âœ… | `upload_file()` |
|  | æ‰¹é‡ä¸Šä¼  | âœ… | `upload_directory()` |
|  | æ–‡æ¡£åˆ—è¡¨ | âœ… | `list_documents()` |
|  | æ–‡æ¡£ä¿¡æ¯ | âœ… | `get_document_info()` |
|  | æ–‡æ¡£åˆ é™¤ | âœ… | `delete_document()` |
|  | å‘é‡åº“é‡å»º | âœ… | `rebuild_vectorstore()` |
| **2.4 æµ‹è¯•** | å®Œæ•´æµ‹è¯•å¥—ä»¶ | âœ… | `test_document_management.py` |

### ğŸ“Š ä»£ç ç»Ÿè®¡

- **æ€»ä»£ç è¡Œæ•°**: ~800 è¡Œï¼ˆå«æ³¨é‡Šï¼‰
- **æ³¨é‡Šè¦†ç›–ç‡**: >50%
- **æ–¹æ³•æ•°é‡**: 17 ä¸ªæ ¸å¿ƒæ–¹æ³•
- **æµ‹è¯•ç”¨ä¾‹**: 6 ä¸ªå®Œæ•´æµ‹è¯•åœºæ™¯

---

## 2. 2.1 çŸ¥è¯†åº“åŸºç¡€åŠŸèƒ½

### 2.1.1 add_documents() - æ–‡æ¡£æ·»åŠ 

**åŠŸèƒ½**ï¼šå°†æ–‡æ¡£åˆ—è¡¨æ·»åŠ åˆ°çŸ¥è¯†åº“ï¼Œè‡ªåŠ¨è¿›è¡Œå‘é‡åŒ–å’Œç´¢å¼•æ›´æ–°ã€‚

**å®ç°è¦ç‚¹**ï¼š

```python
def add_documents(self, documents: List[Document]) -> int:
    # 1. æ·»åŠ åˆ°å‘é‡åº“ï¼ˆè‡ªåŠ¨å‘é‡åŒ–ï¼‰
    self.vectorstore.add_documents(documents)
    
    # 2. æŒä¹…åŒ–åˆ°ç£ç›˜
    self.vectorstore.persist()
    
    # 3. æ›´æ–°æ–‡æ¡£ç´¢å¼•
    # - æŒ‰ source åˆ†ç»„ç»Ÿè®¡
    # - æ›´æ–°æˆ–æ·»åŠ ç´¢å¼•è®°å½•
    # - ä¿å­˜åˆ° documents.json
    
    # 4. è¿”å›æ·»åŠ çš„æ–‡æ¡£æ•°
    return len(documents)
```

**å…³é”®æ”¹è¿›**ï¼š
- âœ… è‡ªåŠ¨ç»´æŠ¤æ–‡æ¡£ç´¢å¼•ï¼ˆJSON æ–‡ä»¶ï¼‰
- âœ… è®°å½•æ¯ä¸ªæ–‡æ¡£çš„å—æ•°é‡
- âœ… è®°å½•æ·»åŠ æ—¶é—´å’Œæ›´æ–°æ—¶é—´

### 2.1.2 search() - æ–‡æ¡£æœç´¢

**åŠŸèƒ½**ï¼šåœ¨çŸ¥è¯†åº“ä¸­è¿›è¡Œè¯­ä¹‰æœç´¢ã€‚

**å®ç°é€»è¾‘**ï¼š

```python
def search(self, query: str, k: int = 4) -> List[Document]:
    # 1. æ£€æŸ¥å‘é‡åº“æ˜¯å¦ä¸ºç©º
    if self.vectorstore.vectorstore is None:
        return []
    
    # 2. è°ƒç”¨å‘é‡å­˜å‚¨çš„ç›¸ä¼¼åº¦æœç´¢
    # - è‡ªåŠ¨å¯¹æŸ¥è¯¢è¿›è¡Œå‘é‡åŒ–
    # - è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    # - è¿”å›æœ€ç›¸ä¼¼çš„ k ä¸ªæ–‡æ¡£
    results = self.vectorstore.similarity_search(query, k=k)
    
    return results
```

### 2.1.3 delete() - çŸ¥è¯†åº“åˆ é™¤

**åŠŸèƒ½**ï¼šåˆ é™¤æ•´ä¸ªçŸ¥è¯†åº“ï¼ˆåŒ…æ‹¬å‘é‡åº“å’Œå­˜å‚¨ç›®å½•ï¼‰ã€‚

**å®ç°é€»è¾‘**ï¼š

```python
def delete(self):
    # 1. æ¸…ç©ºå‘é‡å­˜å‚¨ï¼ˆé‡Šæ”¾å†…å­˜ï¼‰
    self.vectorstore.delete()
    
    # 2. åˆ é™¤ç£ç›˜ä¸Šçš„å­˜å‚¨ç›®å½•
    if self.kb_path.exists():
        shutil.rmtree(self.kb_path)
```

---

## 3. 2.2 çŸ¥è¯†åº“ç®¡ç†å™¨

### 3.2.1 KnowledgeBaseManager æ¶æ„

```
KnowledgeBaseManager
â”œâ”€â”€ root_path: Path           # æ‰€æœ‰çŸ¥è¯†åº“çš„æ ¹ç›®å½•
â””â”€â”€ knowledge_bases: Dict     # {name: KnowledgeBase}

ç®¡ç†çš„çŸ¥è¯†åº“ï¼š
root_path/
â”œâ”€â”€ kb1/
â”‚   â”œâ”€â”€ documents.json        # æ–‡æ¡£ç´¢å¼•
â”‚   â””â”€â”€ faiss_index/          # å‘é‡ç´¢å¼•
â”œâ”€â”€ kb2/
â””â”€â”€ kb3/
```

### 3.2.2 create_kb() - åˆ›å»ºçŸ¥è¯†åº“

**åŠŸèƒ½**ï¼šåˆ›å»ºæ–°çš„çŸ¥è¯†åº“å®ä¾‹ã€‚

**å…³é”®é€»è¾‘**ï¼š

```python
def create_kb(self, name, vectorstore, embedding) -> KnowledgeBase:
    # âœ… é‡ç‚¹ï¼šæ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨
    if name in self.knowledge_bases:  # æ­£ç¡®çš„é€»è¾‘
        raise ValueError(f"çŸ¥è¯†åº“ '{name}' å·²å­˜åœ¨")
    
    # åˆ›å»ºçŸ¥è¯†åº“ç›®å½•
    kb_path = self.root_path / name
    kb_path.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»º KnowledgeBase å®ä¾‹
    kb = KnowledgeBase(name, vectorstore, embedding, kb_path)
    
    # æ·»åŠ åˆ°ç®¡ç†å­—å…¸
    self.knowledge_bases[name] = kb
    
    return kb
```

**ä¿®å¤çš„ Bug**ï¼š

```python
# âŒ é”™è¯¯çš„é€»è¾‘
if name not in self.knowledge_bases:
    raise ValueError(...)  # é€»è¾‘åäº†ï¼

# âœ… æ­£ç¡®çš„é€»è¾‘
if name in self.knowledge_bases:
    raise ValueError(...)
```

---

## 4. 2.3 æ–‡æ¡£ç®¡ç†åŠŸèƒ½

### 4.3.1 æ–‡æ¡£ç´¢å¼•è®¾è®¡

**ä¸ºä»€ä¹ˆéœ€è¦æ–‡æ¡£ç´¢å¼•ï¼Ÿ**

FAISS å‘é‡åº“åªå­˜å‚¨å‘é‡ï¼Œä¸æ–¹ä¾¿æŸ¥è¯¢æ–‡æ¡£åˆ—è¡¨ã€‚å› æ­¤æˆ‘ä»¬ç»´æŠ¤ä¸€ä¸ª JSON ç´¢å¼•æ–‡ä»¶ï¼š

```json
[
    {
        "source": "docs/python.pdf",
        "chunk_count": 15,
        "added_at": "2024-01-01T10:00:00",
        "updated_at": "2024-01-01T10:00:00"
    },
    {
        "source": "docs/javascript.txt",
        "chunk_count": 8,
        "added_at": "2024-01-01T11:00:00",
        "updated_at": "2024-01-01T11:00:00"
    }
]
```

**ç´¢å¼•æ“ä½œ**ï¼š

```python
# åŠ è½½ç´¢å¼•
def _load_doc_index(self) -> List[Dict]:
    if self.doc_index_file.exists():
        with open(self.doc_index_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

# ä¿å­˜ç´¢å¼•
def _save_doc_index(self):
    with open(self.doc_index_file, 'w', encoding='utf-8') as f:
        json.dump(self.documents_index, f, indent=2, ensure_ascii=False)
```

### 4.3.2 upload_file() - æ–‡ä»¶ä¸Šä¼ 

**åŠŸèƒ½**ï¼šä¸€ç«™å¼æ–‡ä»¶ä¸Šä¼ ï¼Œè‡ªåŠ¨å®ŒæˆåŠ è½½ã€åˆ‡åˆ†ã€å‘é‡åŒ–ã€‚

**å®Œæ•´æµç¨‹**ï¼š

```python
def upload_file(self, file_path, chunk_size=500, chunk_overlap=50):
    # æ­¥éª¤1: åŠ è½½æ–‡ä»¶
    # - æ ¹æ®æ‰©å±•åè‡ªåŠ¨é€‰æ‹©åŠ è½½å™¨ï¼ˆ.txt, .pdf, .mdï¼‰
    documents = DocumentLoaderFactory.load(file_path)
    
    # æ­¥éª¤2: åˆ‡åˆ†æ–‡æ¡£
    # - æ ¹æ®ç±»å‹é€‰æ‹©åˆ‡åˆ†å™¨ï¼ˆrecursive, chineseï¼‰
    # - é…ç½®å—å¤§å°å’Œé‡å 
    chunks = TextSplitterFactory.split(
        documents,
        splitter_type="recursive",
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap
    )
    
    # æ­¥éª¤3: æ·»åŠ åˆ°å‘é‡åº“
    # - è‡ªåŠ¨å‘é‡åŒ–
    # - æ›´æ–°ç´¢å¼•
    # - æŒä¹…åŒ–
    count = self.add_documents(chunks)
    
    return count
```

**æ”¯æŒçš„æ–‡ä»¶æ ¼å¼**ï¼š

| æ ¼å¼ | åŠ è½½å™¨ | è¯´æ˜ |
|------|--------|------|
| `.txt` | TextLoader | çº¯æ–‡æœ¬ï¼Œæ”¯æŒå¤šç§ç¼–ç  |
| `.pdf` | PDFLoader | PDF æ–‡æ¡£ï¼ŒæŒ‰é¡µåŠ è½½ |
| `.md`, `.markdown` | MarkdownLoader | Markdown æ–‡æ¡£ |

### 4.3.3 upload_directory() - æ‰¹é‡ä¸Šä¼ 

**åŠŸèƒ½**ï¼šæ‰¹é‡ä¸Šä¼ ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ã€‚

**ç‰¹æ€§**ï¼š

- âœ… æ”¯æŒé€’å½’éå†å­ç›®å½•
- âœ… æ”¯æŒæ–‡ä»¶æ‰©å±•åè¿‡æ»¤
- âœ… è¯¦ç»†çš„å¤„ç†ç»“æœç»Ÿè®¡
- âœ… é”™è¯¯å¤„ç†ï¼ˆå•ä¸ªæ–‡ä»¶å¤±è´¥ä¸å½±å“å…¶ä»–æ–‡ä»¶ï¼‰

**è¿”å›ç»“æœç¤ºä¾‹**ï¼š

```python
{
    'success': 3,
    'failed': 1,
    'total_chunks': 45,
    'files': [
        {'file': 'doc1.txt', 'status': 'success', 'chunks': 15},
        {'file': 'doc2.pdf', 'status': 'success', 'chunks': 20},
        {'file': 'doc3.txt', 'status': 'success', 'chunks': 10},
        {'file': 'doc4.txt', 'status': 'failed', 'error': '...'}
    ]
}
```

### 4.3.4 list_documents() - æ–‡æ¡£åˆ—è¡¨

**åŠŸèƒ½**ï¼šåˆ—å‡ºçŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£ä¿¡æ¯ã€‚

```python
def list_documents(self) -> List[Dict]:
    # ç›´æ¥è¿”å›æ–‡æ¡£ç´¢å¼•
    return self.documents_index.copy()
```

**è¿”å›ç¤ºä¾‹**ï¼š

```python
[
    {
        'source': 'docs/python.pdf',
        'chunk_count': 15,
        'added_at': '2024-01-01T10:00:00',
        'updated_at': '2024-01-01T10:00:00'
    },
    ...
]
```

### 4.3.5 delete_document() - æ–‡æ¡£åˆ é™¤

**åŠŸèƒ½**ï¼šåˆ é™¤æŒ‡å®šæ¥æºçš„æ–‡æ¡£ã€‚

**æŒ‘æˆ˜**ï¼šFAISS ä¸æ”¯æŒæŒ‰ ID åˆ é™¤å•ä¸ªæ–‡æ¡£ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šé‡å»ºå‘é‡åº“ï¼ˆæ’é™¤è¦åˆ é™¤çš„æ–‡æ¡£ï¼‰

```python
def delete_document(self, source):
    # 1. ä»ç´¢å¼•ä¸­ç§»é™¤
    self.documents_index = [
        d for d in self.documents_index if d['source'] != source
    ]
    
    # 2. å¦‚æœç´¢å¼•ä¸ºç©ºï¼Œæ¸…ç©ºå‘é‡åº“
    if not self.documents_index:
        self.vectorstore.delete()
        return
    
    # 3. å¦åˆ™ï¼Œé‡å»ºå‘é‡åº“ï¼ˆæ’é™¤è¯¥æ–‡æ¡£ï¼‰
    self.rebuild_vectorstore(exclude_sources=[source])
```

**æ³¨æ„**ï¼šæ­¤æ“ä½œæ¯”è¾ƒè€—æ—¶ï¼Œå› ä¸ºéœ€è¦é‡å»ºæ•´ä¸ªå‘é‡åº“ã€‚

### 4.3.6 rebuild_vectorstore() - å‘é‡åº“é‡å»º

**åŠŸèƒ½**ï¼šé‡å»ºæ•´ä¸ªå‘é‡åº“ã€‚

**ä½¿ç”¨åœºæ™¯**ï¼š

1. **æ›´æ¢ Embedding æ¨¡å‹**
   ```python
   new_embedding = OpenAIEmbedding(model_name="text-embedding-3-small")
   kb.rebuild_vectorstore(new_embedding=new_embedding)
   ```

2. **åˆ é™¤æ–‡æ¡£**
   ```python
   kb.rebuild_vectorstore(exclude_sources=["old_file.pdf"])
   ```

3. **å‘é‡åº“æŸåæ—¶æ¢å¤**
   ```python
   kb.rebuild_vectorstore()
   ```

**å®ç°æµç¨‹**ï¼š

```python
def rebuild_vectorstore(self, new_embedding=None, exclude_sources=None):
    # 1. ä¿å­˜åŸå§‹æ–‡æ¡£åˆ—è¡¨
    original_docs = self.documents_index.copy()
    
    # 2. è¿‡æ»¤è¦æ’é™¤çš„æ–‡æ¡£
    docs_to_rebuild = [
        d for d in original_docs 
        if d['source'] not in (exclude_sources or [])
    ]
    
    # 3. æ¸…ç©ºå‘é‡åº“
    self.vectorstore.delete()
    
    # 4. æ›´æ–° Embeddingï¼ˆå¦‚æœæä¾›ï¼‰
    if new_embedding:
        self.embedding = new_embedding
    
    # 5. é‡æ–°åŠ è½½å¹¶æ·»åŠ æ¯ä¸ªæ–‡æ¡£
    for doc_info in docs_to_rebuild:
        source = doc_info['source']
        # åŠ è½½æ–‡ä»¶
        documents = DocumentLoaderFactory.load(source)
        # åˆ‡åˆ†æ–‡æ¡£
        chunks = TextSplitterFactory.split(documents, ...)
        # æ·»åŠ åˆ°å‘é‡åº“
        self.add_documents(chunks)
```

---

## 5. 2.4 æµ‹è¯•éªŒè¯

### 5.4.1 æµ‹è¯•è¦†ç›–

åˆ›å»ºäº†å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ `examples/test_document_management.py`ï¼š

| æµ‹è¯• | è¦†ç›–åŠŸèƒ½ | çŠ¶æ€ |
|------|---------|------|
| test_document_upload | æ–‡ä»¶ä¸Šä¼ ã€ç´¢å¼•ç»´æŠ¤ã€æœç´¢ | âœ… |
| test_batch_upload | æ‰¹é‡ä¸Šä¼ ç›®å½•ã€é€’å½’éå† | âœ… |
| test_document_list | æ–‡æ¡£åˆ—è¡¨ã€æ–‡æ¡£ä¿¡æ¯è·å– | âœ… |
| test_document_delete | æ–‡æ¡£åˆ é™¤ã€å‘é‡åº“é‡å»º | âœ… |
| test_vectorstore_rebuild | å‘é‡åº“é‡å»ºã€æ–‡æ¡£æ’é™¤ | âœ… |
| test_kb_manager_integration | å¤šçŸ¥è¯†åº“ç®¡ç†ã€å®Œæ•´æµç¨‹ | âœ… |

### 5.4.2 æµ‹è¯•æ•°æ®

æµ‹è¯•è‡ªåŠ¨åˆ›å»ºä»¥ä¸‹æ–‡ä»¶ï¼š

```
test_data/doc_test/
â”œâ”€â”€ python_basics.txt      # Python åŸºç¡€æ•™ç¨‹
â”œâ”€â”€ javascript_intro.txt   # JavaScript ç®€ä»‹
â”œâ”€â”€ ai_overview.txt        # äººå·¥æ™ºèƒ½æ¦‚è¿°
â””â”€â”€ subdoc/
    â””â”€â”€ advanced_python.txt # Python é«˜çº§ç‰¹æ€§
```

### 5.4.3 è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•
python examples/test_document_management.py

# é¢„æœŸè¾“å‡ºï¼š
# ============================================================
# æ–‡æ¡£ç®¡ç†åŠŸèƒ½ - å®Œæ•´æµ‹è¯•å¥—ä»¶ï¼ˆ2.3 & 2.4ï¼‰
# ============================================================
# 
# æµ‹è¯• 1: æ–‡æ¡£ä¸Šä¼ åŠŸèƒ½
# [PASS]
# 
# ... (æ‰€æœ‰æµ‹è¯•)
# 
# é€šè¿‡: 6/6
# ğŸ‰ SUCCESS! æ‰€æœ‰æµ‹è¯•é€šè¿‡!
```

---

## 6. æ ¸å¿ƒæ¦‚å¿µè¯¦è§£

### 6.1 æ–‡æ¡£ç´¢å¼• vs å‘é‡ç´¢å¼•

| ç±»å‹ | å­˜å‚¨å†…å®¹ | ç”¨é€” | æ ¼å¼ |
|------|---------|------|------|
| **æ–‡æ¡£ç´¢å¼•** | æ–‡æ¡£å…ƒä¿¡æ¯ | æŸ¥è¯¢æ–‡æ¡£åˆ—è¡¨ã€ç»Ÿè®¡ä¿¡æ¯ | JSON æ–‡ä»¶ |
| **å‘é‡ç´¢å¼•** | æ–‡æ¡£å‘é‡ | è¯­ä¹‰æœç´¢ã€ç›¸ä¼¼åº¦è®¡ç®— | FAISS äºŒè¿›åˆ¶ |

**ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ä¸ªç´¢å¼•ï¼Ÿ**

- FAISS åªå­˜å‚¨å‘é‡ï¼Œä¸æ–¹ä¾¿æŸ¥è¯¢æ–‡æ¡£åˆ—è¡¨
- JSON ç´¢å¼•ä¾¿äºäººå·¥æŸ¥çœ‹å’Œç®¡ç†
- ä¸¤è€…é…åˆä½¿ç”¨ï¼Œæ—¢ä¿è¯æ€§èƒ½åˆæä¾›ä¾¿åˆ©

### 6.2 æ–‡æ¡£å—ï¼ˆChunkï¼‰ç®¡ç†

**é—®é¢˜**ï¼šä¸€ä¸ªæ–‡ä»¶å¯èƒ½è¢«åˆ‡åˆ†æˆå¤šä¸ªå—ï¼Œå¦‚ä½•ç®¡ç†ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼šåœ¨ç´¢å¼•ä¸­è®°å½• `chunk_count`

```python
# åŒä¸€ä¸ªæ–‡ä»¶çš„å¤šä¸ªå—å…±äº«ç›¸åŒçš„ source
documents = [
    Document(page_content="ç¬¬1å—", metadata={"source": "file.txt"}),
    Document(page_content="ç¬¬2å—", metadata={"source": "file.txt"}),
    Document(page_content="ç¬¬3å—", metadata={"source": "file.txt"}),
]

# ç´¢å¼•ä¸­è®°å½•ï¼š
{
    "source": "file.txt",
    "chunk_count": 3,  # 3ä¸ªå—
    ...
}
```

### 6.3 æ–‡æ¡£åˆ é™¤çš„æŒ‘æˆ˜

**é—®é¢˜**ï¼šFAISS ä¸æ”¯æŒæŒ‰ ID åˆ é™¤å•ä¸ªæ–‡æ¡£ã€‚

**æŠ€æœ¯å¯¹æ¯”**ï¼š

| å‘é‡åº“ | æ”¯æŒåˆ é™¤ | è¯´æ˜ |
|--------|---------|------|
| FAISS | âŒ ä¸æ”¯æŒ | åªèƒ½æ¸…ç©ºæ•´ä¸ªç´¢å¼• |
| Chroma | âœ… æ”¯æŒ | æ”¯æŒæŒ‰ ID åˆ é™¤ |
| Milvus | âœ… æ”¯æŒ | ä¼ä¸šçº§ï¼Œæ”¯æŒåˆ é™¤ |
| Pinecone | âœ… æ”¯æŒ | äº‘æœåŠ¡ï¼Œæ”¯æŒåˆ é™¤ |

**æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆ**ï¼šé‡å»ºå‘é‡åº“

```python
# åˆ é™¤æ–‡æ¡£ = é‡å»ºå‘é‡åº“ï¼ˆæ’é™¤è¯¥æ–‡æ¡£ï¼‰
def delete_document(self, source):
    # æ–¹æ¡ˆï¼š
    # 1. ä»ç´¢å¼•ä¸­ç§»é™¤
    # 2. é‡æ–°åŠ è½½å…¶ä»–æ–‡æ¡£
    # 3. é‡æ–°å‘é‡åŒ–å¹¶æ·»åŠ 
    self.rebuild_vectorstore(exclude_sources=[source])
```

**æ€§èƒ½è€ƒè™‘**ï¼š

- âœ… ä¼˜ç‚¹ï¼šç®€å•å¯é 
- âŒ ç¼ºç‚¹ï¼šè€—æ—¶ï¼ˆéœ€è¦é‡æ–°å‘é‡åŒ–æ‰€æœ‰æ–‡æ¡£ï¼‰
- ğŸ’¡ ä¼˜åŒ–ï¼šå¦‚æœåªæœ‰å°‘é‡æ–‡æ¡£ï¼Œæ€§èƒ½å¯æ¥å—

---

## 7. å®æˆ˜ç¤ºä¾‹

### 7.1 ç¤ºä¾‹1ï¼šæ„å»ºæŠ€æœ¯æ–‡æ¡£çŸ¥è¯†åº“

```python
from src.knowledge_base import KnowledgeBase
from src.core.embedding import OpenAIEmbedding
from src.core.vectorstore import FAISSVectorStore

# åˆ›å»ºçŸ¥è¯†åº“
embedding = OpenAIEmbedding(model_name="text-embedding-ada-002")
vectorstore = FAISSVectorStore(
    embedding=embedding,
    persist_directory="./data/tech_docs"
)
kb = KnowledgeBase("æŠ€æœ¯æ–‡æ¡£åº“", vectorstore, embedding)

# æ‰¹é‡ä¸Šä¼ æ–‡æ¡£ç›®å½•
result = kb.upload_directory(
    "./docs",
    file_extensions=['.txt', '.md', '.pdf'],
    chunk_size=500,
    chunk_overlap=50,
    recursive=True
)

print(f"æˆåŠŸä¸Šä¼ : {result['success']} ä¸ªæ–‡ä»¶")
print(f"æ€»æ–‡æ¡£å—: {result['total_chunks']}")

# æŸ¥çœ‹æ–‡æ¡£åˆ—è¡¨
docs = kb.list_documents()
for doc in docs:
    print(f"{doc['source']}: {doc['chunk_count']} å—")

# æœç´¢
results = kb.search("å¦‚ä½•ä½¿ç”¨ Python è£…é¥°å™¨ï¼Ÿ", k=3)
for i, result in enumerate(results, 1):
    print(f"{i}. {result.page_content[:100]}...")
```

### 7.2 ç¤ºä¾‹2ï¼šå¤šçŸ¥è¯†åº“ç®¡ç†

```python
from src.knowledge_base import KnowledgeBaseManager
from src.core.embedding import OpenAIEmbedding
from src.core.vectorstore import FAISSVectorStore

# åˆ›å»ºç®¡ç†å™¨
manager = KnowledgeBaseManager(root_path="./data/knowledge_bases")

# åˆ›å»ºå¤šä¸ªçŸ¥è¯†åº“
embedding = OpenAIEmbedding(model_name="text-embedding-ada-002")

# æŠ€æœ¯æ–‡æ¡£åº“
tech_vs = FAISSVectorStore(embedding=embedding, persist_directory="./data/kb_tech")
tech_kb = manager.create_kb("æŠ€æœ¯æ–‡æ¡£", tech_vs, embedding)
tech_kb.upload_directory("./docs/tech")

# äº§å“æ‰‹å†Œåº“
product_vs = FAISSVectorStore(embedding=embedding, persist_directory="./data/kb_product")
product_kb = manager.create_kb("äº§å“æ‰‹å†Œ", product_vs, embedding)
product_kb.upload_directory("./docs/products")

# åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†åº“
for kb_name in manager.list_kb():
    kb = manager.get_kb(kb_name)
    info = manager.get_kb_info(kb_name)
    print(f"{kb_name}: {info['document_count']} ä¸ªæ–‡æ¡£å—")

# åœ¨ä¸åŒçŸ¥è¯†åº“ä¸­æœç´¢
tech_results = tech_kb.search("Python è£…é¥°å™¨")
product_results = product_kb.search("äº§å“ä»·æ ¼")
```

### 7.3 ç¤ºä¾‹3ï¼šæ›´æ¢ Embedding æ¨¡å‹

```python
# åœºæ™¯ï¼šä» ada-002 å‡çº§åˆ° text-embedding-3-small

# 1. åˆ›å»ºæ–° Embedding
new_embedding = OpenAIEmbedding(model_name="text-embedding-3-small")

# 2. é‡å»ºå‘é‡åº“
kb.rebuild_vectorstore(new_embedding=new_embedding)

# 3. éªŒè¯
results = kb.search("æµ‹è¯•æŸ¥è¯¢")
print(f"ä½¿ç”¨æ–°æ¨¡å‹æœç´¢åˆ° {len(results)} ä¸ªç»“æœ")
```

### 7.4 ç¤ºä¾‹4ï¼šæ–‡æ¡£ç»´æŠ¤

```python
# æŸ¥çœ‹æ–‡æ¡£åˆ—è¡¨
docs = kb.list_documents()
for doc in docs:
    print(f"{doc['source']}: æ·»åŠ äº {doc['added_at']}")

# è·å–ç‰¹å®šæ–‡æ¡£ä¿¡æ¯
info = kb.get_document_info("docs/python.pdf")
if info:
    print(f"å—æ•°: {info['chunk_count']}")
    print(f"æœ€åæ›´æ–°: {info['updated_at']}")

# åˆ é™¤è¿‡æ—¶çš„æ–‡æ¡£
kb.delete_document("docs/old_version.pdf")

# é‡æ–°ä¸Šä¼ æ–°ç‰ˆæœ¬
kb.upload_file("docs/new_version.pdf")
```

---

## 8. å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆä¸Šä¼ æ–‡ä»¶æ¯”è¾ƒæ…¢ï¼Ÿ

**ç­”**ï¼šä¸Šä¼ æ–‡ä»¶åŒ…æ‹¬å¤šä¸ªè€—æ—¶æ­¥éª¤ï¼š
1. æ–‡ä»¶åŠ è½½ï¼ˆPDF è§£æè¾ƒæ…¢ï¼‰
2. æ–‡æœ¬åˆ‡åˆ†
3. å‘é‡åŒ–ï¼ˆè°ƒç”¨ APIï¼‰
4. FAISS ç´¢å¼•æ›´æ–°

**ä¼˜åŒ–å»ºè®®**ï¼š
- å‡å° `chunk_size`ï¼ˆä½†å¯èƒ½å½±å“è´¨é‡ï¼‰
- ä½¿ç”¨æœ¬åœ° Embedding æ¨¡å‹ï¼ˆOllamaï¼‰
- æ‰¹é‡å¤„ç†æ—¶ä½¿ç”¨å¹¶å‘

### Q2: æ–‡æ¡£åˆ é™¤ä¸ºä»€ä¹ˆè¿™ä¹ˆæ…¢ï¼Ÿ

**ç­”**ï¼šå› ä¸º FAISS ä¸æ”¯æŒåˆ é™¤ï¼Œéœ€è¦é‡å»ºæ•´ä¸ªå‘é‡åº“ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å¦‚æœç»å¸¸éœ€è¦åˆ é™¤ï¼Œè€ƒè™‘ä½¿ç”¨æ”¯æŒåˆ é™¤çš„å‘é‡åº“ï¼ˆChromaã€Milvusï¼‰
- æ‰¹é‡åˆ é™¤å¤šä¸ªæ–‡æ¡£ï¼Œä¸€æ¬¡æ€§é‡å»º
- å®šæœŸæ¸…ç†æ•´ä¸ªçŸ¥è¯†åº“å¹¶é‡æ–°å¯¼å…¥

### Q3: å¦‚ä½•å¤„ç†å¤§æ–‡ä»¶ï¼Ÿ

**ç­”**ï¼š
```python
# æ–¹æ³•1ï¼šå¢å¤§ chunk_size
kb.upload_file("large_file.pdf", chunk_size=1000)

# æ–¹æ³•2ï¼šæµå¼å¤„ç†ï¼ˆéœ€è¦è‡ªå·±å®ç°ï¼‰
# é€é¡µåŠ è½½å¤§æ–‡ä»¶ï¼Œé¿å…å†…å­˜æº¢å‡º
```

### Q4: æ–‡æ¡£ç´¢å¼•æŸåæ€ä¹ˆåŠï¼Ÿ

**ç­”**ï¼š
```python
# é‡å»ºæ–‡æ¡£ç´¢å¼•
# 1. å¤‡ä»½ documents.json
# 2. åˆ é™¤æ–‡ä»¶
# 3. é‡å»ºå‘é‡åº“ï¼ˆä¼šè‡ªåŠ¨é‡å»ºç´¢å¼•ï¼‰
kb.rebuild_vectorstore()
```

### Q5: å¦‚ä½•å¤‡ä»½çŸ¥è¯†åº“ï¼Ÿ

**ç­”**ï¼š
```python
import shutil

# å¤‡ä»½æ•´ä¸ªçŸ¥è¯†åº“ç›®å½•
source = "./data/knowledge_base/tech_docs"
backup = "./backups/tech_docs_20240101"
shutil.copytree(source, backup)

# æ¢å¤ï¼š
# 1. å¤åˆ¶å¤‡ä»½ç›®å½•
# 2. åˆ›å»º KnowledgeBase æŒ‡å‘è¯¥ç›®å½•
# 3. å‘é‡åº“ä¼šè‡ªåŠ¨åŠ è½½
```

---

## 9. æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 9.1 ä¸Šä¼ ä¼˜åŒ–

```python
# ä¼˜åŒ–1ï¼šä½¿ç”¨æœ¬åœ° Embedding
from src.core.embedding import OllamaEmbedding
embedding = OllamaEmbedding(model_name="nomic-embed-text")

# ä¼˜åŒ–2ï¼šè°ƒæ•´åˆ‡åˆ†å‚æ•°
kb.upload_file(
    "file.pdf",
    chunk_size=300,      # å‡å°å—å¤§å°ï¼ˆæ›´å¿«ä½†å¯èƒ½å½±å“è´¨é‡ï¼‰
    chunk_overlap=30
)

# ä¼˜åŒ–3ï¼šæ‰¹é‡ä¸Šä¼ æ—¶ä½¿ç”¨å¹¶å‘ï¼ˆéœ€è¦è‡ªå·±å®ç°ï¼‰
```

### 9.2 æœç´¢ä¼˜åŒ–

```python
# ä¼˜åŒ–1ï¼šå‡å°‘è¿”å›ç»“æœæ•°
results = kb.search(query, k=3)  # é»˜è®¤ 4ï¼Œå¯ä»¥å‡å°

# ä¼˜åŒ–2ï¼šç¼“å­˜å¸¸è§æŸ¥è¯¢ï¼ˆéœ€è¦è‡ªå·±å®ç°ï¼‰
cache = {}
if query in cache:
    return cache[query]
results = kb.search(query)
cache[query] = results
```

### 9.3 å­˜å‚¨ä¼˜åŒ–

```python
# ä¼˜åŒ–1ï¼šå®šæœŸæ¸…ç†ç´¢å¼•
# åˆ é™¤è¿‡æ—¶æ–‡æ¡£åï¼Œé‡å»ºå‘é‡åº“å¯ä»¥å‹ç¼©å­˜å‚¨

# ä¼˜åŒ–2ï¼šä½¿ç”¨æ›´å°çš„ Embedding æ¨¡å‹
# text-embedding-3-small (1536 ç»´) vs ada-002 (1536 ç»´)
# text-embedding-3-large (3072 ç»´) - è´¨é‡æ›´é«˜ä½†æ›´å¤§
```

---

## 10. æ€»ç»“ä¸ä¸‹ä¸€æ­¥

### 10.1 é˜¶æ®µäºŒå®Œæˆæ€»ç»“

âœ… **å·²å®Œæˆçš„å†…å®¹**ï¼š

1. **2.1 çŸ¥è¯†åº“åŸºç¡€åŠŸèƒ½**
   - âœ… æ–‡æ¡£æ·»åŠ ï¼ˆå«ç´¢å¼•ç»´æŠ¤ï¼‰
   - âœ… æ–‡æ¡£æœç´¢
   - âœ… çŸ¥è¯†åº“åˆ é™¤
   - âœ… æ–‡æ¡£è®¡æ•°

2. **2.2 çŸ¥è¯†åº“ç®¡ç†å™¨**
   - âœ… åˆ›å»ºçŸ¥è¯†åº“ï¼ˆä¿®å¤é€»è¾‘ Bugï¼‰
   - âœ… è·å–çŸ¥è¯†åº“
   - âœ… åˆ—å‡ºçŸ¥è¯†åº“
   - âœ… åˆ é™¤çŸ¥è¯†åº“
   - âœ… çŸ¥è¯†åº“ä¿¡æ¯

3. **2.3 æ–‡æ¡£ç®¡ç†åŠŸèƒ½**
   - âœ… æ–‡æ¡£ç´¢å¼•ç»´æŠ¤ï¼ˆJSONï¼‰
   - âœ… æ–‡ä»¶ä¸Šä¼ ï¼ˆæ”¯æŒ .txt, .pdf, .mdï¼‰
   - âœ… æ‰¹é‡ä¸Šä¼ ç›®å½•
   - âœ… æ–‡æ¡£åˆ—è¡¨æŸ¥è¯¢
   - âœ… æ–‡æ¡£ä¿¡æ¯è·å–
   - âœ… æ–‡æ¡£åˆ é™¤ï¼ˆå«é‡å»ºï¼‰
   - âœ… å‘é‡åº“é‡å»º

4. **2.4 æµ‹è¯•**
   - âœ… 6 ä¸ªå®Œæ•´æµ‹è¯•åœºæ™¯
   - âœ… è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•æ•°æ®
   - âœ… è‡ªåŠ¨æ¸…ç†æµ‹è¯•æ•°æ®

### 10.2 å…³é”®æˆå°±

1. **ä»£ç è´¨é‡**
   - âœ… 800+ è¡Œé«˜è´¨é‡ä»£ç 
   - âœ… 50%+ æ³¨é‡Šè¦†ç›–ç‡
   - âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†
   - âœ… è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²

2. **åŠŸèƒ½å®Œæ•´æ€§**
   - âœ… 17 ä¸ªæ ¸å¿ƒæ–¹æ³•
   - âœ… æ”¯æŒ 3 ç§æ–‡æ¡£æ ¼å¼
   - âœ… å®Œæ•´çš„æ–‡æ¡£ç”Ÿå‘½å‘¨æœŸç®¡ç†
   - âœ… å¤šçŸ¥è¯†åº“å¹¶è¡Œç®¡ç†

3. **å¯ç»´æŠ¤æ€§**
   - âœ… æ¸…æ™°çš„ä»£ç ç»“æ„
   - âœ… ç»Ÿä¸€çš„é”™è¯¯å¤„ç†
   - âœ… è¯¦ç»†çš„æ—¥å¿—è¾“å‡º
   - âœ… å®Œæ•´çš„æµ‹è¯•è¦†ç›–

### 10.3 ä¸‹ä¸€æ­¥ï¼šé˜¶æ®µä¸‰

æ ¹æ® TODO.mdï¼Œä¸‹ä¸€æ­¥æ˜¯ï¼š

**é˜¶æ®µä¸‰ï¼šWeb æ¥å£å¼€å‘ (Week 4)**

1. **3.1 API æ¥å£è®¾è®¡**
   - çŸ¥è¯†åº“ç®¡ç† API
   - æ–‡æ¡£ç®¡ç† API
   - é—®ç­” API

2. **3.2 FastAPI å®ç°**
   - è·¯ç”±è®¾è®¡
   - è¯·æ±‚éªŒè¯
   - é”™è¯¯å¤„ç†

3. **3.3 å‰ç«¯ç•Œé¢**
   - æ–‡ä»¶ä¸Šä¼ é¡µé¢
   - é—®ç­”ç•Œé¢
   - çŸ¥è¯†åº“ç®¡ç†é¡µé¢

---

## ğŸ‰ ç¥è´ºï¼

ä½ å·²ç»å®Œæˆäº†é˜¶æ®µäºŒçš„æ‰€æœ‰å†…å®¹ï¼

**ä½ ç°åœ¨æŒæ¡äº†**ï¼š
- âœ… çŸ¥è¯†åº“çš„å®Œæ•´ç®¡ç†
- âœ… æ–‡æ¡£çš„å¢åˆ æ”¹æŸ¥
- âœ… å‘é‡åº“çš„ç»´æŠ¤å’Œä¼˜åŒ–
- âœ… å¤šçŸ¥è¯†åº“çš„ååŒç®¡ç†

**ä»£ç ç»Ÿè®¡**ï¼š
- ğŸ“Š æ€»ä»£ç ï¼š~800 è¡Œ
- ğŸ“ æ–¹æ³•æ•°ï¼š17 ä¸ª
- âœ… æµ‹è¯•è¦†ç›–ï¼š6 ä¸ªåœºæ™¯
- ğŸ“š æ–‡æ¡£ï¼šè¯¦ç»†æ³¨é‡Š + å®ç°æ–‡æ¡£

ç»§ç»­åŠ æ²¹ï¼ğŸš€

