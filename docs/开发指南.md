# 开发指南

## 如何开始开发

### 第一步：理解项目结构

项目采用模块化设计，每个模块都有清晰的职责：

```
src/
├── core/           # 核心功能（LLM、Embedding、VectorStore、Chain）
├── knowledge_base/ # 知识库管理
├── agent/          # LangGraph Agent
└── api/            # API 接口（阶段四）
```

### 第二步：按照 TODO 列表逐步实现

**重要**：不要跳过基础步骤！每个阶段都是下一阶段的基础。

### 第三步：遇到问题时的调试方法

1. **打印中间结果**
   ```python
   # 在 RAG Chain 中
   print(f"检索到的文档: {relevant_docs}")
   print(f"组装的 Prompt: {prompt}")
   ```

2. **单独测试每个组件**
   ```python
   # 测试 Embedding
   embedding = OpenAIEmbedding(...)
   vector = embedding.embed_query("测试")
   print(f"向量维度: {len(vector)}")
   ```

3. **使用 LangSmith（如果可用）**
   - 设置环境变量：`LANGCHAIN_TRACING_V2=true`
   - 查看详细的执行链路

## 关键实现提示

### 1. RAG Chain 实现要点

```python
def query(self, question: str, k: int = 4) -> str:
    # 步骤1: 检索
    docs = self.vectorstore.similarity_search(question, k=k)
    
    # 步骤2: 组装上下文
    context = "\n\n".join([doc.page_content for doc in docs])
    
    # 步骤3: 组装 Prompt
    prompt = self.prompt_template.format(
        context=context,
        question=question
    )
    
    # 步骤4: 生成
    answer = self.llm.generate(prompt)
    return answer
```

### 2. LangGraph Agent 实现要点

```python
# 1. 定义状态
class AgentState(TypedDict):
    question: str
    retrieved_docs: List[Document]
    answer: str

# 2. 定义节点
def retrieve_node(state):
    # 检索逻辑
    return {"retrieved_docs": docs}

# 3. 构建图
graph = StateGraph(AgentState)
graph.add_node("retrieve", retrieve_node)
graph.add_node("generate", generate_node)
graph.add_edge("retrieve", "generate")
graph.add_edge("generate", END)
```

### 3. 常见问题解决

**问题1：向量检索不准确**
- 调整 `chunk_size` 和 `chunk_overlap`
- 尝试不同的文本切分策略
- 增加检索数量 `k`

**问题2：答案不相关**
- 优化 prompt 模板
- 检查检索到的文档质量
- 添加重排序（Reranker）

**问题3：Agent 卡住**
- 检查条件分支逻辑
- 确保有终止条件
- 添加最大步数限制

## 代码规范

1. **命名规范**
   - 类名：大驼峰（`BaseLLM`）
   - 函数名：小写下划线（`similarity_search`）
   - 常量：大写下划线（`DEFAULT_K`）

2. **注释规范**
   - 每个类和方法都要有 docstring
   - 复杂逻辑要有行内注释

3. **错误处理**
   - 使用 try-except 处理异常
   - 提供有意义的错误信息

## 测试建议

每个模块实现后，编写简单的测试：

```python
# test_rag_chain.py
def test_rag_chain():
    # 初始化
    llm = OpenAILLM(...)
    vectorstore = FAISSVectorStore(...)
    chain = RAGChain(llm, vectorstore)
    
    # 测试
    answer = chain.query("测试问题")
    assert len(answer) > 0
    print(f"答案: {answer}")
```

## 下一步

完成当前阶段后，查看 `TODO.md` 中的下一个任务。

记住：**理解比完成更重要**。如果某个概念不清楚，停下来学习，不要急于实现。

