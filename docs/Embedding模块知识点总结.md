# Embedding æ¨¡å—çŸ¥è¯†ç‚¹æ€»ç»“

## ä¸€ã€æ¨¡å—æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯ Embedding æ¨¡å—ï¼Ÿ

**Embeddingï¼ˆåµŒå…¥ï¼‰æ¨¡å—**æ˜¯é¡¹ç›®çš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ï¼Œè´Ÿè´£å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡ï¼Œå®ç°è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—å’Œå‘é‡æ£€ç´¢åŠŸèƒ½ã€‚

**æ ¸å¿ƒèŒè´£**ï¼š
- å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡ï¼ˆå‘é‡åŒ–ï¼‰
- æ”¯æŒæŸ¥è¯¢å‘é‡åŒ–å’Œæ–‡æ¡£æ‰¹é‡å‘é‡åŒ–
- ä¸ºå‘é‡å­˜å‚¨å’Œç›¸ä¼¼åº¦æ£€ç´¢æä¾›åŸºç¡€
- å°è£…ä¸åŒ Embedding æä¾›å•†çš„è°ƒç”¨æ¥å£

### 1.2 æ¨¡å—åœ¨é¡¹ç›®ä¸­çš„ä½ç½®

```
HuahuaChat/
â””â”€â”€ src/
    â””â”€â”€ core/
        â”œâ”€â”€ llm/          â† LLM æ¨¡å—ï¼ˆæ–‡æœ¬ç”Ÿæˆï¼‰
        â”œâ”€â”€ embedding/    â† Embedding æ¨¡å—ï¼ˆå‘é‡åŒ–ï¼‰
        â””â”€â”€ vectorstore/  â† å‘é‡å­˜å‚¨æ¨¡å—ï¼ˆä½¿ç”¨ Embeddingï¼‰
```

**åœ¨ RAG æµç¨‹ä¸­çš„ä½ç½®**ï¼š

```
æ–‡æ¡£ä¸Šä¼ 
  â†“
æ–‡æœ¬åˆ‡åˆ†
  â†“
Embedding å‘é‡åŒ– â†â”€â”€â”€ Embedding æ¨¡å—
  â†“
å­˜å‚¨åˆ°å‘é‡åº“
  â†“
ç”¨æˆ·é—®é¢˜
  â†“
Embedding å‘é‡åŒ– â†â”€â”€â”€ Embedding æ¨¡å—
  â†“
å‘é‡ç›¸ä¼¼åº¦æœç´¢
  â†“
æ£€ç´¢ç›¸å…³æ–‡æ¡£
  â†“
LLM ç”Ÿæˆç­”æ¡ˆ
```

### 1.3 åº”ç”¨åœºæ™¯

1. **æ–‡æ¡£å‘é‡åŒ–**ï¼šå°†çŸ¥è¯†åº“æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡ï¼Œå­˜å‚¨åˆ°å‘é‡åº“
2. **æŸ¥è¯¢å‘é‡åŒ–**ï¼šå°†ç”¨æˆ·é—®é¢˜è½¬æ¢ä¸ºå‘é‡ï¼Œç”¨äºç›¸ä¼¼åº¦æ£€ç´¢
3. **è¯­ä¹‰æœç´¢**ï¼šé€šè¿‡å‘é‡ç›¸ä¼¼åº¦æ‰¾åˆ°è¯­ä¹‰ç›¸å…³çš„æ–‡æ¡£
4. **æ¨èç³»ç»Ÿ**ï¼šåŸºäºå‘é‡ç›¸ä¼¼åº¦æ¨èç›¸å…³å†…å®¹
5. **æ–‡æœ¬èšç±»**ï¼šå°†ç›¸ä¼¼æ–‡æœ¬å½’ç±»

---

## äºŒã€æ ¸å¿ƒæ¦‚å¿µï¼šä»€ä¹ˆæ˜¯ Embeddingï¼Ÿ

### 2.1 Embedding çš„æœ¬è´¨

**Embeddingï¼ˆåµŒå…¥ï¼‰**æ˜¯å°†ç¦»æ•£çš„æ–‡æœ¬æ˜ å°„åˆ°è¿ç»­çš„é«˜ç»´å‘é‡ç©ºé—´çš„è¿‡ç¨‹ã€‚

**ç®€å•ç†è§£**ï¼š
```
æ–‡æœ¬ï¼ˆç¦»æ•£ï¼‰ â†’ Embedding æ¨¡å‹ â†’ å‘é‡ï¼ˆè¿ç»­ï¼‰
"ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ" â†’ [0.1, 0.3, -0.2, ..., 0.5] (1536ç»´)
```

**å…³é”®ç‰¹æ€§**ï¼š
- **è¯­ä¹‰ç›¸ä¼¼æ€§**ï¼šè¯­ä¹‰ç›¸ä¼¼çš„æ–‡æœ¬ï¼Œå‘é‡è·ç¦»æ›´è¿‘
- **é«˜ç»´è¡¨ç¤º**ï¼šé€šå¸¸å‡ ç™¾åˆ°å‡ åƒç»´ï¼ˆOpenAI ada-002 æ˜¯ 1536 ç»´ï¼‰
- **æ•°å€¼è¡¨ç¤º**ï¼šå‘é‡ä¸­çš„æ¯ä¸ªå€¼éƒ½æ˜¯æµ®ç‚¹æ•°

### 2.2 ä¸ºä»€ä¹ˆéœ€è¦ Embeddingï¼Ÿ

**ä¼ ç»Ÿæ–‡æœ¬åŒ¹é…çš„é—®é¢˜**ï¼š
- å…³é”®è¯åŒ¹é…ï¼šæ— æ³•ç†è§£è¯­ä¹‰
  - "Python æ˜¯ä»€ä¹ˆï¼Ÿ" å’Œ "ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ" å…³é”®è¯ç›¸åŒï¼Œä½†é¡ºåºä¸åŒ
  - "æ±½è½¦" å’Œ "è½¦è¾†" è¯­ä¹‰ç›¸åŒï¼Œä½†å­—é¢ä¸åŒ
- æ— æ³•å¤„ç†åŒä¹‰è¯ã€è¿‘ä¹‰è¯
- æ— æ³•ç†è§£ä¸Šä¸‹æ–‡

**Embedding çš„ä¼˜åŠ¿**ï¼š
- **è¯­ä¹‰ç†è§£**ï¼šç†è§£æ–‡æœ¬çš„è¯­ä¹‰ï¼Œä¸ä»…ä»…æ˜¯å­—é¢æ„æ€
- **ç›¸ä¼¼åº¦è®¡ç®—**ï¼šé€šè¿‡å‘é‡è·ç¦»è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šè€ƒè™‘è¯è¯­çš„ä¸Šä¸‹æ–‡å…³ç³»

**ç¤ºä¾‹**ï¼š
```python
# ä¼ ç»Ÿå…³é”®è¯åŒ¹é…
"Python æ˜¯ä»€ä¹ˆï¼Ÿ" vs "ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"  # å¯èƒ½åŒ¹é…åº¦ä½

# Embedding å‘é‡ç›¸ä¼¼åº¦
"Python æ˜¯ä»€ä¹ˆï¼Ÿ" çš„å‘é‡ vs "ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ" çš„å‘é‡  # ç›¸ä¼¼åº¦å¾ˆé«˜
```

### 2.3 å‘é‡ç›¸ä¼¼åº¦è®¡ç®—

**ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine Similarityï¼‰**ï¼š

```python
import numpy as np

def cosine_similarity(vec1, vec2):
    """
    è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
    
    å…¬å¼ï¼šcos(Î¸) = (AÂ·B) / (||A|| * ||B||)
    
    è¿”å›å€¼ï¼š-1 åˆ° 1 ä¹‹é—´
    - 1ï¼šå®Œå…¨ç›¸åŒ
    - 0ï¼šæ— å…³
    - -1ï¼šå®Œå…¨ç›¸å
    """
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    return dot_product / (norm1 * norm2)
```

**å®é™…åº”ç”¨**ï¼š
```python
# æŸ¥è¯¢å‘é‡
query_vec = embedding.embed_query("ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ")

# æ–‡æ¡£å‘é‡
doc1_vec = embedding.embed_query("Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€")
doc2_vec = embedding.embed_query("ä»Šå¤©å¤©æ°”çœŸå¥½")

# è®¡ç®—ç›¸ä¼¼åº¦
similarity1 = cosine_similarity(query_vec, doc1_vec)  # 0.85ï¼ˆé«˜ç›¸ä¼¼åº¦ï¼‰
similarity2 = cosine_similarity(query_vec, doc2_vec)  # 0.12ï¼ˆä½ç›¸ä¼¼åº¦ï¼‰

# æ ¹æ®ç›¸ä¼¼åº¦æ’åºï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£
```

---

## ä¸‰ã€æ¶æ„è®¾è®¡

### 3.1 ä¸ºä»€ä¹ˆéœ€è¦æŠ½è±¡æ¥å£ï¼Ÿ

**è®¾è®¡æ¨¡å¼**ï¼šç­–ç•¥æ¨¡å¼ï¼ˆStrategy Patternï¼‰+ é€‚é…å™¨æ¨¡å¼ï¼ˆAdapter Patternï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š**ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒå¤šç§å®ç°**

```python
# æŠ½è±¡æ¥å£
class BaseEmbedding(ABC):
    @abstractmethod
    def embed_query(self, text: str) -> List[float]:
        pass
    
    @abstractmethod
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        pass

# å…·ä½“å®ç°
class OpenAIEmbedding(BaseEmbedding):
    def embed_query(self, text: str) -> List[float]:
        # OpenAI çš„å®ç°
        pass

class OllamaEmbedding(BaseEmbedding):
    def embed_query(self, text: str) -> List[float]:
        # Ollama çš„å®ç°
        pass
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š

1. **å¯æ‰©å±•æ€§**ï¼šè½»æ¾æ·»åŠ æ–°çš„ Embedding æä¾›å•†
   ```python
   # æœªæ¥å¯ä»¥æ·»åŠ  HuggingFaceã€æœ¬åœ°æ¨¡å‹ç­‰
   class HuggingFaceEmbedding(BaseEmbedding):
       def embed_query(self, text: str) -> List[float]:
           # å®ç° HuggingFace çš„è°ƒç”¨
           pass
   ```

2. **å¯æµ‹è¯•æ€§**ï¼šå¯ä»¥åˆ›å»º Mock Embedding ç”¨äºæµ‹è¯•
   ```python
   class MockEmbedding(BaseEmbedding):
       def embed_query(self, text: str) -> List[float]:
           return [0.1] * 1536  # è¿”å›å›ºå®šå‘é‡
   ```

3. **ä»£ç è§£è€¦**ï¼šä¸Šå±‚ä»£ç ä¸ä¾èµ–å…·ä½“å®ç°
   ```python
   # VectorStore åªä¾èµ–æ¥å£
   class FAISSVectorStore:
       def __init__(self, embedding: BaseEmbedding):  # ä¾èµ–æŠ½è±¡
           self.embedding = embedding
       
       def add_documents(self, documents):
           # å¯ä»¥ä½¿ç”¨ä»»ä½•å®ç°äº† BaseEmbedding çš„ç±»
           vectors = self.embedding.embed_documents([doc.page_content for doc in documents])
   ```

4. **æ¥å£ç»Ÿä¸€**ï¼šä¸åŒæä¾›å•†çš„è°ƒç”¨æ–¹å¼ç»Ÿä¸€
   ```python
   # ä½¿ç”¨æ–¹å¼å®Œå…¨ä¸€è‡´
   openai_emb = OpenAIEmbedding(...)
   ollama_emb = OllamaEmbedding(...)
   
   # æ¥å£ç›¸åŒï¼Œå¯ä»¥äº’æ¢
   vector1 = openai_emb.embed_query("é—®é¢˜")
   vector2 = ollama_emb.embed_query("é—®é¢˜")
   ```

### 3.2 ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ä¸ªæ–¹æ³•ï¼Ÿ

**embed_query() å’Œ embed_documents() çš„åŒºåˆ«**ï¼š

| ç‰¹æ€§ | embed_query() | embed_documents() |
|------|--------------|-------------------|
| **è¾“å…¥** | å•ä¸ªå­—ç¬¦ä¸² | å­—ç¬¦ä¸²åˆ—è¡¨ |
| **è¾“å‡º** | `List[float]`ï¼ˆä¸€ä¸ªå‘é‡ï¼‰ | `List[List[float]]`ï¼ˆå‘é‡åˆ—è¡¨ï¼‰ |
| **ä½¿ç”¨åœºæ™¯** | ç”¨æˆ·æŸ¥è¯¢å‘é‡åŒ– | æ–‡æ¡£æ‰¹é‡å‘é‡åŒ– |
| **è°ƒç”¨é¢‘ç‡** | æ¯æ¬¡æŸ¥è¯¢è°ƒç”¨ä¸€æ¬¡ | æ–‡æ¡£å…¥åº“æ—¶æ‰¹é‡è°ƒç”¨ |
| **ä¼˜åŒ–æ–¹å‘** | é’ˆå¯¹æŸ¥è¯¢ä¼˜åŒ–ï¼ˆé€šå¸¸è¾ƒçŸ­ï¼‰ | é’ˆå¯¹æ–‡æ¡£ä¼˜åŒ–ï¼ˆå¯èƒ½è¾ƒé•¿ï¼‰ |

**ä¸ºä»€ä¹ˆåˆ†å¼€ï¼Ÿ**

1. **è¯­ä¹‰åŒºåˆ†**ï¼š
   - æŸ¥è¯¢é€šå¸¸æ˜¯é—®é¢˜ï¼Œè¾ƒçŸ­ï¼ˆå¦‚ "ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"ï¼‰
   - æ–‡æ¡£é€šå¸¸æ˜¯å†…å®¹ï¼Œè¾ƒé•¿ï¼ˆå¦‚ "Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€..."ï¼‰
   - æŸäº›æ¨¡å‹å¯¹ä¸¤è€…æœ‰ä¸åŒçš„å¤„ç†æ–¹å¼

2. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - `embed_documents()` å¯ä»¥æ‰¹é‡å¤„ç†ï¼Œæ•ˆç‡æ›´é«˜
   - `embed_query()` é’ˆå¯¹å•ä¸ªæŸ¥è¯¢ä¼˜åŒ–

3. **å®é™…ä½¿ç”¨åœºæ™¯**ï¼š
   ```python
   # æ–‡æ¡£å…¥åº“ï¼ˆæ‰¹é‡ï¼‰
   documents = ["æ–‡æ¡£1å†…å®¹", "æ–‡æ¡£2å†…å®¹", "æ–‡æ¡£3å†…å®¹"]
   doc_vectors = embedding.embed_documents(documents)  # ä¸€æ¬¡è°ƒç”¨ï¼Œæ‰¹é‡å¤„ç†
   # è¿”å›: [[0.1, 0.2, ...], [0.3, 0.1, ...], [0.2, 0.4, ...]]
   
   # ç”¨æˆ·æŸ¥è¯¢ï¼ˆå•ä¸ªï¼‰
   query = "ç”¨æˆ·çš„é—®é¢˜"
   query_vector = embedding.embed_query(query)  # å•ä¸ªæŸ¥è¯¢
   # è¿”å›: [0.15, 0.25, ...]
   ```

4. **API è®¾è®¡ä¸€è‡´æ€§**ï¼š
   - LangChain çš„ Embeddings æ¥å£å°±æ˜¯è¿™æ ·è®¾è®¡çš„
   - éµå¾ª LangChain çš„è®¾è®¡è§„èŒƒ

---

## å››ã€å®ç°ç»†èŠ‚è§£æ

### 4.1 BaseEmbedding æŠ½è±¡åŸºç±»

```python
from abc import ABC, abstractmethod
from typing import List

class BaseEmbedding(ABC):
    """Embedding åŸºç¡€æ¥å£"""
    
    def __init__(self, model_name: str):
        """
        åˆå§‹åŒ– Embedding æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
        """
        self.model_name = model_name
    
    @abstractmethod
    def embed_query(self, text: str) -> List[float]:
        """
        å¯¹å•ä¸ªæŸ¥è¯¢æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–
        
        Args:
            text: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            å‘é‡è¡¨ç¤º
        """
        pass
    
    @abstractmethod
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """
        å¯¹æ–‡æ¡£åˆ—è¡¨è¿›è¡Œå‘é‡åŒ–
        
        Args:
            texts: æ–‡æ¡£æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            å‘é‡åˆ—è¡¨
        """
        pass
```

**çŸ¥è¯†ç‚¹è§£æ**ï¼š

1. **ABC å’Œ @abstractmethod**ï¼š
   - å®šä¹‰æŠ½è±¡æ¥å£ï¼Œä¸èƒ½ç›´æ¥å®ä¾‹åŒ–
   - å¼ºåˆ¶å­ç±»å®ç°è¿™ä¸¤ä¸ªæ–¹æ³•
   - ç¡®ä¿æ¥å£ä¸€è‡´æ€§

2. **ç±»å‹æ³¨è§£**ï¼š
   - `text: str`ï¼šè¾“å…¥æ˜¯å­—ç¬¦ä¸²
   - `-> List[float]`ï¼šè¿”å›æµ®ç‚¹æ•°åˆ—è¡¨ï¼ˆä¸€ä¸ªå‘é‡ï¼‰
   - `-> List[List[float]]`ï¼šè¿”å›å‘é‡åˆ—è¡¨ï¼ˆå¤šä¸ªå‘é‡ï¼‰

3. **ä¸ºä»€ä¹ˆ model_name åœ¨åŸºç±»ä¸­ï¼Ÿ**
   - æ‰€æœ‰ Embedding å®ç°éƒ½éœ€è¦æ¨¡å‹åç§°
   - ç»Ÿä¸€ç®¡ç†ï¼Œä¾¿äºé…ç½®

### 4.2 OpenAIEmbedding å®ç°

#### 4.2.1 åˆå§‹åŒ–æ–¹æ³•

```python
class OpenAIEmbedding(BaseEmbedding):
    def __init__(self, model_name: str):
        super().__init__(model_name)
        
        api_key = os.getenv("OPENAI_API_KEY")
        
        self.embeddings = OpenAIEmbeddings(
            api_key=api_key,
            model=model_name
        )
```

**çŸ¥è¯†ç‚¹è§£æ**ï¼š

1. **super().__init__(model_name)**ï¼š
   - è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼Œè®¾ç½® `self.model_name`
   - Python ç»§æ‰¿çš„æ ‡å‡†åšæ³•

2. **os.getenv("OPENAI_API_KEY")**ï¼š
   - ä»ç¯å¢ƒå˜é‡è·å– API Key
   - å®‰å…¨åœ°å¤„ç†æ•æ„Ÿä¿¡æ¯
   - ä¸ç¡¬ç¼–ç åœ¨ä»£ç ä¸­

3. **OpenAIEmbeddings**ï¼š
   - LangChain æä¾›çš„ OpenAI Embedding å°è£…ç±»
   - å¤„ç† API è°ƒç”¨ã€é”™è¯¯é‡è¯•ç­‰ç»†èŠ‚
   - æä¾›ç»Ÿä¸€çš„æ¥å£ï¼ˆ`embed_query()`ã€`embed_documents()`ï¼‰

**ä¸ LLM æ¨¡å—çš„å¯¹æ¯”**ï¼š
- LLM ä½¿ç”¨ `ChatOpenAI`ï¼Œéœ€è¦æ¶ˆæ¯æ ¼å¼
- Embedding ä½¿ç”¨ `OpenAIEmbeddings`ï¼Œç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²
- Embedding æ›´ç®€å•ï¼Œä¸éœ€è¦æ¶ˆæ¯è½¬æ¢

#### 4.2.2 embed_query() æ–¹æ³•

```python
def embed_query(self, text: str) -> List[float]:
    """
    å¯¹å•ä¸ªæŸ¥è¯¢æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–
    
    Args:
        text: æŸ¥è¯¢æ–‡æœ¬
        
    Returns:
        å‘é‡è¡¨ç¤ºï¼ˆæµ®ç‚¹æ•°åˆ—è¡¨ï¼‰
    """
    try:
        vector = self.embeddings.embed_query(text)
        return vector
    except Exception as e:
        raise Exception(f"å‘é‡åŒ–æŸ¥è¯¢å¤±è´¥: {str(e)}") from e
```

**æµç¨‹è§£æ**ï¼š

1. **è¾“å…¥å¤„ç†**ï¼š
   ```python
   text: str  # ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²ï¼Œä¸éœ€è¦è½¬æ¢
   ```
   - ä¸ LLM ä¸åŒï¼Œä¸éœ€è¦ `HumanMessage`
   - ç›´æ¥ä¼ å…¥å­—ç¬¦ä¸²å³å¯

2. **è°ƒç”¨åº•å±‚æ–¹æ³•**ï¼š
   ```python
   vector = self.embeddings.embed_query(text)
   ```
   - `self.embeddings` æ˜¯ `OpenAIEmbeddings` å®ä¾‹
   - `embed_query()` æ˜¯ LangChain æä¾›çš„æ–¹æ³•
   - è¿”å› `List[float]`ï¼ˆä¸€ä¸ªå‘é‡ï¼‰

3. **è¿”å›ç»“æœ**ï¼š
   ```python
   return vector  # List[float]
   ```
   - ç›´æ¥è¿”å›å‘é‡ï¼Œä¸éœ€è¦æå–å±æ€§ï¼ˆä¸åƒ LLM éœ€è¦ `.content`ï¼‰
   - è¿”å›ç±»å‹æ˜¯ `List[float]`

4. **é”™è¯¯å¤„ç†**ï¼š
   ```python
   except Exception as e:
       raise Exception(f"å‘é‡åŒ–æŸ¥è¯¢å¤±è´¥: {str(e)}") from e
   ```
   - æ•è·æ‰€æœ‰å¼‚å¸¸
   - æä¾›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
   - `from e` ä¿ç•™åŸå§‹å¼‚å¸¸ä¿¡æ¯

**å®é™…ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
embedding = OpenAIEmbedding(model_name="text-embedding-ada-002")
query = "ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"
vector = embedding.embed_query(query)

print(f"å‘é‡ç»´åº¦: {len(vector)}")  # 1536
print(f"å‘é‡ç±»å‹: {type(vector)}")  # <class 'list'>
print(f"å…ƒç´ ç±»å‹: {type(vector[0])}")  # <class 'float'>
```

#### 4.2.3 embed_documents() æ–¹æ³•

```python
def embed_documents(self, texts: List[str]) -> List[List[float]]:
    """
    å¯¹æ–‡æ¡£åˆ—è¡¨è¿›è¡Œå‘é‡åŒ–
    
    Args:
        texts: æ–‡æ¡£æ–‡æœ¬åˆ—è¡¨
        
    Returns:
        å‘é‡åˆ—è¡¨ï¼ˆæ¯ä¸ªæ–‡æ¡£å¯¹åº”ä¸€ä¸ªå‘é‡ï¼‰
    """
    try:
        vectors = self.embeddings.embed_documents(texts)
        return vectors
    except Exception as e:
        raise Exception(f"å‘é‡åŒ–æ–‡æ¡£å¤±è´¥: {str(e)}") from e
```

**æµç¨‹è§£æ**ï¼š

1. **è¾“å…¥å¤„ç†**ï¼š
   ```python
   texts: List[str]  # å­—ç¬¦ä¸²åˆ—è¡¨
   ```
   - æ¥å—å¤šä¸ªæ–‡æ¡£
   - æ‰¹é‡å¤„ç†ï¼Œæ•ˆç‡æ›´é«˜

2. **è°ƒç”¨åº•å±‚æ–¹æ³•**ï¼š
   ```python
   vectors = self.embeddings.embed_documents(texts)
   ```
   - `embed_documents()` æ‰¹é‡å¤„ç†
   - è¿”å› `List[List[float]]`ï¼ˆå‘é‡åˆ—è¡¨ï¼‰

3. **è¿”å›ç»“æœ**ï¼š
   ```python
   return vectors  # List[List[float]]
   ```
   - è¿”å›ç±»å‹æ˜¯ `List[List[float]]`ï¼ˆåˆ—è¡¨çš„åˆ—è¡¨ï¼‰
   - å¤–å±‚åˆ—è¡¨ï¼šæ–‡æ¡£æ•°é‡
   - å†…å±‚åˆ—è¡¨ï¼šæ¯ä¸ªæ–‡æ¡£çš„å‘é‡

**å®é™…ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
embedding = OpenAIEmbedding(model_name="text-embedding-ada-002")
documents = [
    "Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€",
    "Java æ˜¯ä¸€ç§é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€",
    "ä»Šå¤©å¤©æ°”çœŸå¥½"
]
vectors = embedding.embed_documents(documents)

print(f"æ–‡æ¡£æ•°é‡: {len(vectors)}")  # 3
print(f"æ¯ä¸ªå‘é‡ç»´åº¦: {len(vectors[0])}")  # 1536
print(f"è¿”å›ç±»å‹: {type(vectors)}")  # <class 'list'>
print(f"ç¬¬ä¸€ä¸ªå‘é‡ç±»å‹: {type(vectors[0])}")  # <class 'list'>
```

**ç†è§£åµŒå¥—åˆ—è¡¨**ï¼š
```python
vectors = [
    [0.1, 0.2, 0.3, ...],  # æ–‡æ¡£1çš„å‘é‡ï¼ˆ1536ç»´ï¼‰
    [0.4, 0.5, 0.6, ...],  # æ–‡æ¡£2çš„å‘é‡ï¼ˆ1536ç»´ï¼‰
    [0.7, 0.8, 0.9, ...]   # æ–‡æ¡£3çš„å‘é‡ï¼ˆ1536ç»´ï¼‰
]

# è®¿é—®æ–¹å¼
print(vectors[0])      # ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å‘é‡
print(vectors[0][0])    # ç¬¬ä¸€ä¸ªæ–‡æ¡£å‘é‡çš„ç¬¬ä¸€ä¸ªå…ƒç´ 
```

### 4.3 ä¸ LLM æ¨¡å—çš„å¯¹æ¯”

**å…³é”®åŒºåˆ«**ï¼š

| ç‰¹æ€§ | LLM æ¨¡å— | Embedding æ¨¡å— |
|------|---------|---------------|
| **è¾“å…¥æ ¼å¼** | éœ€è¦ `HumanMessage` | ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸² |
| **è¾“å‡ºæ ¼å¼** | `AIMessage` å¯¹è±¡ï¼Œéœ€è¦æå– `.content` | ç›´æ¥è¿”å›å‘é‡ |
| **è°ƒç”¨æ–¹å¼** | `invoke()` / `stream()` | `embed_query()` / `embed_documents()` |
| **è¿”å›ç±»å‹** | `str`ï¼ˆå­—ç¬¦ä¸²ï¼‰ | `List[float]` æˆ– `List[List[float]]` |
| **åº”ç”¨åœºæ™¯** | æ–‡æœ¬ç”Ÿæˆ | å‘é‡åŒ– |
| **å¤æ‚åº¦** | è¾ƒå¤æ‚ï¼ˆæ¶ˆæ¯æ ¼å¼ï¼‰ | è¾ƒç®€å•ï¼ˆç›´æ¥å­—ç¬¦ä¸²ï¼‰ |

**ä»£ç å¯¹æ¯”**ï¼š

```python
# LLM æ¨¡å—
message = HumanMessage(content=prompt)
messages = [message]
response = llm.invoke(messages)
answer = response.content  # éœ€è¦æå– content

# Embedding æ¨¡å—
vector = embedding.embed_query(text)  # ç›´æ¥è¿”å›å‘é‡
```

---

## äº”ã€å‘é‡å’Œç›¸ä¼¼åº¦è®¡ç®—

### 5.1 å‘é‡çš„æœ¬è´¨

**å‘é‡ï¼ˆVectorï¼‰**æ˜¯ä¸€ç»„æœ‰åºçš„æ•°å€¼ï¼Œè¡¨ç¤ºæ–‡æœ¬åœ¨é«˜ç»´ç©ºé—´ä¸­çš„ä½ç½®ã€‚

**ç¤ºä¾‹**ï¼š
```python
# æ–‡æœ¬ï¼š"ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"
vector = [0.1, 0.3, -0.2, 0.5, ..., 0.2]  # 1536 ä¸ªæµ®ç‚¹æ•°

# å‘é‡çš„ç‰¹æ€§
print(len(vector))        # 1536ï¼ˆç»´åº¦ï¼‰
print(type(vector))       # <class 'list'>
print(type(vector[0]))    # <class 'float'>
print(vector[:5])         # [0.1, 0.3, -0.2, 0.5, 0.1]
```

**ä¸ºä»€ä¹ˆæ˜¯æµ®ç‚¹æ•°ï¼Ÿ**
- æµ®ç‚¹æ•°å¯ä»¥è¡¨ç¤ºå°æ•°å€¼
- å‘é‡è®¡ç®—éœ€è¦ç²¾ç¡®çš„æ•°å€¼
- ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆå¦‚ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰éœ€è¦æµ®ç‚¹æ•°

**ä¸ºä»€ä¹ˆç»´åº¦è¿™ä¹ˆé«˜ï¼Ÿ**
- é«˜ç»´ç©ºé—´å¯ä»¥æ›´å¥½åœ°è¡¨ç¤ºè¯­ä¹‰ä¿¡æ¯
- æ¯ä¸ªç»´åº¦å¯èƒ½ä»£è¡¨æŸç§è¯­ä¹‰ç‰¹å¾
- ç»´åº¦è¶Šé«˜ï¼Œè¡¨è¾¾èƒ½åŠ›è¶Šå¼ºï¼ˆä½†ä¹Ÿè¶Šå¤æ‚ï¼‰

### 5.2 å‘é‡ç›¸ä¼¼åº¦è®¡ç®—

**ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine Similarityï¼‰**ï¼š

```python
import numpy as np

def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
    
    å…¬å¼ï¼šcos(Î¸) = (AÂ·B) / (||A|| * ||B||)
    
    å…¶ä¸­ï¼š
    - AÂ·Bï¼šå‘é‡ç‚¹ç§¯
    - ||A||ï¼šå‘é‡Açš„æ¨¡ï¼ˆé•¿åº¦ï¼‰
    - ||B||ï¼šå‘é‡Bçš„æ¨¡ï¼ˆé•¿åº¦ï¼‰
    
    è¿”å›å€¼ï¼š-1 åˆ° 1 ä¹‹é—´
    - 1ï¼šå®Œå…¨ç›¸åŒï¼ˆè§’åº¦ä¸º0ï¼‰
    - 0ï¼šæ­£äº¤ï¼ˆè§’åº¦ä¸º90åº¦ï¼‰
    - -1ï¼šå®Œå…¨ç›¸åï¼ˆè§’åº¦ä¸º180åº¦ï¼‰
    """
    vec1_array = np.array(vec1)
    vec2_array = np.array(vec2)
    
    # è®¡ç®—ç‚¹ç§¯
    dot_product = np.dot(vec1_array, vec2_array)
    
    # è®¡ç®—æ¨¡
    norm1 = np.linalg.norm(vec1_array)
    norm2 = np.linalg.norm(vec2_array)
    
    # é¿å…é™¤é›¶
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    return dot_product / (norm1 * norm2)
```

**å®é™…åº”ç”¨**ï¼š
```python
# æŸ¥è¯¢å‘é‡
query = "ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"
query_vec = embedding.embed_query(query)

# æ–‡æ¡£å‘é‡
doc1 = "Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€"
doc2 = "ä»Šå¤©å¤©æ°”çœŸå¥½"

doc1_vec = embedding.embed_query(doc1)
doc2_vec = embedding.embed_query(doc2)

# è®¡ç®—ç›¸ä¼¼åº¦
similarity1 = cosine_similarity(query_vec, doc1_vec)  # 0.85ï¼ˆé«˜ç›¸ä¼¼åº¦ï¼‰
similarity2 = cosine_similarity(query_vec, doc2_vec)  # 0.12ï¼ˆä½ç›¸ä¼¼åº¦ï¼‰

print(f"æŸ¥è¯¢ä¸æ–‡æ¡£1çš„ç›¸ä¼¼åº¦: {similarity1:.4f}")  # 0.8500
print(f"æŸ¥è¯¢ä¸æ–‡æ¡£2çš„ç›¸ä¼¼åº¦: {similarity2:.4f}")  # 0.1200

# æ ¹æ®ç›¸ä¼¼åº¦æ’åºï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£
if similarity1 > similarity2:
    print("æ–‡æ¡£1æ›´ç›¸å…³")
```

**ä¸ºä»€ä¹ˆä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Ÿ**
- **å½’ä¸€åŒ–**ï¼šä¸å—å‘é‡é•¿åº¦å½±å“ï¼Œåªå…³æ³¨æ–¹å‘
- **èŒƒå›´å›ºå®š**ï¼šç»“æœåœ¨ -1 åˆ° 1 ä¹‹é—´ï¼Œæ˜“äºç†è§£
- **è¯­ä¹‰åŒ¹é…**ï¼šé€‚åˆæ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—

### 5.3 å‘é‡ç»´åº¦è¯´æ˜

**ä¸åŒæ¨¡å‹çš„å‘é‡ç»´åº¦**ï¼š

| æ¨¡å‹ | å‘é‡ç»´åº¦ |
|------|---------|
| OpenAI `text-embedding-ada-002` | 1536 |
| OpenAI `text-embedding-3-small` | 1536 |
| OpenAI `text-embedding-3-large` | 3072 |
| Ollama `nomic-embed-text` | 768 |

**ä¸ºä»€ä¹ˆç»´åº¦ä¸åŒï¼Ÿ**
- æ¨¡å‹æ¶æ„ä¸åŒ
- ç»´åº¦è¶Šé«˜ï¼Œè¡¨è¾¾èƒ½åŠ›è¶Šå¼ºï¼Œä½†è®¡ç®—æˆæœ¬ä¹Ÿè¶Šé«˜
- éœ€è¦å¹³è¡¡æ€§èƒ½å’Œæ•ˆæœ

**åœ¨ä½ çš„ä»£ç ä¸­**ï¼š
```python
embedding = OpenAIEmbedding(model_name="text-embedding-ada-002")
vector = embedding.embed_query("æµ‹è¯•")
print(len(vector))  # 1536
```

---

## å…­ã€Python è¯­æ³•çŸ¥è¯†ç‚¹

### 6.1 ç±»å‹æ³¨è§£

```python
def embed_query(self, text: str) -> List[float]:
    pass
```

**çŸ¥è¯†ç‚¹**ï¼š
- `text: str`ï¼šå‚æ•°ç±»å‹æ³¨è§£
- `-> List[float]`ï¼šè¿”å›ç±»å‹æ³¨è§£
- `List[float]`ï¼šåˆ—è¡¨ï¼Œå…ƒç´ æ˜¯æµ®ç‚¹æ•°
- `List[List[float]]`ï¼šåˆ—è¡¨çš„åˆ—è¡¨ï¼ˆäºŒç»´åˆ—è¡¨ï¼‰

### 6.2 åµŒå¥—åˆ—è¡¨

```python
vectors: List[List[float]] = [
    [0.1, 0.2, 0.3],  # ç¬¬ä¸€ä¸ªå‘é‡
    [0.4, 0.5, 0.6],  # ç¬¬äºŒä¸ªå‘é‡
    [0.7, 0.8, 0.9]   # ç¬¬ä¸‰ä¸ªå‘é‡
]

# è®¿é—®æ–¹å¼
print(vectors[0])      # [0.1, 0.2, 0.3]
print(vectors[0][0])   # 0.1
print(len(vectors))    # 3ï¼ˆæ–‡æ¡£æ•°é‡ï¼‰
print(len(vectors[0])) # 3ï¼ˆå‘é‡ç»´åº¦ï¼‰
```

### 6.3 å¼‚å¸¸å¤„ç†

```python
try:
    vector = self.embeddings.embed_query(text)
    return vector
except Exception as e:
    raise Exception(f"å‘é‡åŒ–æŸ¥è¯¢å¤±è´¥: {str(e)}") from e
```

**çŸ¥è¯†ç‚¹**ï¼š
- `try-except`ï¼šæ•è·å¼‚å¸¸
- `from e`ï¼šä¿ç•™åŸå§‹å¼‚å¸¸ä¿¡æ¯
- æä¾›å‹å¥½çš„é”™è¯¯ä¿¡æ¯

---

## ä¸ƒã€åº”ç”¨åœºæ™¯è¯¦è§£

### 7.1 RAG ä¸­çš„ä½¿ç”¨

**å®Œæ•´æµç¨‹**ï¼š

```python
# 1. æ–‡æ¡£å…¥åº“
documents = ["æ–‡æ¡£1", "æ–‡æ¡£2", "æ–‡æ¡£3"]
doc_vectors = embedding.embed_documents(documents)  # æ‰¹é‡å‘é‡åŒ–
vectorstore.add_vectors(doc_vectors, documents)     # å­˜å‚¨åˆ°å‘é‡åº“

# 2. ç”¨æˆ·æŸ¥è¯¢
query = "ç”¨æˆ·çš„é—®é¢˜"
query_vector = embedding.embed_query(query)          # æŸ¥è¯¢å‘é‡åŒ–
similar_docs = vectorstore.similarity_search(query_vector, k=4)  # ç›¸ä¼¼åº¦æ£€ç´¢

# 3. ç”Ÿæˆç­”æ¡ˆ
context = "\n".join([doc.page_content for doc in similar_docs])
answer = llm.generate(f"åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š\n{context}\n\né—®é¢˜ï¼š{query}")
```

### 7.2 æ–‡æ¡£æ£€ç´¢

**è¯­ä¹‰æœç´¢**ï¼š
```python
# ä¼ ç»Ÿå…³é”®è¯æœç´¢
# é—®é¢˜ï¼š"Python æ˜¯ä»€ä¹ˆï¼Ÿ"
# æ–‡æ¡£ï¼š"Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€"
# å¯èƒ½åŒ¹é…ä¸åˆ°ï¼ˆå¦‚æœç´¢å¼•ä¸­æ²¡æœ‰"æ˜¯ä»€ä¹ˆ"ï¼‰

# Embedding è¯­ä¹‰æœç´¢
query_vec = embedding.embed_query("Python æ˜¯ä»€ä¹ˆï¼Ÿ")
doc_vec = embedding.embed_query("Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€")
similarity = cosine_similarity(query_vec, doc_vec)  # é«˜ç›¸ä¼¼åº¦ï¼Œå¯ä»¥åŒ¹é…åˆ°
```

### 7.3 æ–‡æœ¬èšç±»

```python
# å°†ç›¸ä¼¼æ–‡æœ¬å½’ç±»
texts = ["Python æ•™ç¨‹", "Java æ•™ç¨‹", "Python å…¥é—¨", "å¤©æ°”çœŸå¥½"]
vectors = embedding.embed_documents(texts)

# è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
similarity_matrix = []
for i, vec1 in enumerate(vectors):
    row = []
    for j, vec2 in enumerate(vectors):
        row.append(cosine_similarity(vec1, vec2))
    similarity_matrix.append(row)

# æ ¹æ®ç›¸ä¼¼åº¦èšç±»
# "Python æ•™ç¨‹" å’Œ "Python å…¥é—¨" ç›¸ä¼¼åº¦é«˜ï¼Œå½’ä¸ºä¸€ç±»
```

---

## å…«ã€è®¾è®¡æ¨¡å¼åº”ç”¨

### 8.1 ç­–ç•¥æ¨¡å¼ï¼ˆStrategy Patternï¼‰

**å®šä¹‰**ï¼šå®šä¹‰ä¸€ç³»åˆ—ç®—æ³•ï¼ŒæŠŠå®ƒä»¬å°è£…èµ·æ¥ï¼Œå¹¶ä¸”ä½¿å®ƒä»¬å¯ä»¥äº’æ¢ã€‚

**åœ¨ä½ çš„ä»£ç ä¸­**ï¼š
```python
# ç­–ç•¥æ¥å£
class BaseEmbedding(ABC):
    @abstractmethod
    def embed_query(self, text: str) -> List[float]:
        pass

# å…·ä½“ç­–ç•¥
class OpenAIEmbedding(BaseEmbedding):  # ç­–ç•¥1
    def embed_query(self, text: str) -> List[float]:
        # OpenAI çš„å®ç°
        pass

class OllamaEmbedding(BaseEmbedding):  # ç­–ç•¥2
    def embed_query(self, text: str) -> List[float]:
        # Ollama çš„å®ç°
        pass

# ä½¿ç”¨ç­–ç•¥
def use_embedding(embedding: BaseEmbedding):  # å¯ä»¥ä¼ å…¥ä»»ä½•ç­–ç•¥
    vector = embedding.embed_query("é—®é¢˜")
```

### 8.2 é€‚é…å™¨æ¨¡å¼ï¼ˆAdapter Patternï¼‰

**å®šä¹‰**ï¼šå°†ä¸€ä¸ªç±»çš„æ¥å£è½¬æ¢æˆå®¢æˆ·å¸Œæœ›çš„å¦ä¸€ä¸ªæ¥å£ã€‚

**åœ¨ä½ çš„ä»£ç ä¸­**ï¼š
```python
# é€‚é…å™¨ï¼šå°† LangChain çš„æ¥å£é€‚é…ä¸ºä½ çš„æ¥å£
class OpenAIEmbedding(BaseEmbedding):
    def __init__(self, ...):
        self.embeddings = OpenAIEmbeddings(...)  # LangChain çš„æ¥å£
    
    def embed_query(self, text: str) -> List[float]:  # ä½ çš„æ¥å£
        # é€‚é…ï¼šç›´æ¥è°ƒç”¨ LangChainï¼Œè¿”å›å‘é‡
        return self.embeddings.embed_query(text)
```

---

## ä¹ã€æœ€ä½³å®è·µ

### 9.1 é”™è¯¯å¤„ç†

```python
def embed_query(self, text: str) -> List[float]:
    try:
        vector = self.embeddings.embed_query(text)
        if not vector or len(vector) == 0:
            raise ValueError("å‘é‡åŒ–ç»“æœä¸ºç©º")
        return vector
    except Exception as e:
        raise Exception(f"å‘é‡åŒ–æŸ¥è¯¢å¤±è´¥: {str(e)}") from e
```

**è¦ç‚¹**ï¼š
- æ•è·æ‰€æœ‰å¯èƒ½çš„å¼‚å¸¸
- éªŒè¯è¿”å›ç»“æœ
- æä¾›æœ‰æ„ä¹‰çš„é”™è¯¯ä¿¡æ¯

### 9.2 ç¯å¢ƒå˜é‡ç®¡ç†

```python
api_key = os.getenv("OPENAI_API_KEY")
```

**è¦ç‚¹**ï¼š
- æ•æ„Ÿä¿¡æ¯ä¸ç¡¬ç¼–ç 
- ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶
- æä¾›é»˜è®¤å€¼ï¼ˆå¦‚ Ollama çš„ `base_url`ï¼‰

### 9.3 æ‰¹é‡å¤„ç†ä¼˜åŒ–

```python
# æ¨èï¼šæ‰¹é‡å¤„ç†
documents = ["æ–‡æ¡£1", "æ–‡æ¡£2", "æ–‡æ¡£3"]
vectors = embedding.embed_documents(documents)  # ä¸€æ¬¡è°ƒç”¨

# ä¸æ¨èï¼šé€ä¸ªå¤„ç†
vectors = []
for doc in documents:
    vec = embedding.embed_query(doc)  # å¤šæ¬¡è°ƒç”¨ï¼Œæ•ˆç‡ä½
    vectors.append(vec)
```

---

## åã€å¸¸è§é—®é¢˜

### Q1: embed_query() å’Œ embed_documents() å¯ä»¥äº’æ¢å—ï¼Ÿ

**A**: æŠ€æœ¯ä¸Šå¯ä»¥ï¼Œä½†ä¸æ¨èã€‚
- `embed_query()` å¯ä»¥å¤„ç†å•ä¸ªå­—ç¬¦ä¸²
- `embed_documents()` å¯ä»¥å¤„ç†åˆ—è¡¨ï¼ˆå³ä½¿åªæœ‰ä¸€ä¸ªå…ƒç´ ï¼‰
- ä½†è¯­ä¹‰ä¸Šä¸åŒï¼Œåº”è¯¥æŒ‰ç”¨é€”ä½¿ç”¨

### Q2: å‘é‡ç»´åº¦æ˜¯å¤šå°‘ï¼Ÿ

**A**: å–å†³äºæ¨¡å‹ï¼š
- OpenAI `text-embedding-ada-002`ï¼š1536 ç»´
- OpenAI `text-embedding-3-large`ï¼š3072 ç»´
- Ollama æ¨¡å‹ï¼šé€šå¸¸ 768 æˆ– 1024 ç»´

### Q3: ä¸ºä»€ä¹ˆå‘é‡æ˜¯æµ®ç‚¹æ•°ï¼Ÿ

**A**: 
- æµ®ç‚¹æ•°å¯ä»¥è¡¨ç¤ºå°æ•°å€¼
- å‘é‡è®¡ç®—éœ€è¦ç²¾ç¡®çš„æ•°å€¼
- ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆå¦‚ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰éœ€è¦æµ®ç‚¹æ•°

### Q4: å¯ä»¥æœ¬åœ°è¿è¡Œ Embedding å—ï¼Ÿ

**A**: å¯ä»¥ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼š
- `sentence-transformers` åº“
- `HuggingFaceEmbeddings`
- `OllamaEmbeddings`ï¼ˆä½ çš„ä»£ç ä¸­å·²å®ç°ï¼‰
- ä¸éœ€è¦ API Key

---

## åä¸€ã€ä»£ç æ£€æŸ¥ç»“æœ

### âœ… å®ç°å®Œæˆæƒ…å†µ

1. **BaseEmbedding æ¥å£**ï¼šâœ… å·²å®ç°
   - ä½¿ç”¨ ABC å’Œ @abstractmethod
   - å®šä¹‰äº† `embed_query()` å’Œ `embed_documents()` æŠ½è±¡æ–¹æ³•

2. **OpenAIEmbedding ç±»**ï¼šâœ… å·²å®ç°
   - æ­£ç¡®ç»§æ‰¿ BaseEmbedding
   - å®ç°äº† `embed_query()` å’Œ `embed_documents()`
   - åŒ…å«é”™è¯¯å¤„ç†

3. **OllamaEmbedding ç±»**ï¼šâœ… å·²å®ç°
   - æ­£ç¡®ç»§æ‰¿ BaseEmbedding
   - å®ç°äº†ä¸¤ä¸ªæ–¹æ³•
   - æ¥å£ä¸ OpenAIEmbedding ä¸€è‡´

### âš ï¸ éœ€è¦æ³¨æ„çš„é—®é¢˜

1. **æ–‡æ¡£å­—ç¬¦ä¸²é”™è¯¯**ï¼š
   - `embed_query()` çš„æ–‡æ¡£å­—ç¬¦ä¸²å†™æˆäº†"å¯¹æ–‡æ¡£åˆ—è¡¨è¿›è¡Œå‘é‡åŒ–"
   - åº”è¯¥æ”¹ä¸º"å¯¹å•ä¸ªæŸ¥è¯¢æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–"

2. **é”™è¯¯ä¿¡æ¯ä¸ä¸€è‡´**ï¼š
   - `embed_query()` çš„é”™è¯¯ä¿¡æ¯å†™æˆäº†"å‘é‡åŒ–æ–‡æ¡£å¤±è´¥"
   - åº”è¯¥æ”¹ä¸º"å‘é‡åŒ–æŸ¥è¯¢å¤±è´¥"

3. **ä¸å¿…è¦çš„å¯¼å…¥**ï¼š
   - `from wandb.sdk.lib.apikey import api_key`ï¼ˆæœªä½¿ç”¨ï¼‰
   - `from ollama import embeddings`ï¼ˆæœªä½¿ç”¨ï¼‰
   - `from langchain_ollama import ChatOllama`ï¼ˆåœ¨ Embedding æ¨¡å—ä¸­ä¸éœ€è¦ï¼‰

### ğŸ“ æ”¹è¿›å»ºè®®

```python
# embed_query() çš„æ–‡æ¡£å­—ç¬¦ä¸²åº”è¯¥æ”¹ä¸ºï¼š
def embed_query(self, text: str) -> List[float]:
    """
    å¯¹å•ä¸ªæŸ¥è¯¢æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–
    
    Args:
        text: æŸ¥è¯¢æ–‡æœ¬
        
    Returns:
        å‘é‡è¡¨ç¤ºï¼ˆæµ®ç‚¹æ•°åˆ—è¡¨ï¼‰
    """
    try:
        vector = self.embeddings.embed_query(text)
        return vector
    except Exception as e:
        raise Exception(f"å‘é‡åŒ–æŸ¥è¯¢å¤±è´¥: {str(e)}") from e  # æ”¹ä¸º"æŸ¥è¯¢"
```

---

## åäºŒã€æ€»ç»“

### 12.1 æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **Embedding æ¦‚å¿µ**ï¼šæ–‡æœ¬åˆ°å‘é‡çš„è½¬æ¢ï¼Œå®ç°è¯­ä¹‰ç†è§£
2. **ä¸¤ä¸ªæ–¹æ³•**ï¼š`embed_query()` å’Œ `embed_documents()` çš„åŒºåˆ«å’Œç”¨é€”
3. **å‘é‡ç›¸ä¼¼åº¦**ï¼šä½™å¼¦ç›¸ä¼¼åº¦çš„è®¡ç®—å’Œåº”ç”¨
4. **æ¶æ„è®¾è®¡**ï¼šæŠ½è±¡æ¥å£ã€ç­–ç•¥æ¨¡å¼ã€é€‚é…å™¨æ¨¡å¼
5. **ä¸ LLM çš„åŒºåˆ«**ï¼šä¸éœ€è¦æ¶ˆæ¯æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²

### 12.2 è®¾è®¡ä¼˜åŠ¿

- âœ… **å¯æ‰©å±•**ï¼šè½»æ¾æ·»åŠ æ–°çš„ Embedding æä¾›å•†
- âœ… **å¯æµ‹è¯•**ï¼šå¯ä»¥åˆ›å»º Mock Embedding
- âœ… **å¯ç»´æŠ¤**ï¼šæ¥å£ç»Ÿä¸€ï¼Œä»£ç æ¸…æ™°
- âœ… **å¯å¤ç”¨**ï¼šä¸Šå±‚ä»£ç ä¸ä¾èµ–å…·ä½“å®ç°

### 12.3 å­¦ä¹ ä»·å€¼

- ç†è§£å‘é‡åŒ–å’Œè¯­ä¹‰æœç´¢çš„åŸç†
- æŒæ¡ Embedding çš„ä½¿ç”¨æ–¹æ³•
- å­¦ä¹ è®¾è®¡æ¨¡å¼çš„å®é™…åº”ç”¨
- ä¸ºå‘é‡å­˜å‚¨æ¨¡å—åšå‡†å¤‡

---

## åä¸‰ã€å‚è€ƒèµ„æº

- [LangChain OpenAI Embeddings æ–‡æ¡£](https://python.langchain.com/docs/integrations/text_embedding/openai)
- [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings)
- [å‘é‡ç›¸ä¼¼åº¦è®¡ç®—](https://en.wikipedia.org/wiki/Cosine_similarity)
- [LangChain Ollama Embeddings](https://python.langchain.com/docs/integrations/text_embedding/ollama)

