# RAG Chain ä»£ç æ£€æŸ¥æŠ¥å‘Š

## âœ… æ€»ä½“è¯„ä»·

ä»£ç å®ç°**éå¸¸å‡ºè‰²**ï¼æ ¸å¿ƒé€»è¾‘å®Œå…¨æ­£ç¡®ï¼Œå·²ç»å¯ä»¥æ­£å¸¸è¿è¡Œã€‚æˆ‘åªåšäº†ä¸€äº›**å°çš„ä¼˜åŒ–å’Œå®Œå–„**ã€‚

---

## ğŸ“‹ ä¿®æ”¹å†…å®¹æ€»ç»“

### 1. ä¿®æ­£å‚æ•°è°ƒç”¨æ–¹å¼ï¼ˆ3 å¤„ï¼‰

**ä¿®æ”¹å‰**ï¼š
```python
# ä½¿ç”¨å…³é”®å­—å‚æ•°
answer = self.llm.generate(prompt=prompt)
self.llm.stream_generate(prompt=prompt)
```

**ä¿®æ”¹å**ï¼š
```python
# ä½¿ç”¨ä½ç½®å‚æ•°ï¼ˆPython æƒ¯ä¾‹ï¼‰
answer = self.llm.generate(prompt)
self.llm.stream_generate(prompt)
```

**ä½ç½®**ï¼š
- `RAGChain.query()` ç¬¬ 141 è¡Œ
- `RAGChain.stream_query()` ç¬¬ 174 è¡Œ
- `ConversationalRAGChain.query()` ç¬¬ 247 è¡Œ

**ç†ç”±**ï¼šè™½ç„¶ä¸¤ç§æ–¹å¼éƒ½èƒ½å·¥ä½œï¼Œä½† Python æƒ¯ä¾‹æ˜¯ç¬¬ä¸€ä¸ªå‚æ•°ç”¨ä½ç½®å‚æ•°ï¼Œæ›´ç®€æ´ä¼˜é›…ã€‚

---

### 2. ä¿®æ­£é”™åˆ«å­—

**ä¿®æ”¹å‰**ï¼ˆç¬¬ 234 è¡Œï¼‰ï¼š
```python
answer = "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯|"  # å¤šäº†ä¸€ä¸ª |
```

**ä¿®æ”¹å**ï¼š
```python
answer = "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
```

---

### 3. æ”¹è¿›ä»£ç é£æ ¼ï¼ˆç¬¦åˆ PEP 8ï¼‰

**ä¿®æ”¹å‰**ï¼š
```python
# èµ‹å€¼è¿ç®—ç¬¦å‰åç¼ºå°‘ç©ºæ ¼
answer=self.llm.generate(prompt)
context="\n\n".join(contexts)
for i,doc in enumerate(relevant_docs,1):
```

**ä¿®æ”¹å**ï¼š
```python
# æ·»åŠ ç©ºæ ¼ï¼Œæ›´æ˜“è¯»
answer = self.llm.generate(prompt)
context = "\n\n".join(contexts)
for i, doc in enumerate(relevant_docs, 1):
```

---

### 4. æ·»åŠ  ConversationalRAGChain.stream_query() â­

**é‡è¦**ï¼šè¿™æ˜¯ä½ æå‡ºçš„é—®é¢˜â€”â€”**æ˜¯çš„ï¼Œéœ€è¦å®ç°ï¼**

#### ä¸ºä»€ä¹ˆéœ€è¦ï¼Ÿ

å¦‚æœä¸å®ç°ï¼Œ`ConversationalRAGChain.stream_query()` ä¼šè°ƒç”¨çˆ¶ç±»çš„æ–¹æ³•ï¼š

```python
# é—®é¢˜ï¼šçˆ¶ç±»çš„ stream_query() ä¸ä¼šå¤„ç†å¯¹è¯å†å²
conv_chain = ConversationalRAGChain(llm, vectorstore)

# ç¬¬ä¸€è½®
conv_chain.query("ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ")  # âœ… ä¿å­˜å†å²

# ç¬¬äºŒè½®ï¼ˆæµå¼ï¼‰
for chunk in conv_chain.stream_query("å®ƒæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ"):  # âŒ ä¸ä¼šä½¿ç”¨å†å²ï¼
    print(chunk, end="")
```

**ç»“æœ**ï¼šæµå¼æŸ¥è¯¢ä¸ä¼šåŒ…å«å¯¹è¯å†å²ï¼Œç”¨æˆ·ä½“éªŒä¸ä¸€è‡´ã€‚

#### å®ç°çš„æ–¹æ³•

```python
def stream_query(self, question: str, k: int = 4):
    """
    æµå¼æ‰§è¡Œå¸¦å†å²çš„ RAG æŸ¥è¯¢
    
    ä¸çˆ¶ç±»çš„åŒºåˆ«ï¼š
    - åŒ…å«å¯¹è¯å†å²
    - ä¿å­˜å½“å‰å¯¹è¯åˆ°å†å²
    """
    try:
        # æ£€ç´¢æ–‡æ¡£
        relevant_docs = self.vectorstore.similarity_search(question, k=k)
        
        if not relevant_docs:
            answer = "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
            self._add_to_history(question, answer)
            yield answer
            return
        
        # ç»„è£…ä¸Šä¸‹æ–‡
        context = "\n\n".join([
            f"[æ–‡æ¡£{i}]\n{doc.page_content}"
            for i, doc in enumerate(relevant_docs, 1)
        ])
        
        # ç»„è£…å†å²ï¼ˆå…³é”®ï¼ï¼‰
        history = self._format_history()
        
        # ç»„è£… Promptï¼ˆåŒ…å«å†å²ï¼‰
        prompt = self.prompt_template.format(
            history=history,
            context=context,
            question=question
        )
        
        # æµå¼ç”Ÿæˆå¹¶æ”¶é›†å®Œæ•´ç­”æ¡ˆ
        answer_parts = []
        for chunk in self.llm.stream_generate(prompt):
            answer_parts.append(chunk)
            yield chunk
        
        # ä¿å­˜å®Œæ•´ç­”æ¡ˆåˆ°å†å²ï¼ˆå…³é”®ï¼ï¼‰
        full_answer = "".join(answer_parts)
        self._add_to_history(question, full_answer)
        
    except Exception as e:
        raise Exception(f"æµå¼å¯¹è¯ RAG æŸ¥è¯¢å¤±è´¥: {str(e)}") from e
```

#### å…³é”®ç‚¹

1. **åŒ…å«å†å²**ï¼š`history = self._format_history()`
2. **ä½¿ç”¨å†å²æ¨¡æ¿**ï¼šåŒ…å« `{history}` å ä½ç¬¦
3. **ä¿å­˜å†å²**ï¼šæ”¶é›†å®Œæ•´ç­”æ¡ˆåè°ƒç”¨ `self._add_to_history()`

---

### 5. å®Œå–„ ConversationalRAGChain.query()

**æ”¹è¿›**ï¼š
- æ·»åŠ å®Œæ•´çš„ docstring
- æ·»åŠ å¼‚å¸¸å¤„ç†
- æ·»åŠ æ–‡æ¡£ç¼–å·ï¼ˆä¸çˆ¶ç±»ä¸€è‡´ï¼‰
- ç»Ÿä¸€ä»£ç é£æ ¼

**ä¿®æ”¹å**ï¼š
```python
def query(self, question: str, k: int = 4) -> str:
    """
    å¸¦å†å²çš„ RAG æŸ¥è¯¢
    
    ä¸çˆ¶ç±»çš„åŒºåˆ«ï¼š
    - åŒ…å«å¯¹è¯å†å²
    - ä¿å­˜å½“å‰å¯¹è¯åˆ°å†å²
    """
    try:
        # æ£€ç´¢æ–‡æ¡£
        docs = self.vectorstore.similarity_search(question, k=k)
        if not docs:
            answer = "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
            self._add_to_history(question, answer)
            return answer

        # ç»„è£…ä¸Šä¸‹æ–‡ï¼ˆæ·»åŠ æ–‡æ¡£ç¼–å·ï¼‰
        context = "\n\n".join([
            f"[æ–‡æ¡£{i}]\n{doc.page_content}"
            for i, doc in enumerate(docs, 1)
        ])

        # ç»„è£…å†å²
        history = self._format_history()

        # ç»„è£… Prompt
        prompt = self.prompt_template.format(
            history=history,
            context=context,
            question=question
        )
        
        # LLM ç”Ÿæˆç­”æ¡ˆ
        answer = self.llm.generate(prompt)

        # ä¿å­˜åˆ°å†å²
        self._add_to_history(question, answer)
        return answer
        
    except Exception as e:
        raise Exception(f"å¯¹è¯ RAG æŸ¥è¯¢å¤±è´¥: {str(e)}") from e
```

---

## ğŸ“Š ä¿®æ”¹å¯¹æ¯”è¡¨

| ä¿®æ”¹é¡¹ | ç±»å‹ | é‡è¦æ€§ | ä½ç½® |
|--------|------|--------|------|
| å‚æ•°è°ƒç”¨æ–¹å¼ | ä¼˜åŒ– | ä¸­ | 3 å¤„ |
| é”™åˆ«å­—ä¿®æ­£ | ä¿®æ­£ | ä½ | 1 å¤„ |
| ä»£ç é£æ ¼ | ä¼˜åŒ– | ä½ | å¤šå¤„ |
| æ·»åŠ  stream_query() | **æ–°å¢** | **é«˜** | ConversationalRAGChain |
| å®Œå–„å¼‚å¸¸å¤„ç† | å¢å¼º | ä¸­ | ConversationalRAGChain.query() |

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½æ£€æŸ¥

### RAGChain ç±»

| æ–¹æ³• | çŠ¶æ€ | æ ¸å¿ƒåŠŸèƒ½ |
|------|------|---------|
| `__init__()` | âœ… å®Œæˆ | ç»„ä»¶åˆå§‹åŒ–ã€æ¨¡æ¿è®¾ç½® |
| `_get_default_template()` | âœ… å®Œæˆ | ä¼ä¸šçº§ Prompt æ¨¡æ¿ |
| `query()` | âœ… å®Œæˆ | æ£€ç´¢â†’ç»„è£…â†’ç”Ÿæˆ |
| `stream_query()` | âœ… å®Œæˆ | æµå¼ç”Ÿæˆ |

### ConversationalRAGChain ç±»

| æ–¹æ³• | çŠ¶æ€ | æ ¸å¿ƒåŠŸèƒ½ |
|------|------|---------|
| `__init__()` | âœ… å®Œæˆ | ç»§æ‰¿åˆå§‹åŒ–ã€å†å²å­˜å‚¨ |
| `_get_default_template()` | âœ… å®Œæˆ | å¸¦å†å²çš„ Prompt æ¨¡æ¿ |
| `query()` | âœ… å®Œæˆ | æ£€ç´¢â†’å†å²â†’ç»„è£…â†’ç”Ÿæˆâ†’ä¿å­˜ |
| `stream_query()` | âœ… **æ–°å¢** | æµå¼ç”Ÿæˆ + å†å²ç®¡ç† |
| `_format_history()` | âœ… å®Œæˆ | æ ¼å¼åŒ–å¯¹è¯å†å² |
| `_add_to_history()` | âœ… å®Œæˆ | æ·»åŠ åˆ°å†å² |
| `clear_history()` | âœ… å®Œæˆ | æ¸…ç©ºå†å² |

---

## ğŸ§ª æµ‹è¯•å»ºè®®

### æµ‹è¯• 1ï¼šåŸºæœ¬ RAG æŸ¥è¯¢

```python
from src.core.llm.base import OpenAILLM
from src.core.vectorstore.base import FAISSVectorStore
from src.core.chain.rag_chain import RAGChain
from langchain.schema import Document

# åˆå§‹åŒ–
llm = OpenAILLM("gpt-3.5-turbo")
vectorstore = FAISSVectorStore()

# æ·»åŠ æ–‡æ¡£
docs = [
    Document(page_content="Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”± Guido van Rossum äº 1991 å¹´åˆ›å»ºã€‚"),
    Document(page_content="Python ä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»åã€‚")
]
vectorstore.add_documents(docs)

# åˆ›å»º RAG Chain
rag_chain = RAGChain(llm=llm, vectorstore=vectorstore)

# æµ‹è¯•æŸ¥è¯¢
answer = rag_chain.query("ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ")
print(f"ç­”æ¡ˆ: {answer}")
```

### æµ‹è¯• 2ï¼šæµå¼æŸ¥è¯¢

```python
# æµ‹è¯•æµå¼ç”Ÿæˆ
print("é—®é¢˜: Python æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ")
print("ç­”æ¡ˆ: ", end="")

for chunk in rag_chain.stream_query("Python æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ"):
    print(chunk, end="", flush=True)
print()
```

### æµ‹è¯• 3ï¼šå¯¹è¯å¼ RAG

```python
from src.core.chain.rag_chain import ConversationalRAGChain

# åˆ›å»ºå¯¹è¯å¼ RAG Chain
conv_chain = ConversationalRAGChain(llm=llm, vectorstore=vectorstore)

# ç¬¬ä¸€è½®å¯¹è¯
q1 = "è°åˆ›å»ºäº† Pythonï¼Ÿ"
a1 = conv_chain.query(q1)
print(f"Q1: {q1}")
print(f"A1: {a1}\n")

# ç¬¬äºŒè½®å¯¹è¯ï¼ˆå¼•ç”¨ä¸Šä¸‹æ–‡ï¼‰
q2 = "ä»–åœ¨ä»€ä¹ˆæ—¶å€™åˆ›å»ºçš„ï¼Ÿ"  # "ä»–" æŒ‡ä»£ Guido
a2 = conv_chain.query(q2)
print(f"Q2: {q2}")
print(f"A2: {a2}\n")

# æµ‹è¯•æµå¼å¯¹è¯
q3 = "å®ƒæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ"  # "å®ƒ" æŒ‡ä»£ Python
print(f"Q3: {q3}")
print("A3: ", end="")
for chunk in conv_chain.stream_query(q3):
    print(chunk, end="", flush=True)
print()
```

---

## ğŸ“ ä»£ç è´¨é‡è¯„ä¼°

### ä¼˜ç‚¹

| æ–¹é¢ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| é€»è¾‘æ­£ç¡®æ€§ | â­â­â­â­â­ | æ ¸å¿ƒé€»è¾‘å®Œå…¨æ­£ç¡® |
| ä»£ç ç»“æ„ | â­â­â­â­â­ | ç»“æ„æ¸…æ™°ï¼Œæ˜“äºç†è§£ |
| å¼‚å¸¸å¤„ç† | â­â­â­â­â­ | å®Œå–„çš„ try-except |
| æ–‡æ¡£æ³¨é‡Š | â­â­â­â­ | å…³é”®åœ°æ–¹æœ‰æ³¨é‡Š |
| ä»£ç é£æ ¼ | â­â­â­â­â­ | ç¬¦åˆ PEP 8ï¼ˆä¿®æ­£åï¼‰ |

### æ”¹è¿›å»ºè®®

1. âœ… **å·²å®Œæˆ**ï¼šæ·»åŠ  `ConversationalRAGChain.stream_query()`
2. âœ… **å·²å®Œæˆ**ï¼šç»Ÿä¸€ä»£ç é£æ ¼
3. âœ… **å·²å®Œæˆ**ï¼šå®Œå–„å¼‚å¸¸å¤„ç†

---

## ğŸ‰ æ€»ç»“

### ä½ çš„å®ç°

**ä¼˜ç§€ï¼** æ ¸å¿ƒé€»è¾‘å®Œå…¨æ­£ç¡®ï¼Œä»£ç ç»“æ„æ¸…æ™°ï¼Œå¼‚å¸¸å¤„ç†å®Œå–„ã€‚

### æˆ‘çš„ä¿®æ”¹

**å¾®è°ƒä¼˜åŒ–**ï¼š
- ä¿®æ­£äº† 3 å¤„å‚æ•°è°ƒç”¨æ–¹å¼
- ä¿®æ­£äº† 1 å¤„é”™åˆ«å­—
- ç»Ÿä¸€äº†ä»£ç é£æ ¼
- **æ·»åŠ äº†å…³é”®çš„ `stream_query()` æ–¹æ³•**

### æœ€ç»ˆçŠ¶æ€

âœ… **RAG Chain å®Œå…¨å®ç°ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼**

åŒ…æ‹¬ï¼š
- âœ… åŸºæœ¬ RAG æŸ¥è¯¢
- âœ… æµå¼ RAG æŸ¥è¯¢
- âœ… å¯¹è¯å¼ RAG æŸ¥è¯¢
- âœ… å¯¹è¯å¼æµå¼ RAG æŸ¥è¯¢
- âœ… å®Œæ•´çš„å†å²ç®¡ç†

### ä¸‹ä¸€æ­¥

RAG Chain å·²å®Œæˆï¼Œå¯ä»¥ç»§ç»­ï¼š
1. å®ç°æ–‡æ¡£åŠ è½½å™¨
2. å®ç°çŸ¥è¯†åº“ç®¡ç†
3. å­¦ä¹  LangGraph å®ç° Agent

**æ­å–œï¼ä½ å·²ç»å®ç°äº†ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„ RAG ç³»ç»Ÿï¼** ğŸŠ
