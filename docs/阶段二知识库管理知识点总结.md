# 阶段二：知识库管理 - 知识点总结

**文档版本**: v1.0  
**创建日期**: 2026-01-09  
**适用阶段**: 阶段二 - 知识库管理 (Week 3)

---

## 目录

1. [模块概述](#模块概述)
2. [核心概念](#核心概念)
3. [KnowledgeBase 类详解](#knowledgebase-类详解)
4. [KnowledgeBaseManager 类详解](#knowledgebasemanager-类详解)
5. [文档索引机制](#文档索引机制)
6. [文档管理功能](#文档管理功能)
7. [向量库重建机制](#向量库重建机制)
8. [错误处理和异常](#错误处理和异常)
9. [设计模式应用](#设计模式应用)
10. [Python 语法知识点](#python-语法知识点)
11. [最佳实践](#最佳实践)
12. [应用场景](#应用场景)

---

## 模块概述

### 什么是知识库管理？

知识库管理是 RAG 系统的核心组件之一，负责组织、存储和检索文档集合。它提供了一个统一的接口来管理多个知识库，每个知识库可以包含不同主题或领域的文档。

### 为什么需要知识库管理？

```
传统方式的问题：
┌─────────────────────────────────────┐
│ 文档 A, B, C, D, E...               │
│ 所有文档混在一起                    │
│ 难以管理和维护                      │
│ 无法按主题分类                      │
└─────────────────────────────────────┘

使用知识库管理：
┌───────────┬───────────┬───────────┐
│ 技术文档  │ 产品手册  │ FAQ       │
│ ├─ doc1   │ ├─ doc4   │ ├─ doc7   │
│ ├─ doc2   │ ├─ doc5   │ ├─ doc8   │
│ └─ doc3   │ └─ doc6   │ └─ doc9   │
└───────────┴───────────┴───────────┘
清晰的组织结构
便于管理和维护
支持多租户场景
```

### 模块架构

```
知识库管理模块架构：

┌────────────────────────────────────────────┐
│        KnowledgeBaseManager                │  ← 管理多个知识库
│  ┌──────────────────────────────────────┐ │
│  │ 知识库列表：                         │ │
│  │ - 技术文档 KB                        │ │
│  │ - 产品手册 KB                        │ │
│  │ - FAQ KB                             │ │
│  └──────────────────────────────────────┘ │
└────────────────────────────────────────────┘
                    │
        ┌───────────┼───────────┐
        ▼           ▼           ▼
   ┌─────────┐ ┌─────────┐ ┌─────────┐
   │   KB1   │ │   KB2   │ │   KB3   │  ← 单个知识库
   ├─────────┤ ├─────────┤ ├─────────┤
   │VectorDB │ │VectorDB │ │VectorDB │  ← 向量存储
   ├─────────┤ ├─────────┤ ├─────────┤
   │Doc Index│ │Doc Index│ │Doc Index│  ← 文档索引
   └─────────┘ └─────────┘ └─────────┘
```

---

## 核心概念

### 1. 知识库（Knowledge Base）

**定义**：一个包含特定主题或领域文档的集合，具有独立的向量存储和文档索引。

**组成部分**：
```python
KnowledgeBase
├── name: str              # 知识库名称
├── vectorstore: BaseVectorStore  # 向量存储（FAISS）
├── embedding: BaseEmbedding      # 向量化模型
└── documents_index: List[Dict]   # 文档索引（元数据）
```

**生命周期**：
```
创建 → 添加文档 → 搜索 → 更新/删除文档 → 重建 → 删除
  ↓       ↓        ↓          ↓            ↓      ↓
 Init  Upload   Query    Manage        Rebuild  Clean
```

### 2. 文档索引（Document Index）

**定义**：记录知识库中所有文档的元数据信息，存储为 JSON 格式。

**索引结构**：
```json
[
  {
    "source": "docs/python_basics.txt",
    "chunk_count": 5,
    "added_time": "2026-01-09T10:30:00.123456",
    "updated_time": "2026-01-09T10:30:00.123456"
  },
  {
    "source": "docs/advanced_python.pdf",
    "chunk_count": 12,
    "added_time": "2026-01-09T11:00:00.654321",
    "updated_time": "2026-01-09T11:00:00.654321"
  }
]
```

**作用**：
1. **追踪文档来源**：记录每个文档的原始路径
2. **记录块数量**：知道文档被切分成多少块
3. **时间戳管理**：追踪文档的添加和更新时间
4. **快速查询**：不需要加载向量库就能获取文档列表

### 3. 向量库（Vector Store）

在知识库管理中，向量库是核心的存储层：

```
文档处理流程：

原始文档
    ↓
文档加载器（Loader）
    ↓
文本切分器（Splitter）
    ↓
文档块（Chunks）
    ↓
向量化模型（Embedding）
    ↓
向量（Vectors）
    ↓
向量库（FAISS）
```

### 4. 持久化（Persistence）

**向量库持久化**：
```python
# 保存向量库到磁盘
vectorstore.save_local(persist_directory)

# 从磁盘加载向量库
vectorstore = FAISS.load_local(persist_directory, embeddings)
```

**文档索引持久化**：
```python
# 保存索引到 JSON 文件
index_file = kb_path / "doc_index.json"
with open(index_file, 'w', encoding='utf-8') as f:
    json.dump(documents_index, f, ensure_ascii=False, indent=2)

# 加载索引
with open(index_file, 'r', encoding='utf-8') as f:
    documents_index = json.load(f)
```

---

## KnowledgeBase 类详解

### 类定义

```python
class KnowledgeBase:
    """
    知识库类 - 管理单个知识库
    
    职责：
    1. 文档的添加、删除、查询
    2. 向量存储管理
    3. 文档索引维护
    4. 文件上传和处理
    """
    
    def __init__(
        self,
        name: str,
        vectorstore: BaseVectorStore,
        embedding: BaseEmbedding,
        kb_path: Optional[str] = None
    ):
        self.name = name
        self.vectorstore = vectorstore
        self.embedding = embedding
        self.kb_path = Path(kb_path) if kb_path else None
        self.documents_index: List[Dict] = []
        
        # 加载已有的文档索引
        if self.kb_path:
            self._load_doc_index()
```

### 核心方法详解

#### 1. add_documents() - 添加文档

**功能**：添加文档到知识库，自动更新索引。

**实现逻辑**：
```python
def add_documents(
    self,
    documents: List[Document],
    update_index: bool = True
) -> int:
    """
    处理流程：
    1. 验证输入（documents 非空）
    2. 调用向量存储的 add_documents
    3. 更新文档索引（记录 source、chunk_count、时间戳）
    4. 持久化索引到磁盘
    5. 返回添加的文档数量
    """
    try:
        if not documents:
            raise ValueError("文档列表不能为空")
        
        # 添加到向量库
        self.vectorstore.add_documents(documents)
        
        # 更新索引
        if update_index:
            self._update_doc_index(documents)
        
        return len(documents)
    except Exception as e:
        raise Exception(f"添加文档失败: {str(e)}") from e
```

**知识点**：
- **参数验证**：确保输入有效
- **原子操作**：成功或失败是一个整体
- **自动索引**：无需手动维护索引
- **异常链**：`from e` 保留原始错误信息

#### 2. upload_file() - 上传文件

**功能**：上传单个文件，自动完成加载、切分、向量化、存储全流程。

**实现逻辑**：
```python
def upload_file(
    self,
    file_path: str,
    chunk_size: int = 500,
    chunk_overlap: int = 50
) -> int:
    """
    完整处理流程：
    
    文件路径
       ↓
    文件验证（是否存在）
       ↓
    选择加载器（根据扩展名）
       ↓
    加载文档（Document 对象）
       ↓
    选择切分器
       ↓
    切分文档（多个 Chunks）
       ↓
    向量化并存储
       ↓
    更新索引
       ↓
    返回块数量
    """
    file_path = Path(file_path)
    
    # 1. 验证文件
    if not file_path.exists():
        raise FileNotFoundError(f"文件不存在: {file_path}")
    
    # 2. 选择加载器（工厂模式）
    loader = DocumentLoaderFactory.create_loader(str(file_path))
    
    # 3. 加载文档
    documents = loader.load()
    
    # 4. 切分文档
    splitter = TextSplitterFactory.create_splitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap
    )
    chunks = splitter.split_documents(documents)
    
    # 5. 添加到知识库
    self.add_documents(chunks)
    
    return len(chunks)
```

**知识点**：
- **工厂模式**：根据文件类型自动选择加载器
- **流水线处理**：一步步完成整个流程
- **参数可配置**：chunk_size 和 chunk_overlap 可调
- **错误提前发现**：在开始处理前验证文件存在

#### 3. upload_directory() - 批量上传

**功能**：递归上传整个目录的所有文件。

**实现逻辑**：
```python
def upload_directory(
    self,
    directory: str,
    chunk_size: int = 500,
    chunk_overlap: int = 50,
    extensions: Optional[List[str]] = None
) -> Dict[str, int]:
    """
    批量处理流程：
    
    目录路径
       ↓
    递归遍历（rglob）
       ↓
    文件筛选（按扩展名）
       ↓
    逐个处理文件
       ↓
    收集结果
       ↓
    返回统计信息
    """
    directory = Path(directory)
    
    # 默认支持的扩展名
    if extensions is None:
        extensions = ['.txt', '.pdf', '.md']
    
    results = {
        'success': 0,
        'failed': 0,
        'total_chunks': 0,
        'failed_files': []
    }
    
    # 递归遍历目录
    for file_path in directory.rglob('*'):
        if file_path.is_file() and file_path.suffix in extensions:
            try:
                chunks = self.upload_file(
                    str(file_path),
                    chunk_size,
                    chunk_overlap
                )
                results['success'] += 1
                results['total_chunks'] += chunks
            except Exception as e:
                results['failed'] += 1
                results['failed_files'].append(str(file_path))
    
    return results
```

**知识点**：
- **递归遍历**：`rglob('*')` 遍历所有子目录
- **文件筛选**：`suffix in extensions` 只处理指定类型
- **容错处理**：单个文件失败不影响其他文件
- **统计信息**：返回详细的处理结果

#### 4. delete_document() - 删除文档

**功能**：删除指定文档，自动重建向量库。

**实现逻辑**：
```python
def delete_document(self, source: str):
    """
    删除流程：
    
    验证文档存在
       ↓
    从索引中移除
       ↓
    判断索引是否为空
       ↓
    ├─ 为空：清空向量库
    └─ 不为空：重建向量库（排除该文档）
    """
    try:
        # 1. 验证文档存在
        doc_info = self.get_document_info(source)
        if not doc_info:
            raise ValueError(f"文档 '{source}' 不存在于知识库中")
        
        # 2. 从索引中移除
        self.documents_index = [
            d for d in self.documents_index 
            if d['source'] != source
        ]
        self._save_doc_index()
        
        # 3. 更新向量库
        if not self.documents_index:
            # 索引为空，直接清空
            self.vectorstore.delete()
        else:
            # 索引不为空，重建（排除被删除的文档）
            self.rebuild_vectorstore(exclude_sources=[source])
    
    except ValueError:
        # 保留 ValueError，直接抛出
        raise
    except Exception as e:
        raise Exception(f"删除文档 '{source}' 失败: {str(e)}") from e
```

**知识点**：
- **异常分层**：区分 `ValueError` 和其他异常
- **列表推导式**：`[d for d in ... if ...]` 过滤列表
- **重建策略**：删除后需要重建向量库保证一致性
- **空判断优化**：空知识库直接清空，不需要重建

#### 5. rebuild_vectorstore() - 重建向量库

**功能**：从源文件重新加载所有文档，重建向量库。

**实现逻辑**：
```python
def rebuild_vectorstore(
    self,
    new_embedding: Optional[BaseEmbedding] = None,
    exclude_sources: Optional[List[str]] = None
):
    """
    重建流程：
    
    清空向量库
       ↓
    遍历文档索引
       ↓
    ├─ 在排除列表中？跳过
    └─ 不在排除列表中：
         ↓
       加载文件
         ↓
       添加到向量库
         ↓
       更新成功计数
    """
    print(f"🔄 开始重建向量库 '{self.name}'...")
    
    # 使用新的 embedding 或保持原有的
    embedding = new_embedding or self.embedding
    
    # 清空向量库
    self.vectorstore.delete()
    
    # 统计信息
    success_count = 0
    failed_count = 0
    failed_files = []
    
    # 遍历索引中的所有文档
    for doc_info in self.documents_index:
        source = doc_info['source']
        
        # 跳过排除的文档
        if exclude_sources and source in exclude_sources:
            continue
        
        try:
            # 重新加载文件
            file_path = Path(source)
            if not file_path.exists():
                raise FileNotFoundError(f"文件不存在: {source}")
            
            loader = DocumentLoaderFactory.create_loader(source)
            documents = loader.load()
            
            # 添加到向量库（不更新索引，因为索引已存在）
            self.add_documents(documents, update_index=False)
            success_count += 1
            
        except Exception as e:
            failed_count += 1
            failed_files.append(source)
    
    print(f"✅ 重建完成:")
    print(f"   成功: {success_count} 个文档")
    print(f"   失败: {failed_count} 个文档")
    
    return {
        'success': success_count,
        'failed': failed_count,
        'failed_files': failed_files
    }
```

**知识点**：
- **可选参数**：支持更换 embedding 模型
- **排除机制**：`exclude_sources` 允许跳过特定文档
- **容错处理**：单个文档失败不影响其他文档
- **详细反馈**：返回重建的统计信息

#### 6. search() - 搜索文档

**功能**：在知识库中进行语义搜索。

**实现逻辑**：
```python
def search(
    self,
    query: str,
    k: int = 3
) -> List[Document]:
    """
    搜索流程：
    
    查询文本
       ↓
    向量化（embedding.embed_query）
       ↓
    相似度搜索（vectorstore.similarity_search）
       ↓
    返回 Top-K 结果
    """
    try:
        if not query:
            raise ValueError("查询文本不能为空")
        
        # 调用向量存储的搜索方法
        results = self.vectorstore.search(query, k=k)
        
        return results
    except Exception as e:
        raise Exception(f"搜索失败: {str(e)}") from e
```

**知识点**：
- **语义搜索**：基于向量相似度，不是关键词匹配
- **Top-K 结果**：返回最相关的 K 个文档
- **简单封装**：委托给 vectorstore 实现

---

## KnowledgeBaseManager 类详解

### 类定义

```python
class KnowledgeBaseManager:
    """
    知识库管理器 - 管理多个知识库
    
    职责：
    1. 创建和删除知识库
    2. 获取和列出知识库
    3. 知识库生命周期管理
    4. 持久化管理
    """
    
    def __init__(self, root_path: str = "./data/knowledge_base"):
        self.root_path = Path(root_path)
        self.root_path.mkdir(parents=True, exist_ok=True)
        self.knowledge_bases: Dict[str, KnowledgeBase] = {}
```

### 核心方法详解

#### 1. create_kb() - 创建知识库

**功能**：创建新的知识库实例。

**实现逻辑**：
```python
def create_kb(
    self,
    name: str,
    vectorstore: BaseVectorStore,
    embedding: BaseEmbedding
) -> KnowledgeBase:
    """
    创建流程：
    
    验证名称唯一性
       ↓
    创建知识库目录
       ↓
    创建 KnowledgeBase 实例
       ↓
    加入管理字典
       ↓
    返回实例
    """
    # 1. 检查重复
    if name in self.knowledge_bases:
        raise ValueError(f"知识库 '{name}' 已存在，请使用不同的名称")
    
    # 2. 创建目录
    kb_path = self.root_path / name
    kb_path.mkdir(parents=True, exist_ok=True)
    
    # 3. 创建实例
    kb = KnowledgeBase(
        name=name,
        vectorstore=vectorstore,
        embedding=embedding,
        kb_path=str(kb_path)
    )
    
    # 4. 添加到管理器
    self.knowledge_bases[name] = kb
    
    return kb
```

**知识点**：
- **唯一性检查**：避免同名知识库
- **目录管理**：每个知识库有独立目录
- **字典存储**：`Dict[str, KnowledgeBase]` 快速查找

#### 2. get_kb() - 获取知识库

**功能**：根据名称获取知识库实例。

**实现逻辑**：
```python
def get_kb(self, name: str) -> Optional[KnowledgeBase]:
    """
    获取逻辑：
    
    1. 先从内存查找（self.knowledge_bases）
    2. 如果不在内存，尝试从磁盘加载
    3. 返回实例或 None
    """
    # 从内存获取
    if name in self.knowledge_bases:
        return self.knowledge_bases[name]
    
    # 从磁盘加载
    kb_path = self.root_path / name
    if kb_path.exists():
        # 这里可以实现从磁盘加载的逻辑
        # 但需要保存更多信息（embedding 配置等）
        pass
    
    return None
```

**知识点**：
- **缓存机制**：内存优先，磁盘其次
- **懒加载**：只在需要时加载
- **Optional 类型**：明确可能返回 None

#### 3. list_kb() - 列出所有知识库

**功能**：获取所有知识库的名称列表。

**实现逻辑**：
```python
def list_kb(self) -> List[str]:
    """
    返回所有知识库的名称
    """
    return list(self.knowledge_bases.keys())
```

**知识点**：
- **字典键转列表**：`list(dict.keys())`
- **简单直接**：不需要复杂逻辑

#### 4. delete_kb() - 删除知识库

**功能**：删除知识库及其所有数据。

**实现逻辑**：
```python
def delete_kb(self, name: str):
    """
    删除流程：
    
    验证知识库存在
       ↓
    清空向量库
       ↓
    删除目录
       ↓
    从管理器移除
    """
    # 1. 验证存在
    if name not in self.knowledge_bases:
        raise ValueError(f"知识库 '{name}' 不存在，无法删除")
    
    # 2. 获取实例
    kb = self.knowledge_bases[name]
    
    # 3. 清空向量库
    kb.vectorstore.delete()
    
    # 4. 删除目录
    if kb.kb_path:
        import shutil
        shutil.rmtree(kb.kb_path, ignore_errors=True)
    
    # 5. 从管理器移除
    del self.knowledge_bases[name]
```

**知识点**：
- **完整清理**：向量库 + 文件系统 + 内存
- **shutil.rmtree**：递归删除目录
- **ignore_errors**：删除失败不抛异常

---

## 文档索引机制

### 索引的作用

文档索引是知识库管理的核心数据结构：

```
文档索引的三大作用：

1. 快速查询
   ┌────────────────────────┐
   │ 查看有哪些文档？       │
   │ 直接读取索引文件       │
   │ 无需加载向量库         │
   └────────────────────────┘

2. 文档追踪
   ┌────────────────────────┐
   │ 文档何时添加的？       │
   │ 文档被切分成几块？     │
   │ 文档何时更新的？       │
   └────────────────────────┘

3. 重建依据
   ┌────────────────────────┐
   │ 重建时加载哪些文件？   │
   │ 从哪里加载？           │
   │ 排除哪些文件？         │
   └────────────────────────┘
```

### 索引结构详解

```python
# 单个文档的索引条目
{
    "source": "E:/docs/python_basics.txt",  # 文档源路径（绝对路径）
    "chunk_count": 5,                        # 切分的块数
    "added_time": "2026-01-09T10:30:00.123456",    # 添加时间（ISO 格式）
    "updated_time": "2026-01-09T10:30:00.123456"   # 更新时间（ISO 格式）
}
```

**字段说明**：

1. **source（文档源）**：
   - 存储文档的原始路径
   - 使用绝对路径，避免相对路径问题
   - 用于重建时重新加载文件

2. **chunk_count（块数量）**：
   - 记录文档被切分成多少块
   - 用于统计和显示
   - 帮助了解文档大小

3. **added_time（添加时间）**：
   - 文档首次添加的时间戳
   - ISO 8601 格式：`YYYY-MM-DDTHH:MM:SS.ffffff`
   - 使用 `datetime.now().isoformat()`

4. **updated_time（更新时间）**：
   - 文档最后更新的时间戳
   - 重新添加相同文档时更新
   - 用于追踪文档变化

### 索引的持久化

```python
def _save_doc_index(self):
    """保存文档索引到磁盘"""
    if not self.kb_path:
        return
    
    index_file = self.kb_path / "doc_index.json"
    
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(
            self.documents_index,
            f,
            ensure_ascii=False,  # 支持中文
            indent=2             # 格式化输出
        )

def _load_doc_index(self):
    """从磁盘加载文档索引"""
    if not self.kb_path:
        return
    
    index_file = self.kb_path / "doc_index.json"
    
    if index_file.exists():
        with open(index_file, 'r', encoding='utf-8') as f:
            self.documents_index = json.load(f)
    else:
        self.documents_index = []
```

**知识点**：
- **ensure_ascii=False**：允许存储中文字符
- **indent=2**：格式化 JSON，便于阅读和调试
- **UTF-8 编码**：统一使用 UTF-8

### 索引的更新

```python
def _update_doc_index(self, documents: List[Document]):
    """
    更新文档索引
    
    逻辑：
    1. 按 source 分组统计文档块数
    2. 对于每个 source：
       - 如果已存在：更新 chunk_count 和 updated_time
       - 如果不存在：新增索引条目
    3. 持久化到磁盘
    """
    from collections import defaultdict
    from datetime import datetime
    
    # 按 source 分组
    source_counts = defaultdict(int)
    for doc in documents:
        source = doc.metadata.get('source', 'unknown')
        source_counts[source] += 1
    
    current_time = datetime.now().isoformat()
    
    # 更新索引
    for source, count in source_counts.items():
        # 查找是否已存在
        existing = next(
            (d for d in self.documents_index if d['source'] == source),
            None
        )
        
        if existing:
            # 更新已有条目
            existing['chunk_count'] += count
            existing['updated_time'] = current_time
        else:
            # 新增条目
            self.documents_index.append({
                'source': source,
                'chunk_count': count,
                'added_time': current_time,
                'updated_time': current_time
            })
    
    # 持久化
    self._save_doc_index()
```

**知识点**：
- **defaultdict**：自动初始化字典值
- **next() 函数**：在迭代器中查找第一个匹配项
- **生成器表达式**：`(d for d in ... if ...)`
- **增量更新**：只更新变化的部分

---

## 文档管理功能

### 1. 文档上传

#### 单文件上传流程

```
用户调用 upload_file()
       ↓
验证文件存在性
       ↓
根据扩展名选择加载器
    .txt  → TextLoader
    .pdf  → PDFLoader
    .md   → MarkdownLoader
       ↓
加载文档内容
       ↓
选择文本切分器
       ↓
切分成 Chunks
  ┌──────────────────┐
  │ Chunk 1 (500字符) │
  ├──────────────────┤
  │ Chunk 2 (500字符) │ ← overlap (50字符)
  ├──────────────────┤
  │ Chunk 3 (500字符) │
  └──────────────────┘
       ↓
向量化（Embedding）
       ↓
存储到向量库
       ↓
更新文档索引
       ↓
持久化
```

#### 批量上传流程

```
用户调用 upload_directory()
       ↓
递归遍历目录
  directory/
  ├── file1.txt
  ├── file2.pdf
  └── subdir/
      └── file3.md
       ↓
过滤文件（按扩展名）
       ↓
逐个调用 upload_file()
       ↓
收集统计信息
  - 成功: 2
  - 失败: 1
  - 总块数: 15
       ↓
返回结果
```

### 2. 文档列表查询

```python
def list_documents(self) -> List[Dict]:
    """
    返回所有文档的信息
    
    返回格式：
    [
        {
            "source": "doc1.txt",
            "chunk_count": 5,
            "added_time": "...",
            "updated_time": "..."
        },
        ...
    ]
    """
    return self.documents_index.copy()  # 返回副本，避免外部修改

def get_document_info(self, source: str) -> Optional[Dict]:
    """
    获取单个文档的信息
    
    查找逻辑：
    遍历索引 → 匹配 source → 返回条目或 None
    """
    for doc_info in self.documents_index:
        if doc_info['source'] == source:
            return doc_info.copy()
    return None
```

**知识点**：
- **返回副本**：`list.copy()` 和 `dict.copy()` 避免外部修改
- **Optional 返回**：明确可能返回 None
- **简单查找**：线性查找，因为文档数量通常不大

### 3. 文档删除

#### 删除策略

知识库管理提供两种删除策略：

```
策略1：清空整个知识库
  使用场景：删除最后一个文档
  ┌─────────────────────┐
  │ 索引为空            │
  │ ↓                   │
  │ vectorstore.delete()│
  │ ↓                   │
  │ 完成                │
  └─────────────────────┘

策略2：重建向量库
  使用场景：删除部分文档
  ┌─────────────────────┐
  │ 索引不为空          │
  │ ↓                   │
  │ 清空向量库          │
  │ ↓                   │
  │ 重新加载剩余文档    │
  │ ↓                   │
  │ 完成                │
  └─────────────────────┘
```

#### 为什么需要重建？

FAISS 向量库的限制：
```
FAISS 特点：
- ✅ 快速相似度搜索
- ✅ 高效内存管理
- ❌ 不支持按文档删除单个向量

因此，删除文档的唯一方式是：
1. 清空向量库
2. 重新添加剩余文档
```

---

## 向量库重建机制

### 为什么需要重建？

```
需要重建的场景：

1. 删除文档
   ┌────────────────────┐
   │ 原向量库：A B C D  │
   │ 删除 B             │
   │ 新向量库：A C D    │
   └────────────────────┘

2. 更换 Embedding 模型
   ┌────────────────────┐
   │ 原模型：ada-002    │
   │ 新模型：text-3-large│
   │ 需要重新向量化     │
   └────────────────────┘

3. 向量库损坏
   ┌────────────────────┐
   │ 向量库文件损坏     │
   │ 从源文件恢复       │
   └────────────────────┘
```

### 重建流程详解

```
完整重建流程：

1. 准备阶段
   ┌────────────────────┐
   │ 读取文档索引       │
   │ 确定要处理的文档   │
   │ 清空向量库         │
   └────────────────────┘
        ↓
2. 加载阶段
   ┌────────────────────┐
   │ 遍历索引中的文档   │
   │ ├─ 跳过排除的文档  │
   │ └─ 加载其他文档    │
   └────────────────────┘
        ↓
3. 处理阶段
   ┌────────────────────┐
   │ 对每个文档：       │
   │ ├─ 使用加载器读取  │
   │ ├─ 切分文档        │
   │ ├─ 向量化          │
   │ └─ 添加到向量库    │
   └────────────────────┘
        ↓
4. 完成阶段
   ┌────────────────────┐
   │ 持久化向量库       │
   │ 统计处理结果       │
   │ 返回报告           │
   └────────────────────┘
```

### 重建的关键代码

```python
def rebuild_vectorstore(
    self,
    new_embedding: Optional[BaseEmbedding] = None,
    exclude_sources: Optional[List[str]] = None
):
    # 1. 清空向量库
    self.vectorstore.delete()
    print("✅ 向量库已清空")
    
    # 2. 遍历文档索引
    for doc_info in self.documents_index:
        source = doc_info['source']
        
        # 跳过排除的文档
        if exclude_sources and source in exclude_sources:
            continue
        
        try:
            # 3. 重新加载文件
            loader = DocumentLoaderFactory.create_loader(source)
            documents = loader.load()
            
            # 4. 添加到向量库（不更新索引）
            self.add_documents(documents, update_index=False)
            
        except Exception as e:
            print(f"  ⚠️ 失败: {source} - {e}")
```

**重建的注意事项**：

1. **不更新索引**：
   ```python
   self.add_documents(documents, update_index=False)
   ```
   因为索引已经存在，只需要重建向量库

2. **排除机制**：
   ```python
   if exclude_sources and source in exclude_sources:
       continue
   ```
   允许在重建时排除某些文档（如被删除的文档）

3. **容错处理**：
   单个文档失败不影响其他文档的处理

---

## 错误处理和异常

### 异常分层

知识库管理使用分层的异常处理策略：

```
异常层次结构：

第1层：参数验证异常
├─ ValueError: 参数无效
├─ TypeError: 类型错误
└─ FileNotFoundError: 文件不存在

第2层：业务逻辑异常
├─ 知识库不存在
├─ 文档不存在
└─ 重复创建

第3层：系统级异常
├─ 文件系统错误
├─ 网络错误（API 调用）
└─ 内存错误
```

### 异常处理模式

#### 1. 直接抛出特定异常

```python
def delete_document(self, source: str):
    try:
        # 业务逻辑
        if not doc_exists:
            raise ValueError(f"文档 '{source}' 不存在")
    
    except ValueError:
        # 保留 ValueError，直接抛出
        raise
    except Exception as e:
        # 其他异常包装后抛出
        raise Exception(f"删除失败: {str(e)}") from e
```

**为什么这样做？**
- **区分异常类型**：调用者可以根据异常类型做不同处理
- **保留原始异常**：`from e` 保留异常链
- **清晰的错误信息**：明确告诉用户哪里出错了

#### 2. 异常链

```python
try:
    # 原始操作
    result = some_operation()
except Exception as e:
    # 包装异常，保留原始异常信息
    raise Exception(f"操作失败: {str(e)}") from e
```

**异常链的好处**：
```
完整的错误追踪：

Exception: 添加文档失败: 文件加载失败: 文件不存在: doc.txt
  ↑ 第3层
    ↑ 第2层
      ↑ 第1层（原始异常）
```

#### 3. 容错处理

```python
# 批量处理时的容错
for file_path in file_list:
    try:
        process_file(file_path)
        success_count += 1
    except Exception as e:
        # 记录失败，但继续处理其他文件
        failed_count += 1
        failed_files.append(file_path)
        print(f"⚠️ 处理失败: {file_path} - {e}")

# 返回统计信息
return {
    'success': success_count,
    'failed': failed_count,
    'failed_files': failed_files
}
```

**容错的应用场景**：
- 批量上传文件
- 向量库重建
- 文档搜索

### 错误提示最佳实践

```python
# ✅ 好的错误提示
raise ValueError(f"知识库 '{name}' 已存在，请使用不同的名称")
raise FileNotFoundError(f"文件不存在: {file_path}")
raise Exception(f"添加文档失败: {str(e)}")

# ❌ 不好的错误提示
raise ValueError("错误")
raise Exception("失败")
raise Exception(str(e))  # 没有上下文
```

**好的错误提示应该包含**：
1. **具体的错误类型**：ValueError、FileNotFoundError 等
2. **上下文信息**：哪个知识库、哪个文件
3. **建议的解决方案**：如"请使用不同的名称"

---

## 设计模式应用

### 1. 工厂模式（Factory Pattern）

**应用场景**：根据文件类型自动选择合适的加载器和切分器。

```python
# DocumentLoaderFactory
class DocumentLoaderFactory:
    @staticmethod
    def create_loader(file_path: str) -> BaseDocumentLoader:
        """
        根据文件扩展名创建加载器
        
        .txt  → TextLoader
        .pdf  → PDFLoader
        .md   → MarkdownLoader
        """
        ext = Path(file_path).suffix.lower()
        
        if ext == '.txt':
            return TextLoader(file_path)
        elif ext == '.pdf':
            return PDFLoader(file_path)
        elif ext == '.md':
            return MarkdownLoader(file_path)
        else:
            raise ValueError(f"不支持的文件类型: {ext}")

# TextSplitterFactory
class TextSplitterFactory:
    @staticmethod
    def create_splitter(
        splitter_type: str = "recursive",
        **kwargs
    ) -> BaseTextSplitter:
        """
        根据类型创建切分器
        """
        if splitter_type == "recursive":
            return RecursiveTextSplitter(**kwargs)
        elif splitter_type == "character":
            return CharacterTextSplitter(**kwargs)
        else:
            raise ValueError(f"不支持的切分器类型: {splitter_type}")
```

**优点**：
- ✅ 调用者无需知道具体的类
- ✅ 易于扩展新的加载器和切分器
- ✅ 集中管理创建逻辑

### 2. 策略模式（Strategy Pattern）

**应用场景**：不同的文档加载策略和文本切分策略。

```python
# 抽象策略
class BaseDocumentLoader(ABC):
    @abstractmethod
    def load(self) -> List[Document]:
        pass

# 具体策略1：文本加载
class TextLoader(BaseDocumentLoader):
    def load(self) -> List[Document]:
        # 实现文本加载逻辑
        pass

# 具体策略2：PDF加载
class PDFLoader(BaseDocumentLoader):
    def load(self) -> List[Document]:
        # 实现PDF加载逻辑
        pass

# 使用策略
loader: BaseDocumentLoader = factory.create_loader(file_path)
documents = loader.load()  # 统一接口
```

**优点**：
- ✅ 算法可以独立变化
- ✅ 易于添加新策略
- ✅ 符合开闭原则

### 3. 组合模式（Composite Pattern）

**应用场景**：KnowledgeBaseManager 管理多个 KnowledgeBase。

```python
# 容器类
class KnowledgeBaseManager:
    def __init__(self):
        self.knowledge_bases: Dict[str, KnowledgeBase] = {}
    
    def add(self, kb: KnowledgeBase):
        """添加子组件"""
        self.knowledge_bases[kb.name] = kb
    
    def remove(self, name: str):
        """删除子组件"""
        del self.knowledge_bases[name]
    
    def get(self, name: str) -> KnowledgeBase:
        """获取子组件"""
        return self.knowledge_bases[name]

# 叶子类
class KnowledgeBase:
    def __init__(self, name: str, ...):
        self.name = name
        # ...
```

**优点**：
- ✅ 统一管理多个知识库
- ✅ 支持树形结构（可以扩展为知识库组）
- ✅ 简化客户端代码

### 4. 单例模式（Singleton Pattern）

**应用场景**：确保 KnowledgeBaseManager 只有一个实例。

```python
class KnowledgeBaseManager:
    _instance = None
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self, root_path: str = "./data/knowledge_base"):
        # 只初始化一次
        if not hasattr(self, 'initialized'):
            self.root_path = Path(root_path)
            self.knowledge_bases = {}
            self.initialized = True

# 使用
manager1 = KnowledgeBaseManager()
manager2 = KnowledgeBaseManager()
assert manager1 is manager2  # 同一个实例
```

**优点**：
- ✅ 全局只有一个管理器实例
- ✅ 避免重复创建
- ✅ 共享状态

---

## Python 语法知识点

### 1. 类型注解（Type Hints）

```python
from typing import List, Dict, Optional

class KnowledgeBase:
    # 属性类型注解
    name: str
    documents_index: List[Dict]
    
    # 方法参数和返回值注解
    def add_documents(
        self,
        documents: List[Document],  # 参数类型
        update_index: bool = True
    ) -> int:  # 返回值类型
        pass
    
    # Optional 表示可能为 None
    def get_document_info(
        self,
        source: str
    ) -> Optional[Dict]:
        pass
```

**类型注解的好处**：
- ✅ IDE 自动补全
- ✅ 静态类型检查
- ✅ 文档化代码
- ✅ 避免类型错误

### 2. Path 对象（pathlib）

```python
from pathlib import Path

# 创建 Path 对象
file_path = Path("data/kb/doc.txt")

# 常用操作
file_path.exists()          # 检查是否存在
file_path.is_file()         # 是否是文件
file_path.is_dir()          # 是否是目录
file_path.suffix            # 获取扩展名 ".txt"
file_path.stem              # 获取文件名（不含扩展名）
file_path.parent            # 获取父目录

# 路径拼接（推荐）
kb_path = Path("data") / "kb" / "doc.txt"

# 递归遍历
for file in directory.rglob("*.txt"):
    print(file)

# 创建目录
kb_path.mkdir(parents=True, exist_ok=True)
```

**为什么使用 pathlib？**
- ✅ 跨平台兼容
- ✅ 面向对象
- ✅ 操作直观

### 3. JSON 序列化

```python
import json

# 保存 JSON
data = [
    {"name": "doc1", "count": 5},
    {"name": "文档2", "count": 3}
]

with open("index.json", 'w', encoding='utf-8') as f:
    json.dump(
        data,
        f,
        ensure_ascii=False,  # 支持中文
        indent=2             # 格式化
    )

# 加载 JSON
with open("index.json", 'r', encoding='utf-8') as f:
    data = json.load(f)
```

**关键参数**：
- **ensure_ascii=False**：允许中文字符，否则会转义为 `\uXXXX`
- **indent=2**：格式化输出，便于阅读
- **encoding='utf-8'**：统一使用 UTF-8 编码

### 4. defaultdict

```python
from collections import defaultdict

# 自动初始化的字典
counts = defaultdict(int)  # 默认值为 0

for doc in documents:
    source = doc.metadata['source']
    counts[source] += 1  # 不需要检查 key 是否存在

# 等价于
counts = {}
for doc in documents:
    source = doc.metadata['source']
    if source not in counts:
        counts[source] = 0
    counts[source] += 1
```

**defaultdict 的类型**：
- `defaultdict(int)` → 默认值 0
- `defaultdict(list)` → 默认值 []
- `defaultdict(dict)` → 默认值 {}

### 5. 列表推导式和生成器

```python
# 列表推导式
filtered_docs = [
    d for d in self.documents_index 
    if d['source'] != deleted_source
]

# 生成器表达式
matching_doc = next(
    (d for d in self.documents_index if d['source'] == source),
    None  # 默认值
)

# 字典推导式
source_to_count = {
    doc['source']: doc['chunk_count']
    for doc in self.documents_index
}
```

**区别**：
- **列表推导式** `[...]`：立即创建整个列表
- **生成器表达式** `(...)`：惰性求值，节省内存

### 6. 上下文管理器（with 语句）

```python
# 文件操作
with open("file.txt", 'r', encoding='utf-8') as f:
    content = f.read()
# 自动关闭文件

# 等价于
f = open("file.txt", 'r', encoding='utf-8')
try:
    content = f.read()
finally:
    f.close()
```

**with 的优点**：
- ✅ 自动资源管理
- ✅ 异常安全
- ✅ 代码简洁

### 7. datetime 时间处理

```python
from datetime import datetime

# 获取当前时间
current_time = datetime.now()

# 转换为 ISO 格式字符串
iso_string = current_time.isoformat()
# "2026-01-09T10:30:00.123456"

# 从 ISO 字符串解析
parsed_time = datetime.fromisoformat(iso_string)

# 格式化输出
formatted = current_time.strftime("%Y-%m-%d %H:%M:%S")
# "2026-01-09 10:30:00"
```

**ISO 8601 格式**：
- 国际标准时间格式
- 易于解析和比较
- 包含日期和时间

---

## 最佳实践

### 1. 代码组织

```python
# ✅ 好的组织
src/
├── knowledge_base/
│   ├── __init__.py          # 导出公共接口
│   └── kb_manager.py        # 核心实现
├── core/
│   ├── document/            # 文档处理
│   ├── embedding/           # 向量化
│   └── vectorstore/         # 向量存储
└── examples/                # 示例和测试

# ❌ 不好的组织
all_in_one.py               # 所有代码在一个文件
```

### 2. 命名规范

```python
# ✅ 清晰的命名
class KnowledgeBase:          # 类名：大驼峰
    def add_documents(self):  # 方法名：小写+下划线
        pass
    
    documents_index: List     # 变量名：小写+下划线

# ❌ 不好的命名
class kb:                     # 类名应该大写
    def addDocs(self):        # 不一致的风格
        pass
    
    docIdx: List              # 不清晰
```

### 3. 文档字符串

```python
# ✅ 完整的文档字符串
def upload_file(
    self,
    file_path: str,
    chunk_size: int = 500,
    chunk_overlap: int = 50
) -> int:
    """
    上传单个文件到知识库
    
    参数：
        file_path: 文件路径
        chunk_size: 文本块大小（字符数）
        chunk_overlap: 文本块重叠大小（字符数）
    
    返回：
        int: 切分的文档块数量
    
    异常：
        FileNotFoundError: 文件不存在
        ValueError: 不支持的文件类型
    
    示例：
        >>> kb.upload_file("docs/manual.pdf", chunk_size=1000)
        5
    """
    pass
```

### 4. 错误处理

```python
# ✅ 分层的错误处理
try:
    result = operation()
except SpecificError:
    # 特定错误的处理
    raise
except Exception as e:
    # 通用错误的处理
    raise Exception(f"操作失败: {str(e)}") from e

# ❌ 捕获所有异常
try:
    result = operation()
except:  # 不推荐
    pass
```

### 5. 参数验证

```python
# ✅ 提前验证参数
def add_documents(self, documents: List[Document]) -> int:
    # 参数验证
    if not documents:
        raise ValueError("文档列表不能为空")
    
    if not isinstance(documents, list):
        raise TypeError("documents 必须是列表")
    
    # 业务逻辑
    # ...

# ❌ 不验证参数
def add_documents(self, documents):
    # 直接使用，可能导致难以调试的错误
    for doc in documents:  # 如果 documents 不是列表会报错
        # ...
```

### 6. 日志和反馈

```python
# ✅ 清晰的进度反馈
def rebuild_vectorstore(self):
    print(f"🔄 开始重建向量库 '{self.name}'...")
    
    for doc in self.documents_index:
        print(f"  处理: {doc['source']}")
        try:
            # 处理文档
            pass
        except Exception as e:
            print(f"  ⚠️ 失败: {doc['source']} - {e}")
    
    print("✅ 重建完成")

# ❌ 没有反馈
def rebuild_vectorstore(self):
    # 用户不知道程序在做什么
    for doc in self.documents_index:
        # 处理文档
        pass
```

### 7. 测试驱动开发

```python
# 先写测试
def test_upload_file():
    kb = KnowledgeBase(...)
    
    # 准备测试文件
    test_file = "test.txt"
    
    # 执行操作
    count = kb.upload_file(test_file)
    
    # 验证结果
    assert count > 0
    assert kb.get_document_info(test_file) is not None

# 再实现功能
def upload_file(self, file_path: str) -> int:
    # 实现逻辑
    pass
```

---

## 应用场景

### 1. 企业知识库

```
场景：公司有多个部门，每个部门有自己的文档

技术部门 KB
├── API 文档
├── 架构设计
└── 代码规范

产品部门 KB
├── 产品需求
├── 用户反馈
└── 竞品分析

销售部门 KB
├── 销售话术
├── 客户案例
└── 价格策略

实现：
manager = KnowledgeBaseManager("./company_kb")
tech_kb = manager.create_kb("技术部门", ...)
product_kb = manager.create_kb("产品部门", ...)
sales_kb = manager.create_kb("销售部门", ...)
```

### 2. 多租户 SaaS 服务

```
场景：为不同的客户提供独立的知识库

客户A的知识库
├── 客户A的文档
└── 独立的向量存储

客户B的知识库
├── 客户B的文档
└── 独立的向量存储

实现：
manager = KnowledgeBaseManager("./saas_kb")

# 为客户A创建知识库
client_a_kb = manager.create_kb(f"client_{client_a_id}", ...)

# 为客户B创建知识库
client_b_kb = manager.create_kb(f"client_{client_b_id}", ...)

# 数据隔离，互不影响
```

### 3. 文档版本管理

```
场景：管理文档的不同版本

实现方式1：按版本创建知识库
manager.create_kb("docs_v1", ...)
manager.create_kb("docs_v2", ...)
manager.create_kb("docs_v3", ...)

实现方式2：在元数据中记录版本
documents = [
    Document(
        page_content="...",
        metadata={"source": "doc.txt", "version": "1.0"}
    )
]
```

### 4. 主题分类知识库

```
场景：按主题组织文档

Python 知识库
├── Python 基础
├── Python 进阶
└── Python 框架

JavaScript 知识库
├── JavaScript 基础
├── React
└── Node.js

AI 知识库
├── 机器学习
├── 深度学习
└── NLP

实现：
manager.create_kb("Python", ...)
manager.create_kb("JavaScript", ...)
manager.create_kb("AI", ...)
```

---

## 总结

### 核心要点

1. **知识库管理的本质**
   - 组织和管理文档集合
   - 提供统一的接口
   - 支持多知识库场景

2. **文档索引的重要性**
   - 追踪文档来源
   - 支持快速查询
   - 提供重建依据

3. **向量库的管理**
   - 持久化存储
   - 增量更新
   - 重建机制

4. **错误处理策略**
   - 分层异常
   - 清晰提示
   - 容错处理

5. **设计模式应用**
   - 工厂模式：自动选择加载器
   - 策略模式：不同的处理策略
   - 组合模式：管理多个知识库

### 学习收获

通过阶段二的学习，你应该掌握了：

✅ **RAG 系统的知识库管理**
- 如何组织和管理多个知识库
- 如何维护文档索引
- 如何处理文档的增删改查

✅ **Python 高级编程**
- 面向对象设计
- 类型注解的使用
- pathlib 和 JSON 的操作
- 异常处理的最佳实践

✅ **软件工程实践**
- 模块化设计
- 设计模式应用
- 测试驱动开发
- 文档编写规范

✅ **实际项目经验**
- 完整的功能实现
- 错误处理和日志
- 用户体验优化

### 下一步

阶段三将学习**会话管理**，包括：
- 对话历史的存储和管理
- 会话的持久化
- 多会话并行管理
- 会话上下文的维护

继续加油！🚀

